# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-05-12 15:52+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_guides/kafka-streams.adoc:6
#, fuzzy, no-wrap
msgid "Using Apache Kafka Streams"
msgstr "使用Apache Kafka流"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:11
#, fuzzy
msgid "This guide demonstrates how your Quarkus application can utilize the Apache Kafka Streams API to implement stream processing applications based on Apache Kafka."
msgstr "本指南展示了你的Quarkus应用如何利用Apache Kafka Streams API来实现基于Apache Kafka的流处理应用。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:12
#, fuzzy, no-wrap
msgid "Prerequisites"
msgstr "先决条件"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:19
#, fuzzy
msgid "It is recommended, that you have read the {quickstarts-tree-url}/kafka-quickstart[Kafka quickstart] before."
msgstr "建议你之前阅读过{quickstarts-tree-url}/kafka-quickstart[Kafka快速入门]。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:24
#, fuzzy
msgid "The Quarkus extension for Kafka Streams allows for very fast turnaround times during development by supporting the Quarkus Dev Mode (e.g. via `./mvnw compile quarkus:dev`).  After changing the code of your Kafka Streams topology, the application will automatically be reloaded when the next input message arrives."
msgstr "Kafka Streams的Quarkus扩展通过支持Quarkus Dev模式（例如通过 `./mvnw compile quarkus:dev` ），使得开发过程中的周转时间非常快。在改变你的Kafka流拓扑结构的代码后，当下一个输入消息到达时，应用程序将自动被重新加载。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:27
#, fuzzy
msgid "A recommended development set-up is to have some producer which creates test messages on the processed topic(s) in fixed intervals, e.g. every second and observe the streaming application's output topic(s) using a tool such as `kafkacat`.  Using the dev mode, you'll instantly see messages on the output topic(s) as produced by the latest version of your streaming application when saving."
msgstr "一个推荐的开发设置是有一些生产者以固定的时间间隔在所处理的主题上创建测试消息，例如每秒钟一次，并使用一个工具如 `kafkacat` 观察流媒体应用程序的输出主题。使用开发模式，你将立即看到由最新版本的流媒体应用程序在保存时产生的输出主题上的消息。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:29
#, fuzzy
msgid "For the best development experience, we recommend applying the following configuration settings to your Kafka broker:"
msgstr "为了获得最佳的开发体验，我们建议将以下配置设置应用于你的Kafka代理。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:33
#, no-wrap
msgid "group.min.session.timeout.ms=250\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:36
#, fuzzy
msgid "Also specify the following settings in your Quarkus `application.properties`:"
msgstr "同时在你的Quarkus `application.properties` 中指定以下设置。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:41
#, no-wrap
msgid ""
"kafka-streams.consumer.session.timeout.ms=250\n"
"kafka-streams.consumer.heartbeat.interval.ms=200\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:44
#, fuzzy
msgid "Together, these settings will ensure that the application can very quickly reconnect to the broker after being restarted in dev mode."
msgstr "这些设置将确保应用程序在开发模式下被重新启动后能非常迅速地重新连接到代理服务器。"

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_guides/kafka-streams.adoc:46
#: upstream/_guides/kafka-streams.adoc:803
#, fuzzy, no-wrap
msgid "Architecture"
msgstr "建筑学"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:51
#, fuzzy
msgid "In this guide, we are going to generate (random) temperature values in one component (named `generator`).  These values are associated to given weather stations and are written in a Kafka topic (`temperature-values`).  Another topic (`weather-stations`) contains just the main data about the weather stations themselves (id and name)."
msgstr "在本指南中，我们将在一个组件（名为 `generator` ）中生成（随机）温度值。这些值与给定的气象站相关联，并被写入一个Kafka主题( `temperature-values` )。另一个主题 ( `weather-stations` ) 只包含关于气象站本身的主要数据（ID和名称）。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:53
#, fuzzy
msgid "A second component (`aggregator`) reads from the two Kafka topics and processes them in a streaming pipeline:"
msgstr "第二个组件( `aggregator` )从两个Kafka主题中读取并在一个流式管道中处理它们。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:55
#, fuzzy
msgid "the two topics are joined on weather station id"
msgstr "这两个主题在气象站的ID上是连在一起的"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:56
#, fuzzy
msgid "per weather station the min, max and average temperature is determined"
msgstr "确定每个气象站的最低、最高和平均温度"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:57
#, fuzzy
msgid "this aggregated data is written out to a third topic (`temperatures-aggregated`)"
msgstr "这个汇总的数据被写入第三个主题 ( `temperatures-aggregated` )"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:61
#, fuzzy
msgid "The data can be examined by inspecting the output topic.  By exposing a Kafka Streams https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html[interactive query], the latest result for each weather station can alternatively be obtained via a simple REST query."
msgstr "这些数据可以通过检查输出主题来检查。通过暴露一个Kafka Streams link:https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html[交互式查询] ，每个气象站的最新结果可以通过一个简单的REST查询获得。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:63
#, fuzzy
msgid "The overall architecture looks like so:"
msgstr "整体架构看起来是这样的。"

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_guides/kafka-streams.adoc:64
#, fuzzy, no-wrap
msgid "Architecture,"
msgstr "建筑。"

#. type: Target for macro image
#: upstream/_guides/kafka-streams.adoc:64
#, no-wrap
msgid "kafka-streams-guide-architecture.png"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:66
#, fuzzy, no-wrap
msgid "Solution"
msgstr "解决方案"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:70
#, fuzzy
msgid "We recommend that you follow the instructions in the next sections and create the application step by step.  However, you can go right to the completed example."
msgstr "我们建议你按照下面几节的说明，一步一步地创建应用程序。然而，你可以直接进入已完成的例子。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:72
#, fuzzy
msgid "Clone the Git repository: `git clone {quickstarts-clone-url}`, or download an {quickstarts-archive-url}[archive]."
msgstr "克隆 Git 仓库。 `git clone {quickstarts-clone-url}` ，或者下载一个 {quickstarts-archive-url}[存档] 。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:74
#, fuzzy
msgid "The solution is located in the `kafka-streams-quickstart` {quickstarts-tree-url}/kafka-streams-quickstart[directory]."
msgstr "该解决方案位于 `kafka-streams-quickstart` {quickstarts-tree-url}/kafka-streams-quickstart[目录]中。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:75
#, fuzzy, no-wrap
msgid "Creating the Producer Maven Project"
msgstr "创建生产者Maven项目"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:79
#, fuzzy
msgid "First, we need a new project with the temperature value producer.  Create a new project with the following command:"
msgstr "首先，我们需要一个带有温度值生产者的新项目。用以下命令创建一个新项目。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:86
#, fuzzy
msgid "This command generates a Maven project, importing the Reactive Messaging and Kafka connector extensions."
msgstr "该命令生成了一个Maven项目，导入了Reactive Messaging和Kafka连接器扩展。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:89
#, fuzzy
msgid "If you already have your Quarkus project configured, you can add the `smallrye-reactive-messaging-kafka` extension to your project by running the following command in your project base directory:"
msgstr "如果你已经配置了你的Quarkus项目，你可以通过在你的项目基础目录下运行以下命令，将 `smallrye-reactive-messaging-kafka` 扩展到你的项目。"

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:94
#, fuzzy
msgid "This will add the following to your build file:"
msgstr "这将在你的构建文件中添加以下内容。"

#. type: Block title
#: upstream/_guides/kafka-streams.adoc:96
#: upstream/_guides/kafka-streams.adoc:248
#, fuzzy, no-wrap
msgid "pom.xml"
msgstr "pom.xml"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:102
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Block title
#: upstream/_guides/kafka-streams.adoc:105
#: upstream/_guides/kafka-streams.adoc:257
#, fuzzy, no-wrap
msgid "build.gradle"
msgstr "build.gradle"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:108
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-smallrye-reactive-messaging-kafka\")\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:110
#, fuzzy, no-wrap
msgid "The Temperature Value Producer"
msgstr "温度值生产者"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:114
#, fuzzy
msgid "Create the `producer/src/main/java/org/acme/kafka/streams/producer/generator/ValuesGenerator.java` file, with the following content:"
msgstr "创建 `producer/src/main/java/org/acme/kafka/streams/producer/generator/ValuesGenerator.java` 文件，内容如下。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:118
#, no-wrap
msgid "package org.acme.kafka.streams.producer.generator;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:127
#, no-wrap
msgid ""
"import java.math.BigDecimal;\n"
"import java.math.RoundingMode;\n"
"import java.time.Duration;\n"
"import java.time.Instant;\n"
"import java.util.Arrays;\n"
"import java.util.Collections;\n"
"import java.util.List;\n"
"import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:129
#, no-wrap
msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:134
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.kafka.Record;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
"import org.jboss.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:143
#, no-wrap
msgid ""
"/**\n"
" * A bean producing random temperature data every second.\n"
" * The values are written to a Kafka topic (temperature-values).\n"
" * Another topic contains the name of weather stations (weather-stations).\n"
" * The Kafka configuration is specified in the application configuration.\n"
" */\n"
"@ApplicationScoped\n"
"public class ValuesGenerator {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:145
#, no-wrap
msgid "    private static final Logger LOG = Logger.getLogger(ValuesGenerator.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:147
#, no-wrap
msgid "    private Random random = new Random();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:158
#, no-wrap
msgid ""
"    private List<WeatherStation> stations = List.of(\n"
"                        new WeatherStation(1, \"Hamburg\", 13),\n"
"                        new WeatherStation(2, \"Snowdonia\", 5),\n"
"                        new WeatherStation(3, \"Boston\", 11),\n"
"                        new WeatherStation(4, \"Tokio\", 16),\n"
"                        new WeatherStation(5, \"Cusco\", 12),\n"
"                        new WeatherStation(6, \"Svalbard\", -7),\n"
"                        new WeatherStation(7, \"Porthsmouth\", 11),\n"
"                        new WeatherStation(8, \"Oslo\", 7),\n"
"                        new WeatherStation(9, \"Marrakesh\", 20));\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:168
#, no-wrap
msgid ""
"    @Outgoing(\"temperature-values\")                                        // <1>\n"
"    public Multi<Record<Integer, String>> generate() {\n"
"        return Multi.createFrom().ticks().every(Duration.ofMillis(500))    // <2>\n"
"                .onOverflow().drop()\n"
"                .map(tick -> {\n"
"                    WeatherStation station = stations.get(random.nextInt(stations.size()));\n"
"                    double temperature = BigDecimal.valueOf(random.nextGaussian() * 15 + station.averageTemperature)\n"
"                            .setScale(1, RoundingMode.HALF_UP)\n"
"                            .doubleValue();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:173
#, no-wrap
msgid ""
"                    LOG.infov(\"station: {0}, temperature: {1}\", station.name, temperature);\n"
"                    return Record.of(station.id, Instant.now() + \";\" + temperature);\n"
"                });\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:183
#, no-wrap
msgid ""
"    @Outgoing(\"weather-stations\")                                          // <3>\n"
"    public Multi<Record<Integer, String>> weatherStations() {\n"
"        return Multi.createFrom().items(stations.stream()\n"
"            .map(s -> Record.of(\n"
"                    s.id,\n"
"                    \"{ \\\"id\\\" : \" + s.id +\n"
"                    \", \\\"name\\\" : \\\"\" + s.name + \"\\\" }\"))\n"
"        );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:185
#, no-wrap
msgid "    private static class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:189
#, no-wrap
msgid ""
"        int id;\n"
"        String name;\n"
"        int averageTemperature;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:197
#, no-wrap
msgid ""
"        public WeatherStation(int id, String name, int averageTemperature) {\n"
"            this.id = id;\n"
"            this.name = name;\n"
"            this.averageTemperature = averageTemperature;\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:199
#, fuzzy
msgid "Instruct Reactive Messaging to dispatch the items from the returned `Multi` to `temperature-values`."
msgstr "指示Reactive Messaging从返回的 `Multi` ，将项目分派到 `temperature-values` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:200
#, fuzzy
msgid "The method returns a Mutiny _stream_ (`Multi`) emitting a random temperature value every 0.5 seconds."
msgstr "该方法返回一个Mutiny _流_ ( `Multi` )，每0.5秒发出一个随机温度值。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:201
#, fuzzy
msgid "Instruct Reactive Messaging to dispatch the items from the returned `Multi` (static list of weather stations) to `weather-stations`."
msgstr "指示Reactive Messaging将返回的 `Multi` （气象站的静态列表）中的项目分派到 `weather-stations` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:203
#, fuzzy
msgid "The two methods each return a _reactive stream_ whose items are sent to the streams named `temperature-values` and `weather-stations`, respectively."
msgstr "这两个方法分别返回一个 _反应式流_ ，其项目被发送到名为 `temperature-values` 和 `weather-stations` 的流。"

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:204
#, fuzzy, no-wrap
msgid "Topic Configuration"
msgstr "主题配置"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:208
#, fuzzy
msgid "The two channels are mapped to Kafka topics using the Quarkus configuration file `application.properties`.  For that, add the following to the file `producer/src/main/resources/application.properties`:"
msgstr "使用Quarkus配置文件 `application.properties` ，将这两个通道映射到Kafka主题。为此，在文件中添加以下内容： `producer/src/main/resources/application.properties` 。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:213
#, no-wrap
msgid ""
"# Configure the Kafka broker location\n"
"kafka.bootstrap.servers=localhost:9092\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:217
#, no-wrap
msgid ""
"mp.messaging.outgoing.temperature-values.connector=smallrye-kafka\n"
"mp.messaging.outgoing.temperature-values.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
"mp.messaging.outgoing.temperature-values.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:221
#, no-wrap
msgid ""
"mp.messaging.outgoing.weather-stations.connector=smallrye-kafka\n"
"mp.messaging.outgoing.weather-stations.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
"mp.messaging.outgoing.weather-stations.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:225
#, fuzzy
msgid "This configures the Kafka bootstrap server, the two topics and the corresponding (de-)serializers.  More details about the different configuration options are available on the https://kafka.apache.org/documentation/#producerconfigs[Producer configuration] and https://kafka.apache.org/documentation/#consumerconfigs[Consumer configuration] section from the Kafka documentation."
msgstr "这配置了Kafka引导服务器、两个主题和相应的（去）序列化器。关于不同配置选项的更多细节，可以在Kafka文档的 link:https://kafka.apache.org/documentation/#producerconfigs[Producer配置] 和 link:https://kafka.apache.org/documentation/#consumerconfigs[Consumer配置] 部分找到。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:226
#, fuzzy, no-wrap
msgid "Creating the Aggregator Maven Project"
msgstr "创建聚合器Maven项目"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:231
#, fuzzy
msgid "With the producer application in place, it's time to implement the actual aggregator application, which will run the Kafka Streams pipeline.  Create another project like so:"
msgstr "有了生产者应用，现在是时候实现实际的聚合者应用了，它将运行Kafka Streams管道。像这样创建另一个项目。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:238
#, fuzzy
msgid "This creates the `aggregator` project with the Quarkus extension for Kafka Streams and with the Jackson support for RESTEasy Reactive."
msgstr "这就创建了 `aggregator` ，该项目带有Quarkus对Kafka流的扩展，以及Jackson对RESTEasy Reactive的支持。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:241
#, fuzzy
msgid "If you already have your Quarkus project configured, you can add the `kafka-streams` extension to your project by running the following command in your project base directory:"
msgstr "如果你已经配置了你的Quarkus项目，你可以通过在你的项目基础目录下运行以下命令，将 `kafka-streams` 扩展到你的项目。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:246
#, fuzzy
msgid "This will add the following to your `pom.xml`:"
msgstr "这将在你的 `pom.xml` 中添加以下内容。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:254
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-kafka-streams</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:260
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-kafka-streams\")\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:262
#, fuzzy, no-wrap
msgid "The Pipeline Implementation"
msgstr "管道的实施"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:266
#, fuzzy
msgid "Let's begin the implementation of the stream processing application by creating a few value objects for representing temperature measurements, weather stations and for keeping track of aggregated values."
msgstr "让我们开始实施流处理应用程序，创建一些数值对象，用于表示温度测量、气象站和保持跟踪汇总的数值。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:269
#, fuzzy
msgid "First, create the file `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStation.java`, representing a weather station, with the following content:"
msgstr "首先，创建文件 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStation.java` ，代表一个气象站，其内容如下。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:273
#: upstream/_guides/kafka-streams.adoc:291
#: upstream/_guides/kafka-streams.adoc:317
#: upstream/_guides/kafka-streams.adoc:679
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.model;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:275
#: upstream/_guides/kafka-streams.adoc:322
#: upstream/_guides/kafka-streams.adoc:681
#, no-wrap
msgid "import io.quarkus.runtime.annotations.RegisterForReflection;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:278
#, no-wrap
msgid ""
"@RegisterForReflection // <1>\n"
"public class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:282
#, no-wrap
msgid ""
"    public int id;\n"
"    public String name;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:284
#, fuzzy
msgid "The `@RegisterForReflection` annotation instructs Quarkus to keep the class and its members during the native compilation. More details about the `@RegisterForReflection` annotation can be found on the xref:writing-native-applications-tips.adoc#registerForReflection[native application tips] page."
msgstr " `@RegisterForReflection` 注解指示Quarkus在本地编译过程中保留该类和其成员。关于 `@RegisterForReflection` 注解的更多细节可以在 link:writing-native-applications-tips.html#registerForReflection[本地应用程序提示] 页面找到。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:287
#, fuzzy
msgid "Then the file `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/TemperatureMeasurement.java`, representing temperature measurements for a given station:"
msgstr "然后，文件 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/TemperatureMeasurement.java` ，代表某一个站的温度测量值。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:293
#: upstream/_guides/kafka-streams.adoc:360
#, no-wrap
msgid "import java.time.Instant;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:295
#, no-wrap
msgid "public class TemperatureMeasurement {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:300
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public Instant timestamp;\n"
"    public double value;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:309
#, no-wrap
msgid ""
"    public TemperatureMeasurement(int stationId, String stationName, Instant timestamp,\n"
"            double value) {\n"
"        this.stationId = stationId;\n"
"        this.stationName = stationName;\n"
"        this.timestamp = timestamp;\n"
"        this.value = value;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:313
#, fuzzy
msgid "And finally `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/Aggregation.java`, which will be used to keep track of the aggregated values while the events are processed in the streaming pipeline:"
msgstr "最后是 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/Aggregation.java` ，当事件在流式管道中被处理时，它将被用来跟踪汇总的值。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:320
#, no-wrap
msgid ""
"import java.math.BigDecimal;\n"
"import java.math.RoundingMode;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:325
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class Aggregation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:333
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public double min = Double.MAX_VALUE;\n"
"    public double max = Double.MIN_VALUE;\n"
"    public int count;\n"
"    public double sum;\n"
"    public double avg;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:337
#, no-wrap
msgid ""
"    public Aggregation updateFrom(TemperatureMeasurement measurement) {\n"
"        stationId = measurement.stationId;\n"
"        stationName = measurement.stationName;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:342
#, no-wrap
msgid ""
"        count++;\n"
"        sum += measurement.value;\n"
"        avg = BigDecimal.valueOf(sum / count)\n"
"                .setScale(1, RoundingMode.HALF_UP).doubleValue();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:345
#, no-wrap
msgid ""
"        min = Math.min(min, measurement.value);\n"
"        max = Math.max(max, measurement.value);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:349
#, no-wrap
msgid ""
"        return this;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:354
#, fuzzy
msgid "Next, let's create the actual streaming query implementation itself in the `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/TopologyProducer.java` file.  All we need to do for that is to declare a CDI producer method which returns the Kafka Streams `Topology`; the Quarkus extension will take care of configuring, starting and stopping the actual Kafka Streams engine."
msgstr "接下来，让我们在 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/TopologyProducer.java` 文件中创建实际的流查询实现本身。我们需要做的就是声明一个CDI生产者方法，该方法返回Kafka Streams `Topology` ；Quarkus扩展将负责配置、启动和停止实际的Kafka Streams引擎。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:358
#: upstream/_guides/kafka-streams.adoc:595
#: upstream/_guides/kafka-streams.adoc:642
#: upstream/_guides/kafka-streams.adoc:865
#: upstream/_guides/kafka-streams.adoc:919
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:363
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.inject.Produces;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:376
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.model.Aggregation;\n"
"import org.acme.kafka.streams.aggregator.model.TemperatureMeasurement;\n"
"import org.acme.kafka.streams.aggregator.model.WeatherStation;\n"
"import org.apache.kafka.common.serialization.Serdes;\n"
"import org.apache.kafka.streams.StreamsBuilder;\n"
"import org.apache.kafka.streams.Topology;\n"
"import org.apache.kafka.streams.kstream.Consumed;\n"
"import org.apache.kafka.streams.kstream.GlobalKTable;\n"
"import org.apache.kafka.streams.kstream.Materialized;\n"
"import org.apache.kafka.streams.kstream.Produced;\n"
"import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;\n"
"import org.apache.kafka.streams.state.Stores;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:378
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperSerde;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:381
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class TopologyProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:383
#, no-wrap
msgid "    static final String WEATHER_STATIONS_STORE = \"weather-stations-store\";\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:387
#, no-wrap
msgid ""
"    private static final String WEATHER_STATIONS_TOPIC = \"weather-stations\";\n"
"    private static final String TEMPERATURE_VALUES_TOPIC = \"temperature-values\";\n"
"    private static final String TEMPERATURES_AGGREGATED_TOPIC = \"temperatures-aggregated\";\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:391
#, no-wrap
msgid ""
"    @Produces\n"
"    public Topology buildTopology() {\n"
"        StreamsBuilder builder = new StreamsBuilder();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:395
#, no-wrap
msgid ""
"        ObjectMapperSerde<WeatherStation> weatherStationSerde = new ObjectMapperSerde<>(\n"
"                WeatherStation.class);\n"
"        ObjectMapperSerde<Aggregation> aggregationSerde = new ObjectMapperSerde<>(Aggregation.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:398
#, no-wrap
msgid ""
"        KeyValueBytesStoreSupplier storeSupplier = Stores.persistentKeyValueStore(\n"
"                WEATHER_STATIONS_STORE);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:402
#, no-wrap
msgid ""
"        GlobalKTable<Integer, WeatherStation> stations = builder.globalTable( // <1>\n"
"                WEATHER_STATIONS_TOPIC,\n"
"                Consumed.with(Serdes.Integer(), weatherStationSerde));\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:429
#, no-wrap
msgid ""
"        builder.stream(                                                       // <2>\n"
"                        TEMPERATURE_VALUES_TOPIC,\n"
"                        Consumed.with(Serdes.Integer(), Serdes.String())\n"
"                )\n"
"                .join(                                                        // <3>\n"
"                        stations,\n"
"                        (stationId, timestampAndValue) -> stationId,\n"
"                        (timestampAndValue, station) -> {\n"
"                            String[] parts = timestampAndValue.split(\";\");\n"
"                            return new TemperatureMeasurement(station.id, station.name,\n"
"                                    Instant.parse(parts[0]), Double.valueOf(parts[1]));\n"
"                        }\n"
"                )\n"
"                .groupByKey()                                                 // <4>\n"
"                .aggregate(                                                   // <5>\n"
"                        Aggregation::new,\n"
"                        (stationId, value, aggregation) -> aggregation.updateFrom(value),\n"
"                        Materialized.<Integer, Aggregation> as(storeSupplier)\n"
"                            .withKeySerde(Serdes.Integer())\n"
"                            .withValueSerde(aggregationSerde)\n"
"                )\n"
"                .toStream()\n"
"                .to(                                                          // <6>\n"
"                        TEMPERATURES_AGGREGATED_TOPIC,\n"
"                        Produced.with(Serdes.Integer(), aggregationSerde)\n"
"                );\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:433
#, no-wrap
msgid ""
"        return builder.build();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:435
#, fuzzy
msgid "The `weather-stations` table is read into a `GlobalKTable`, representing the current state of each weather station"
msgstr " `weather-stations` 表被读入一个 `GlobalKTable` ，代表每个气象站的当前状态"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:436
#, fuzzy
msgid "The `temperature-values` topic is read into a `KStream`; whenever a new message arrives to this topic, the pipeline will be processed for this measurement"
msgstr " `temperature-values` 主题被读入一个 `KStream` ；每当有新的消息到达这个主题，管道就会对这个测量进行处理。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:437
#, fuzzy
msgid "The message from the `temperature-values` topic is joined with the corresponding weather station, using the topic's key (weather station id); the join result contains the data from the measurement and associated weather station message"
msgstr "来自 `temperature-values` 主题的信息与相应的气象站连接，使用主题的键（气象站ID）；连接结果包含来自测量和相关气象站信息的数据"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:438
#, fuzzy
msgid "The values are grouped by message key (the weather station id)"
msgstr "这些值按信息键（气象站的ID）进行分组"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:439
#, fuzzy
msgid "Within each group, all the measurements of that station are aggregated, by keeping track of minimum and maximum values and calculating the average value of all measurements of that station (see the `Aggregation` type)"
msgstr "在每个组内，该站的所有测量值被汇总，通过跟踪最小值和最大值，并计算该站所有测量值的平均值（见 `Aggregation` ）。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:440
#, fuzzy
msgid "The results of the pipeline are written out to the `temperatures-aggregated` topic"
msgstr "管线的结果被写出来， `temperatures-aggregated` 主题"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:443
#, fuzzy
msgid "The Kafka Streams extension is configured via the Quarkus configuration file `application.properties`.  Create the file `aggregator/src/main/resources/application.properties` with the following contents:"
msgstr "Kafka Streams扩展是通过Quarkus配置文件 `application.properties` 。创建文件 `aggregator/src/main/resources/application.properties` ，内容如下。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:449
#, no-wrap
msgid ""
"quarkus.kafka-streams.bootstrap-servers=localhost:9092\n"
"quarkus.kafka-streams.application-server=${hostname}:8080\n"
"quarkus.kafka-streams.topics=weather-stations,temperature-values\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:456
#, no-wrap
msgid ""
"# pass-through options\n"
"kafka-streams.cache.max.bytes.buffering=10240\n"
"kafka-streams.commit.interval.ms=1000\n"
"kafka-streams.metadata.max.age.ms=500\n"
"kafka-streams.auto.offset.reset=earliest\n"
"kafka-streams.metrics.recording.level=DEBUG\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:463
#, fuzzy
msgid "The options with the `quarkus.kafka-streams` prefix can be changed dynamically at application startup, e.g. via environment variables or system properties.  `bootstrap-servers` and `application-server` are mapped to the Kafka Streams properties `bootstrap.servers` and `application.server`, respectively.  `topics` is specific to Quarkus: the application will wait for all the given topics to exist before launching the Kafka Streams engine.  This is to done to gracefully await the creation of topics that don't yet exist at application startup time."
msgstr "带有 `quarkus.kafka-streams` 前缀的选项可以在应用程序启动时动态改变，例如通过环境变量或系统属性。 `bootstrap-servers` 和 `application-server` 分别映射到Kafka Streams属性 `bootstrap.servers` 和 `application.server` 。 `topics` 是Quarkus特有的：应用程序在启动Kafka Streams引擎之前会等待所有指定的主题存在。这样做是为了优雅地等待在应用程序启动时还不存在的主题的创建。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:465
#, fuzzy
msgid "Alternatively, you can use `kafka.bootstrap.servers` instead of `quarkus.kafka-streams.bootstrap-servers` as you did in the _generator_ project above."
msgstr "另外，你也可以像上面的 _生成器_ 项目中那样，使用 `kafka.bootstrap.servers` ，而不是 `quarkus.kafka-streams.bootstrap-servers` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:468
#, fuzzy
msgid "All the properties within the `kafka-streams` namespace are passed through as-is to the Kafka Streams engine.  Changing their values requires a rebuild of the application."
msgstr " `kafka-streams` 命名空间内的所有属性都是按原样传递给Kafka流引擎的。改变它们的值需要重建应用程序。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:469
#, fuzzy, no-wrap
msgid "Building and Running the Applications"
msgstr "构建和运行应用程序"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:472
#, fuzzy
msgid "We now can build the `producer` and `aggregator` applications:"
msgstr "我们现在可以建立 `producer` 和 `aggregator` 应用程序。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:477
#, no-wrap
msgid ""
"./mvnw clean package -f producer/pom.xml\n"
"./mvnw clean package -f aggregator/pom.xml\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:482
#, fuzzy
msgid "Instead of running them directly on the host machine using the Quarkus dev mode, we're going to package them into container images and launch them via Docker Compose.  This is done in order to demonstrate scaling the `aggregator` aggregation to multiple nodes later on."
msgstr "我们不使用Quarkus开发模式直接在主机上运行它们，而是将它们打包成容器镜像，并通过Docker Compose启动它们。这样做是为了演示以后将 `aggregator` 聚合到多个节点上的扩展。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:485
#, fuzzy
msgid "The `Dockerfile` created by Quarkus by default needs one adjustment for the `aggregator` application in order to run the Kafka Streams pipeline.  To do so, edit the file `aggregator/src/main/docker/Dockerfile.jvm` and replace the line `FROM fabric8/java-alpine-openjdk8-jre` with `FROM fabric8/java-centos-openjdk8-jdk`."
msgstr "Quarkus默认创建的 `Dockerfile` 需要对 `aggregator` 应用程序进行一次调整，以便运行Kafka Streams管道。要做到这一点，编辑文件 `aggregator/src/main/docker/Dockerfile.jvm` ，用 `FROM fabric8/java-centos-openjdk8-jdk` 替换行 `FROM fabric8/java-alpine-openjdk8-jre` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:487
#, fuzzy
msgid "Next create a Docker Compose file (`docker-compose.yaml`) for spinning up the two applications as well as Apache Kafka and ZooKeeper like so:"
msgstr "接下来创建一个Docker Compose文件（ `docker-compose.yaml` ），用于启动两个应用程序以及Apache Kafka和ZooKeeper，像这样。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:491
#, no-wrap
msgid "version: '3.5'\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:523
#, no-wrap
msgid ""
"services:\n"
"  zookeeper:\n"
"    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
"    command: [\n"
"      \"sh\", \"-c\",\n"
"      \"bin/zookeeper-server-start.sh config/zookeeper.properties\"\n"
"    ]\n"
"    ports:\n"
"      - \"2181:2181\"\n"
"    environment:\n"
"      LOG_DIR: /tmp/logs\n"
"    networks:\n"
"      - kafkastreams-network\n"
"  kafka:\n"
"    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
"    command: [\n"
"      \"sh\", \"-c\",\n"
"      \"bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override num.partitions=$${KAFKA_NUM_PARTITIONS}\"\n"
"    ]\n"
"    depends_on:\n"
"      - zookeeper\n"
"    ports:\n"
"      - \"9092:9092\"\n"
"    environment:\n"
"      LOG_DIR: \"/tmp/logs\"\n"
"      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092\n"
"      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092\n"
"      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n"
"      KAFKA_NUM_PARTITIONS: 3\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:533
#, no-wrap
msgid ""
"  producer:\n"
"    image: quarkus-quickstarts/kafka-streams-producer:1.0\n"
"    build:\n"
"      context: producer\n"
"      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}\n"
"    environment:\n"
"      KAFKA_BOOTSTRAP_SERVERS: kafka:9092\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:543
#, no-wrap
msgid ""
"  aggregator:\n"
"    image: quarkus-quickstarts/kafka-streams-aggregator:1.0\n"
"    build:\n"
"      context: aggregator\n"
"      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}\n"
"    environment:\n"
"      QUARKUS_KAFKA_STREAMS_BOOTSTRAP_SERVERS: kafka:9092\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:547
#, no-wrap
msgid ""
"networks:\n"
"  kafkastreams-network:\n"
"    name: ks\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:551
#, fuzzy
msgid "To launch all the containers, building the `producer` and `aggregator` container images, run `docker-compose up --build`."
msgstr "要启动所有的容器，构建 `producer` 和 `aggregator` 容器镜像，运行 `docker-compose up --build` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:553
#, fuzzy
msgid "Instead of `QUARKUS_KAFKA_STREAMS_BOOTSTRAP_SERVERS`, you can use `KAFKA_BOOTSTRAP_SERVERS`."
msgstr "代替 `QUARKUS_KAFKA_STREAMS_BOOTSTRAP_SERVERS` ，你可以使用 `KAFKA_BOOTSTRAP_SERVERS` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:555
#, fuzzy
msgid "You should see log statements from the `producer` application about messages being sent to the \"temperature-values\" topic."
msgstr "你应该看到来自 `producer` 应用程序的日志声明，关于被发送到 \"temperature-values \"主题的消息。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:558
#, fuzzy
msgid "Now run an instance of the _debezium/tooling_ image, attaching to the same network all the other containers run in.  This image provides several useful tools such as _kafkacat_ and _httpie_:"
msgstr "现在运行 _debezium/tooling_ 镜像的一个实例，连接到所有其他容器运行的同一个网络。这个镜像提供了一些有用的工具，比如 _kafkacat_ 和 _httpie_ 。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:562
#, no-wrap
msgid "docker run --tty --rm -i --network ks debezium/tooling:1.1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:565
#, fuzzy
msgid "Within the tooling container, run _kafkacat_ to examine the results of the streaming pipeline:"
msgstr "在工具容器中，运行 _kafkacat_ 来检查流媒体管道的结果。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:569
#, no-wrap
msgid "kafkacat -b kafka:9092 -C -o beginning -q -t temperatures-aggregated\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:574
#, no-wrap
msgid ""
"{\"avg\":34.7,\"count\":4,\"max\":49.4,\"min\":16.8,\"stationId\":9,\"stationName\":\"Marrakesh\",\"sum\":138.8}\n"
"{\"avg\":15.7,\"count\":1,\"max\":15.7,\"min\":15.7,\"stationId\":2,\"stationName\":\"Snowdonia\",\"sum\":15.7}\n"
"{\"avg\":12.8,\"count\":7,\"max\":25.5,\"min\":-13.8,\"stationId\":7,\"stationName\":\"Porthsmouth\",\"sum\":89.7}\n"
"...\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:578
#, fuzzy
msgid "You should see new values arrive as the producer continues to emit temperature measurements, each value on the outbound topic showing the minimum, maximum and average temperature values of the represented weather station."
msgstr "你应该看到，随着生产者继续发出温度测量值，新的数值就会到来，出站主题上的每个数值都会显示所代表的气象站的最低、最高和平均温度值。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:579
#, fuzzy, no-wrap
msgid "Interactive Queries"
msgstr "互动查询"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:587
#, fuzzy
msgid "Subscribing to the `temperatures-aggregated` topic is a great way to react to any new temperature values.  It's a bit wasteful though if you're just interested in the latest aggregated value for a given weather station.  This is where Kafka Streams interactive queries shine: they let you directly query the underlying state store of the pipeline for the value associated to a given key.  By exposing a simple REST endpoint which queries the state store, the latest aggregation result can be retrieved without having to subscribe to any Kafka topic."
msgstr "订阅 `temperatures-aggregated` 主题是对任何新的温度值作出反应的一个好方法。但如果你只是对某一气象站的最新汇总值感兴趣的话，这就有点浪费了。这就是Kafka流交互式查询的优势所在：它可以让你直接查询管道的底层状态存储，获取与给定键相关的值。通过公开一个简单的REST端点来查询状态存储，无需订阅任何Kafka主题就可以检索到最新的聚合结果。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:589
#, fuzzy
msgid "Let's begin by creating a new class `InteractiveQueries` in the file `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/InteractiveQueries.java`:"
msgstr "让我们首先在文件 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/InteractiveQueries.java` 中创建一个新的类 `InteractiveQueries` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:591
#, fuzzy
msgid "one more method to the `KafkaStreamsPipeline` class which obtains the current state for a given key:"
msgstr " `KafkaStreamsPipeline` 类中又多了一个方法，可以获得给定键的当前状态。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:598
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:605
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.model.Aggregation;\n"
"import org.acme.kafka.streams.aggregator.model.WeatherStationData;\n"
"import org.apache.kafka.streams.KafkaStreams;\n"
"import org.apache.kafka.streams.errors.InvalidStateStoreException;\n"
"import org.apache.kafka.streams.state.QueryableStoreTypes;\n"
"import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:608
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class InteractiveQueries {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:611
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaStreams streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:614
#, no-wrap
msgid ""
"    public GetWeatherStationDataResult getWeatherStationData(int id) {\n"
"        Aggregation result = getWeatherStationStore().get(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:622
#, no-wrap
msgid ""
"        if (result != null) {\n"
"            return GetWeatherStationDataResult.found(WeatherStationData.from(result)); // <1>\n"
"        }\n"
"        else {\n"
"            return GetWeatherStationDataResult.notFound();                             // <2>\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:633
#, no-wrap
msgid ""
"    private ReadOnlyKeyValueStore<Integer, Aggregation> getWeatherStationStore() {\n"
"        while (true) {\n"
"            try {\n"
"                return streams.store(TopologyProducer.WEATHER_STATIONS_STORE, QueryableStoreTypes.keyValueStore());\n"
"            } catch (InvalidStateStoreException e) {\n"
"                // ignore, store not ready yet\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:635
#, fuzzy
msgid "A value for the given station id was found, so that value will be returned"
msgstr "找到了一个给定车站ID的值，所以该值将被返回。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:636
#, fuzzy
msgid "No value was found, either because a non-existing station was queried or no measurement exists yet for the given station"
msgstr "没有发现任何值，要么是因为查询的是一个不存在的站，要么是因为该站还没有测量值存在。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:638
#, fuzzy
msgid "Also create the method's return type in the file `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/GetWeatherStationDataResult.java`:"
msgstr "同时在文件 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/GetWeatherStationDataResult.java` 中创建该方法的返回类型。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:645
#: upstream/_guides/kafka-streams.adoc:868
#, no-wrap
msgid ""
"import java.util.Optional;\n"
"import java.util.OptionalInt;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:647
#: upstream/_guides/kafka-streams.adoc:870
#, no-wrap
msgid "import org.acme.kafka.streams.aggregator.model.WeatherStationData;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:649
#: upstream/_guides/kafka-streams.adoc:872
#, no-wrap
msgid "public class GetWeatherStationDataResult {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:652
#, no-wrap
msgid ""
"    private static GetWeatherStationDataResult NOT_FOUND =\n"
"            new GetWeatherStationDataResult(null);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:654
#, no-wrap
msgid "    private final WeatherStationData result;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:658
#, no-wrap
msgid ""
"    private GetWeatherStationDataResult(WeatherStationData result) {\n"
"        this.result = result;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:662
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult found(WeatherStationData data) {\n"
"        return new GetWeatherStationDataResult(data);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:666
#: upstream/_guides/kafka-streams.adoc:898
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult notFound() {\n"
"        return NOT_FOUND;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:671
#, no-wrap
msgid ""
"    public Optional<WeatherStationData> getResult() {\n"
"        return Optional.ofNullable(result);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:675
#, fuzzy
msgid "Also create `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStationData.java`, which represents the actual aggregation result for a weather station:"
msgstr "同时创建 `aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStationData.java` ，它代表一个气象站的实际聚集结果。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:684
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class WeatherStationData {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:691
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public double min = Double.MAX_VALUE;\n"
"    public double max = Double.MIN_VALUE;\n"
"    public int count;\n"
"    public double avg;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:701
#, no-wrap
msgid ""
"    private WeatherStationData(int stationId, String stationName, double min, double max,\n"
"            int count, double avg) {\n"
"        this.stationId = stationId;\n"
"        this.stationName = stationName;\n"
"        this.min = min;\n"
"        this.max = max;\n"
"        this.count = count;\n"
"        this.avg = avg;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:712
#, no-wrap
msgid ""
"    public static WeatherStationData from(Aggregation aggregation) {\n"
"        return new WeatherStationData(\n"
"                aggregation.stationId,\n"
"                aggregation.stationName,\n"
"                aggregation.min,\n"
"                aggregation.max,\n"
"                aggregation.count,\n"
"                aggregation.avg);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:716
#, fuzzy
msgid "We now can add a simple REST endpoint (`aggregator/src/main/java/org/acme/kafka/streams/aggregator/rest/WeatherStationEndpoint.java`), which invokes `getWeatherStationData()` and returns the data to the client:"
msgstr "我们现在可以添加一个简单的REST端点( `aggregator/src/main/java/org/acme/kafka/streams/aggregator/rest/WeatherStationEndpoint.java` )，它调用 `getWeatherStationData()` ，并将数据返回给客户端。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:720
#: upstream/_guides/kafka-streams.adoc:939
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.rest;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:724
#: upstream/_guides/kafka-streams.adoc:943
#, no-wrap
msgid ""
"import java.net.URI;\n"
"import java.net.URISyntaxException;\n"
"import java.util.List;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:732
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.core.MediaType;\n"
"import javax.ws.rs.core.Response;\n"
"import javax.ws.rs.core.Response.Status;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:735
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;\n"
"import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:739
#: upstream/_guides/kafka-streams.adoc:961
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Path(\"/weather-stations\")\n"
"public class WeatherStationEndpoint {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:742
#: upstream/_guides/kafka-streams.adoc:964
#, no-wrap
msgid ""
"    @Inject\n"
"    InteractiveQueries interactiveQueries;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:747
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/data/{id}\")\n"
"    public Response getWeatherStationData(int id) {\n"
"        GetWeatherStationDataResult result = interactiveQueries.getWeatherStationData(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:757
#, no-wrap
msgid ""
"        if (result.getResult().isPresent()) {  // <1>\n"
"            return Response.ok(result.getResult().get()).build();\n"
"        }\n"
"        else {\n"
"            return Response.status(Status.NOT_FOUND.getStatusCode(),\n"
"                    \"No data found for weather station \" + id).build();\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:759
#, fuzzy
msgid "Depending on whether a value was obtained, either return that value or a 404 response"
msgstr "根据是否获得了一个值，要么返回该值，要么返回一个404响应"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:761
#, fuzzy
msgid "With this code in place, it's time to rebuild the application and the `aggregator` service in Docker Compose:"
msgstr "有了这些代码，现在是时候在Docker Compose中重建应用程序和 `aggregator` 服务了。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:767
#, no-wrap
msgid ""
"./mvnw clean package -f aggregator/pom.xml\n"
"docker-compose stop aggregator\n"
"docker-compose up --build -d\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:772
#, fuzzy
msgid "This will rebuild the `aggregator` container and restart its service.  Once that's done, you can invoke the service's REST API to obtain the temperature data for one of the existing stations.  To do so, you can use `httpie` in the tooling container launched before:"
msgstr "这将重建 `aggregator` 容器并重新启动其服务。一旦完成，你就可以调用该服务的REST API来获取现有站点之一的温度数据。要做到这一点，你可以在之前启动的工具容器中使用 `httpie` 。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:776
#, no-wrap
msgid "http aggregator:8080/weather-stations/data/1\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:782
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 85\n"
"Content-Type: application/json\n"
"Date: Tue, 18 Jun 2019 19:29:16 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:791
#, no-wrap
msgid ""
"{\n"
"    \"avg\": 12.9,\n"
"    \"count\": 146,\n"
"    \"max\": 41.0,\n"
"    \"min\": -25.6,\n"
"    \"stationId\": 1,\n"
"    \"stationName\": \"Hamburg\"\n"
"}\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:793
#, fuzzy, no-wrap
msgid "Scaling Out"
msgstr "扩大规模"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:800
#, fuzzy
msgid "A very interesting trait of Kafka Streams applications is that they can be scaled out, i.e. the load and state can be distributed amongst multiple application instances running the same pipeline.  Each node will then contain a subset of the aggregation results, but Kafka Streams provides you with https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html#querying-remote-state-stores-for-the-entire-app[an API] to obtain the information which node is hosting a given key.  The application can then either fetch the data directly from the other instance, or simply point the client to the location of that other node."
msgstr "Kafka流应用程序的一个非常有趣的特征是，它们可以被扩展，即负载和状态可以分布在运行相同管道的多个应用程序实例中。每个节点将包含聚合结果的一个子集，但Kafka流为你提供了 link:https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html#querying-remote-state-stores-for-the-entire-app[一个API] ，以获得哪个节点承载了给定的键的信息。然后，应用程序可以直接从其他实例中获取数据，或者简单地将客户端指向该其他节点的位置。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:802
#, fuzzy
msgid "Launching multiple instances of the `aggregator` application will make look the overall architecture like so:"
msgstr "启动 `aggregator` 应用程序的多个实例将使整体架构看起来像这样。"

#. type: Target for macro image
#: upstream/_guides/kafka-streams.adoc:803
#, no-wrap
msgid "kafka-streams-guide-architecture-distributed.png"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:806
#, fuzzy
msgid "The `InteractiveQueries` class must be adjusted slightly for this distributed architecture:"
msgstr " `InteractiveQueries` 类必须为这种分布式结构稍作调整。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:815
#, no-wrap
msgid ""
"public GetWeatherStationDataResult getWeatherStationData(int id) {\n"
"    StreamsMetadata metadata = streams.metadataForKey(                  // <1>\n"
"            TopologyProducer.WEATHER_STATIONS_STORE,\n"
"            id,\n"
"            Serdes.Integer().serializer()\n"
"    );\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:823
#, no-wrap
msgid ""
"    if (metadata == null || metadata == StreamsMetadata.NOT_AVAILABLE) {\n"
"        LOG.warn(\"Found no metadata for key {}\", id);\n"
"        return GetWeatherStationDataResult.notFound();\n"
"    }\n"
"    else if (metadata.host().equals(host)) {                            // <2>\n"
"        LOG.info(\"Found data for key {} locally\", id);\n"
"        Aggregation result = getWeatherStationStore().get(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:841
#, no-wrap
msgid ""
"        if (result != null) {\n"
"            return GetWeatherStationDataResult.found(WeatherStationData.from(result));\n"
"        }\n"
"        else {\n"
"            return GetWeatherStationDataResult.notFound();\n"
"        }\n"
"    }\n"
"    else {                                                              // <3>\n"
"        LOG.info(\n"
"            \"Found data for key {} on remote host {}:{}\",\n"
"            id,\n"
"            metadata.host(),\n"
"            metadata.port()\n"
"        );\n"
"        return GetWeatherStationDataResult.foundRemotely(metadata.host(), metadata.port());\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:854
#, no-wrap
msgid ""
"public List<PipelineMetadata> getMetaData() {                           // <4>\n"
"    return streams.allMetadataForStore(TopologyProducer.WEATHER_STATIONS_STORE)\n"
"            .stream()\n"
"            .map(m -> new PipelineMetadata(\n"
"                    m.hostInfo().host() + \":\" + m.hostInfo().port(),\n"
"                    m.topicPartitions()\n"
"                        .stream()\n"
"                        .map(TopicPartition::toString)\n"
"                        .collect(Collectors.toSet()))\n"
"            )\n"
"            .collect(Collectors.toList());\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:856
#, fuzzy
msgid "The streams metadata for the given weather station id is obtained"
msgstr "获得给定气象站ID的数据流元数据"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:857
#, fuzzy
msgid "The given key (weather station id) is maintained by the local application node, i.e. it can answer the query itself"
msgstr "给定的密钥（气象站ID）由本地应用节点维护，即它可以自己回答查询。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:858
#, fuzzy
msgid "The given key is maintained by another application node; in this case the information about that node (host and port) will be returned"
msgstr "给定的密钥是由另一个应用节点维护的；在这种情况下，关于该节点的信息（主机和端口）将被返回。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:859
#, fuzzy
msgid "The `getMetaData()` method is added to provide callers with a list of all the nodes in the application cluster."
msgstr "增加了 `getMetaData()` 方法，向调用者提供应用程序集群中所有节点的列表。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:861
#, fuzzy
msgid "The `GetWeatherStationDataResult` type must be adjusted accordingly:"
msgstr " `GetWeatherStationDataResult` 类型必须进行相应的调整。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:875
#, no-wrap
msgid ""
"    private static GetWeatherStationDataResult NOT_FOUND =\n"
"            new GetWeatherStationDataResult(null, null, null);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:879
#, no-wrap
msgid ""
"    private final WeatherStationData result;\n"
"    private final String host;\n"
"    private final Integer port;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:886
#, no-wrap
msgid ""
"    private GetWeatherStationDataResult(WeatherStationData result, String host,\n"
"            Integer port) {\n"
"        this.result = result;\n"
"        this.host = host;\n"
"        this.port = port;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:890
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult found(WeatherStationData data) {\n"
"        return new GetWeatherStationDataResult(data, null, null);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:894
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult foundRemotely(String host, int port) {\n"
"        return new GetWeatherStationDataResult(null, host, port);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:902
#, no-wrap
msgid ""
"    public Optional<WeatherStationData> getResult() {\n"
"        return Optional.ofNullable(result);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:906
#, no-wrap
msgid ""
"    public Optional<String> getHost() {\n"
"        return Optional.ofNullable(host);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:911
#, no-wrap
msgid ""
"    public OptionalInt getPort() {\n"
"        return port != null ? OptionalInt.of(port) : OptionalInt.empty();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:915
#, fuzzy
msgid "Also the return type for `getMetaData()` must be defined (`aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/PipelineMetadata.java`):"
msgstr "同时必须定义 `getMetaData()` 的返回类型( `aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/PipelineMetadata.java` )。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:921
#, no-wrap
msgid "import java.util.Set;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:923
#, no-wrap
msgid "public class PipelineMetadata {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:926
#, no-wrap
msgid ""
"    public String host;\n"
"    public Set<String> partitions;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:932
#, no-wrap
msgid ""
"    public PipelineMetadata(String host, Set<String> partitions) {\n"
"        this.host = host;\n"
"        this.partitions = partitions;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:935
#, fuzzy
msgid "Lastly, the REST endpoint class must be updated:"
msgstr "最后，必须更新REST端点类。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:953
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import javax.ws.rs.core.Response;\n"
"import javax.ws.rs.core.Response.Status;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:957
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;\n"
"import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;\n"
"import org.acme.kafka.streams.aggregator.streams.PipelineMetadata;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:971
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/data/{id}\")\n"
"    @Consumes(MediaType.APPLICATION_JSON)\n"
"    @Produces(MediaType.APPLICATION_JSON)\n"
"    public Response getWeatherStationData(int id) {\n"
"        GetWeatherStationDataResult result = interactiveQueries.getWeatherStationData(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:985
#, no-wrap
msgid ""
"        if (result.getResult().isPresent()) {                     // <1>\n"
"            return Response.ok(result.getResult().get()).build();\n"
"        }\n"
"        else if (result.getHost().isPresent()) {                  // <2>\n"
"            URI otherUri = getOtherUri(result.getHost().get(), result.getPort().getAsInt(),\n"
"                    id);\n"
"            return Response.seeOther(otherUri).build();\n"
"        }\n"
"        else {                                                    // <3>\n"
"            return Response.status(Status.NOT_FOUND.getStatusCode(),\n"
"                    \"No data found for weather station \" + id).build();\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:992
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/meta-data\")\n"
"    @Produces(MediaType.APPLICATION_JSON)\n"
"    public List<PipelineMetadata> getMetaData() {                 // <4>\n"
"        return interactiveQueries.getMetaData();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1002
#, no-wrap
msgid ""
"    private URI getOtherUri(String host, int port, int id) {\n"
"        try {\n"
"            return new URI(\"http://\" + host + \":\" + port + \"/weather-stations/data/\" + id);\n"
"        }\n"
"        catch (URISyntaxException e) {\n"
"            throw new RuntimeException(e);\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1004
#, fuzzy
msgid "The data was found locally, so return it"
msgstr "数据是在本地找到的，所以返回它"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1005
#, fuzzy
msgid "The data is maintained by another node, so reply with a redirect (HTTP status code 303) if the data for the given key is stored on one of the other nodes."
msgstr "该数据是由另一个节点维护的，因此，如果给定的键的数据存储在其他节点之一，则回复重定向（HTTP状态代码303）。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1006
#, fuzzy
msgid "No data was found for the given weather station id"
msgstr "没有找到指定气象站ID的数据"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1007
#, fuzzy
msgid "Exposes information about all the hosts forming the application cluster"
msgstr "暴露出构成应用集群的所有主机的信息"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1010
#, fuzzy
msgid "Now stop the `aggregator` service again and rebuild it.  Then let's spin up three instances of it:"
msgstr "现在再次停止 `aggregator` 服务并重建它。然后让我们启动它的三个实例。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1016
#, no-wrap
msgid ""
"./mvnw clean package -f aggregator/pom.xml\n"
"docker-compose stop aggregator\n"
"docker-compose up --build -d --scale aggregator=3\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1021
#, fuzzy
msgid "When invoking the REST API on any of the three instances, it might either be that the aggregation for the requested weather station id is stored locally on the node receiving the query, or it could be stored on one of the other two nodes."
msgstr "当在三个实例中的任何一个上调用REST API时，可能是所请求的气象站ID的聚合存储在接收查询的节点上，也可能是存储在另外两个节点中的一个。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1025
#, fuzzy
msgid "As the load balancer of Docker Compose will distribute requests to the `aggregator` service in a round-robin fashion, we'll invoke the actual nodes directly.  The application exposes information about all the host names via REST:"
msgstr "由于Docker Compose的负载均衡器将以循环方式将请求分配到 `aggregator` ，我们将直接调用实际的节点。该应用程序通过REST暴露了所有主机名的信息。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1029
#, no-wrap
msgid "http aggregator:8080/weather-stations/meta-data\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1035
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 202\n"
"Content-Type: application/json\n"
"Date: Tue, 18 Jun 2019 20:00:23 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1056
#, no-wrap
msgid ""
"[\n"
"    {\n"
"        \"host\": \"2af13fe516a9:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-2\"\n"
"        ]\n"
"    },\n"
"    {\n"
"        \"host\": \"32cc8309611b:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-1\"\n"
"        ]\n"
"    },\n"
"    {\n"
"        \"host\": \"1eb39af8d587:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-0\"\n"
"        ]\n"
"    }\n"
"]\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1060
#, fuzzy
msgid "Retrieve the data from one of the three hosts shown in the response (your actual host names will differ):"
msgstr "从响应中显示的三个主机之一检索数据（你的实际主机名称会有所不同）。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1064
#, no-wrap
msgid "http 2af13fe516a9:8080/weather-stations/data/1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1067
#, fuzzy
msgid "If that node holds the data for key \"1\", you'll get a response like this:"
msgstr "如果该节点持有键 \"1 \"的数据，你会得到这样的响应。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1075
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 74\n"
"Content-Type: application/json\n"
"Date: Tue, 11 Jun 2019 19:16:31 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1084
#, no-wrap
msgid ""
"{\n"
"  \"avg\": 11.9,\n"
"  \"count\": 259,\n"
"  \"max\": 50.0,\n"
"  \"min\": -30.1,\n"
"  \"stationId\": 1,\n"
"  \"stationName\": \"Hamburg\"\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1087
#, fuzzy
msgid "Otherwise, the service will send a redirect:"
msgstr "否则，该服务将发送一个重定向。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1095
#, no-wrap
msgid ""
"HTTP/1.1 303 See Other\n"
"Connection: keep-alive\n"
"Content-Length: 0\n"
"Date: Tue, 18 Jun 2019 20:01:03 GMT\n"
"Location: http://1eb39af8d587:8080/weather-stations/data/1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1098
#, fuzzy
msgid "You can also have _httpie_ automatically follow the redirect by passing the `--follow option`:"
msgstr "你也可以通过传递 `--follow option` ，让 _httpie_ 自动跟随重定向。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1102
#, no-wrap
msgid "http --follow 2af13fe516a9:8080/weather-stations/data/1\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1104
#, fuzzy, no-wrap
msgid "Running Natively"
msgstr "自然运行"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1108
#, fuzzy
msgid "The Quarkus extension for Kafka Streams enables the execution of stream processing applications natively via GraalVM without further configuration."
msgstr "用于Kafka流的Quarkus扩展能够通过GraalVM本地执行流处理应用程序，而无需进一步配置。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1111
#, fuzzy
msgid "To run both the `producer` and `aggregator` applications in native mode, the Maven builds can be executed using `-Dnative`:"
msgstr "为了在本地模式下运行 `producer` 和 `aggregator` 应用程序，可以使用 `-Dnative` 执行 Maven 构建。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1116
#, no-wrap
msgid ""
"./mvnw clean package -f producer/pom.xml -Dnative -Dnative-image.container-runtime=docker\n"
"./mvnw clean package -f aggregator/pom.xml -Dnative -Dnative-image.container-runtime=docker\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1119
#, fuzzy
msgid "Now create an environment variable named `QUARKUS_MODE` and with value set to \"native\":"
msgstr "现在创建一个名为 `QUARKUS_MODE` 的环境变量，其值设置为 \"native\"。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1123
#, no-wrap
msgid "export QUARKUS_MODE=native\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1128
#, fuzzy
msgid "This is used by the Docker Compose file to use the correct `Dockerfile` when building the `producer` and `aggregator` images.  The Kafka Streams application can work with less than 50 MB RSS in native mode.  To do so, add the `Xmx` option to the program invocation in `aggregator/src/main/docker/Dockerfile.native`:"
msgstr "这被Docker Compose文件用来在构建 `producer` 和 `aggregator` 镜像时使用正确的 `Dockerfile` 。Kafka Streams应用程序可以在本地模式下使用小于50MB的RSS。要做到这一点，在 `aggregator/src/main/docker/Dockerfile.native` 中的程序调用中添加 `Xmx` 选项。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1132
#, no-wrap
msgid "CMD [\"./application\", \"-Dquarkus.http.host=0.0.0.0\", \"-Xmx32m\"]\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1136
#, fuzzy
msgid "Now start Docker Compose as described above (don't forget to rebuild the container images)."
msgstr "现在按上述方法启动Docker Compose（别忘了重建容器镜像）。"

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1137
#, fuzzy, no-wrap
msgid "Kafka Streams Health Checks"
msgstr "Kafka流的健康检查"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1140
#, fuzzy
msgid "If you are using the `quarkus-smallrye-health` extension, `quarkus-kafka-streams` will automatically add:"
msgstr "如果你使用的是 `quarkus-smallrye-health` ， `quarkus-kafka-streams` ，会自动添加。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1142
#, fuzzy
msgid "a readiness health check to validate that all topics declared in the `quarkus.kafka-streams.topics` property are created,"
msgstr "一个准备就绪的健康检查，以验证所有在 `quarkus.kafka-streams.topics` 属性中声明的主题都被创建。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1143
#, fuzzy
msgid "a liveness health check based on the Kafka Streams state."
msgstr "一个基于Kafka流状态的有效性健康检查。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1145
#, fuzzy
msgid "So when you access the `/q/health` endpoint of your application you will have information about the state of the Kafka Streams and the available and/or missing topics."
msgstr "因此，当你访问你的应用程序的 `/q/health` 端点时，你将获得关于Kafka流的状态以及可用和/或缺失的主题的信息。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1147
#, fuzzy
msgid "This is an example of when the status is `DOWN`:"
msgstr "这是在状态为 `DOWN` 的情况下的一个例子。"

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1150
#, no-wrap
msgid "curl -i http://aggregator:8080/q/health\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1154
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 454\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1175
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams state health check\",  <1>\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"state\": \"CREATED\"\n"
"            }\n"
"        },\n"
"        {\n"
"            \"name\": \"Kafka Streams topics health check\",  <2>\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"available_topics\": \"weather-stations,temperature-values\",\n"
"                \"missing_topics\": \"hygrometry-values\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1177
#, fuzzy
msgid "Liveness health check. Also available at `/q/health/live` endpoint."
msgstr "活性健康检查。也可在 `/q/health/live` 端点。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1178
#, fuzzy
msgid "Readiness health check. Also available at `/q/health/ready` endpoint."
msgstr "准备就绪的健康检查。也可在 `/q/health/ready` 端点。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1180
#, fuzzy
msgid "So as you can see, the status is `DOWN` as soon as one of the `quarkus.kafka-streams.topics` is missing or the Kafka Streams `state` is not `RUNNING`."
msgstr "所以你可以看到，只要其中一个 `quarkus.kafka-streams.topics` ，或者Kafka Streams `state` 没有 `RUNNING` ，状态就是 `DOWN` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1183
#, fuzzy
msgid "If no topics are available, the `available_topics` key will not be present in the `data` field of the `Kafka Streams topics health check`.  As well as if no topics are missing, the `missing_topics` key will not be present in the `data` field of the `Kafka Streams topics health check`."
msgstr "如果没有任何主题， `available_topics` 关键将不会出现在 `data` 领域的 `Kafka Streams topics health check` 。以及如果没有任何主题， `missing_topics` 关键将不会出现在 `data` 领域的 `Kafka Streams topics health check` 。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1185
#, fuzzy
msgid "You can of course disable the health check of the `quarkus-kafka-streams` extension by setting the `quarkus.kafka-streams.health.enabled` property to `false` in your `application.properties`."
msgstr "当然，你可以通过在你的 `application.properties` 中设置 `quarkus.kafka-streams.health.enabled` 属性为 `false` ，来禁用 `quarkus-kafka-streams` 扩展的健康检查。"

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1187
msgid "Obviously you can create your liveness and readiness probes based on the respective endpoints `/q/health/live` and `/q/health/ready`."
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:1188
#, no-wrap
msgid "Liveness health check"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1191
msgid "Here is an example of the liveness check:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1195
#, no-wrap
msgid "curl -i http://aggregator:8080/q/health/live\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1199
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 225\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1212
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams state health check\",\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"state\": \"CREATED\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1214
msgid "The `state` is coming from the `KafkaStreams.State` enum."
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:1215
#, no-wrap
msgid "Readiness health check"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1218
msgid "Here is an example of the readiness check:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1222
#, no-wrap
msgid "curl -i http://aggregator:8080/q/health/ready\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1226
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 265\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1239
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams topics health check\",\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"missing_topics\": \"weather-stations,temperature-values\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1241
#, no-wrap
msgid "Going Further"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1247
msgid "This guide has shown how you can build stream processing applications using Quarkus and the Kafka Streams APIs, both in JVM and native modes.  For running your KStreams application in production, you could also add health checks and metrics for the data pipeline.  Refer to the Quarkus guides on xref:micrometer.adoc[Micrometer], xref:smallrye-metrics.adoc[SmallRye Metrics], and xref:smallrye-health.adoc[SmallRye Health] to learn more."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1248
#, no-wrap
msgid "Configuration Reference"
msgstr "配置参考"
