# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-05-12 15:52+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_guides/kafka.adoc:6
#, fuzzy, no-wrap
msgid "Apache Kafka Reference Guide"
msgstr "Apache Kafka参考指南"

#. type: Plain text
#: upstream/_guides/kafka.adoc:16
#, fuzzy
msgid "This reference guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka."
msgstr "本参考指南展示了您的Quarkus应用程序如何利用SmallRye Reactive Messaging与Apache Kafka进行交互。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:17
#, fuzzy, no-wrap
msgid "Introduction"
msgstr "简介"

#. type: Plain text
#: upstream/_guides/kafka.adoc:22
#, fuzzy
msgid "https://kafka.apache.org[Apache Kafka] is a popular open-source distributed event streaming platform.  It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.  Similar to a message queue, or an enterprise messaging platform, it lets you:"
msgstr "link:https://kafka.apache.org[Apache Kafka] 是一个流行的开源分布式事件流平台。它通常用于高性能数据管道、流分析、数据集成和关键任务的应用。类似于消息队列，或企业消息平台，它可以让你。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:24
#, fuzzy, no-wrap
msgid "*publish* (write) and *subscribe* to (read) streams of events, called _records_.\n"
msgstr " *发布* （写）和 *订阅* （读）的事件流，称为 _记录_ 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:25
#, fuzzy, no-wrap
msgid "*store* streams of records durably and reliably inside _topics_.\n"
msgstr "在 _主题_ 内持久而可靠地 *存储* 记录流。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:26
#, fuzzy, no-wrap
msgid "*process* streams of records as they occur or retrospectively.\n"
msgstr "在记录发生时或回顾性地 *处理* 记录流。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:28
#, fuzzy
msgid "And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner."
msgstr "而所有这些功能都是以分布式、高度可扩展、弹性、容错和安全的方式提供。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:29
#, fuzzy, no-wrap
msgid "Quarkus Extension for Apache Kafka"
msgstr "奎尔库斯对Apache Kafka的扩展"

#. type: Plain text
#: upstream/_guides/kafka.adoc:33
#, fuzzy
msgid "Quarkus provides support for Apache Kafka through https://smallrye.io/smallrye-reactive-messaging/[SmallRye Reactive Messaging] framework.  Based on Eclipse MicroProfile Reactive Messaging specification 2.0, it proposes a flexible programming model bridging CDI and event-driven."
msgstr "Quarkus通过 link:https://smallrye.io/smallrye-reactive-messaging/[SmallRye Reactive Messaging] 框架为Apache Kafka提供支持。基于Eclipse MicroProfile Reactive Messaging规范2.0，它提出了一个连接CDI和事件驱动的灵活编程模型。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:38
#, fuzzy
msgid "This guide provides an in-depth look on Apache Kafka and SmallRye Reactive Messaging framework.  For a quick start take a look at xref:kafka-reactive-getting-started.adoc[Getting Started to SmallRye Reactive Messaging with Apache Kafka]."
msgstr "本指南深入介绍了Apache Kafka和SmallRye Reactive Messaging框架。要想快速入门，请看《 link:kafka-reactive-getting-started.html[使用Apache Kafka的SmallRye Reactive Messaging入门] 》。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:41
#, fuzzy
msgid "You can add the `smallrye-reactive-messaging-kafka` extensions to your project by running the following command in your project base directory:"
msgstr "你可以通过在你的项目基础目录下运行以下命令将 `smallrye-reactive-messaging-kafka` 扩展添加到你的项目中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:46
#, fuzzy
msgid "This will add the following to your build file:"
msgstr "这将在你的构建文件中添加以下内容。"

#. type: Block title
#: upstream/_guides/kafka.adoc:48 upstream/_guides/kafka.adoc:1324
#: upstream/_guides/kafka.adoc:1573 upstream/_guides/kafka.adoc:1641
#, fuzzy, no-wrap
msgid "pom.xml"
msgstr "pom.xml"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:54
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Block title
#: upstream/_guides/kafka.adoc:57 upstream/_guides/kafka.adoc:1333
#: upstream/_guides/kafka.adoc:1582 upstream/_guides/kafka.adoc:1651
#, fuzzy, no-wrap
msgid "build.gradle"
msgstr "build.gradle"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:60
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-smallrye-reactive-messaging-kafka\")\n"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:65
#, fuzzy
msgid "The extension includes `kafka-clients` version 3.1.0 as a transitive dependency and is compatible with Kafka brokers version 2.x."
msgstr "该扩展包括 `kafka-clients` 3.1.0版本作为一个横向依赖，并与Kafka经纪人2.x版本兼容。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:67
#, fuzzy, no-wrap
msgid "Configuring Smallrye Kafka Connector"
msgstr "配置Smallrye Kafka连接器"

#. type: Plain text
#: upstream/_guides/kafka.adoc:70
#, fuzzy
msgid "Because Smallrye Reactive Messaging framework supports different messaging backends like Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., it employs a generic vocabulary:"
msgstr "因为Smallrye Reactive Messaging框架支持不同的消息传递后端，如Apache Kafka、AMQP、Apache Camel、JMS、MQTT等，所以它采用了一个通用词汇表。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:72
#, fuzzy
msgid "Applications send and receive *messages*. A message wraps a _payload_ and can be extended with some _metadata_. With the Kafka connector, a _message_ corresponds to a Kafka _record_."
msgstr "应用程序发送和接收 *消息* 。一条消息包裹着一个 _有效载荷_ ，并可以用一些 _元数据_ 进行扩展。通过Kafka连接器，一条 _消息_ 对应于一条Kafka _记录_ 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:73
#, fuzzy
msgid "Messages transit on *channels*. Application components connect to channels to publish and consume messages. The Kafka connector maps _channels_ to Kafka _topics_."
msgstr "信息在 *通道* 上传输。应用程序组件连接到通道来发布和消费消息。Kafka连接器将 _通道_ 映射到Kafka _主题_ 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:74
#, fuzzy
msgid "Channels are connected to message backends using *connectors*. Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named `smallrye-kafka`."
msgstr "通道使用 *连接器* 连接到消息后端。连接器被配置为将传入的消息映射到一个特定的通道（由应用程序消耗），并收集发送到特定通道的传出消息。每个连接器都是专门用于特定的消息传递技术。例如，处理Kafka的连接器被命名为 `smallrye-kafka` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:76
#, fuzzy
msgid "A minimal configuration for the Kafka connector with an incoming channel looks like the following:"
msgstr "一个带有传入通道的Kafka连接器的最小配置看起来像下面这样。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:81
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.incoming.prices.connector=smallrye-kafka <2>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:85
#, fuzzy
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.incoming.$channel.bootstrap.servers` property.  In dev mode and when running tests, <<kafka-dev-services>> automatically starts a Kafka broker.  When not provided this property defaults to `localhost:9092`."
msgstr "配置生产配置文件的经纪人位置。你可以使用 `mp.messaging.incoming.$channel.bootstrap.servers` 属性在全局或每个通道配置它。在开发模式和运行测试时， link:#kafka-dev-services[[kafka-dev-services]] 自动启动一个Kafka代理。如果没有提供这个属性，则默认为 `localhost:9092` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:86
#, fuzzy
msgid "Configure the connector to manage the prices channel. By default the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr "配置连接器来管理价格通道。默认情况下，主题名称与频道名称相同。你可以配置主题属性来覆盖它。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:88
#, fuzzy
msgid "The `%prod` prefix indicates that the property is only used when the application runs in prod mode (so not in dev or test). Refer to the xref:config-reference.adoc#profiles[Profile documentation] for further details."
msgstr " `%prod` 前缀表示该属性只在应用程序运行在prod模式下时使用（所以不是在dev或test）。更多细节请参考 link:config-reference.html#profiles[配置文件文档] 。"

#. type: Block title
#: upstream/_guides/kafka.adoc:90
#, fuzzy, no-wrap
msgid "Connector auto-attachment"
msgstr "连接器自动连接"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:95
#, fuzzy
msgid "If you have a single connector on your classpath, you can omit the `connector` attribute configuration.  Quarkus automatically associates _orphan_ channels to the (unique) connector found on the classpath.  _Orphans_ channels are outgoing channels without a downstream consumer or incoming channels without an upstream producer."
msgstr "如果你的classpath上只有一个连接器，你可以省略 `connector` 属性配置。Quarkus会自动将 _孤儿_ 通道与classpath上找到的（唯一的）连接器联系起来。 _孤_ 儿通道是没有下游消费者的出站通道或没有上游生产者的入站通道。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:97
#, fuzzy
msgid "This auto-attachment can be disabled using:"
msgstr "可以用以下方法禁用这种自动附加功能。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:101
#, no-wrap
msgid "quarkus.reactive-messaging.auto-connector-attachment=false\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka.adoc:104
#, fuzzy, no-wrap
msgid "Receiving messages from Kafka"
msgstr "接收来自Kafka的消息"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:107
#, fuzzy
msgid "Continuing from the previous minimal configuration, your Quarkus application can receive message payload directly:"
msgstr "继续之前的最小配置，你的Quarkus应用程序可以直接接收消息有效载荷。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:111 upstream/_guides/kafka.adoc:2104
#: upstream/_guides/kafka.adoc:2184
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:113 upstream/_guides/kafka.adoc:1019
#: upstream/_guides/kafka.adoc:1066 upstream/_guides/kafka.adoc:1089
#: upstream/_guides/kafka.adoc:1230 upstream/_guides/kafka.adoc:2182
#, no-wrap
msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:116
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:121
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    public void consume(double price) {\n"
"        // process your price.\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:123 upstream/_guides/kafka.adoc:270
#: upstream/_guides/kafka.adoc:584 upstream/_guides/kafka.adoc:610
#: upstream/_guides/kafka.adoc:738 upstream/_guides/kafka.adoc:1079
#: upstream/_guides/kafka.adoc:1107 upstream/_guides/kafka.adoc:1191
#: upstream/_guides/kafka.adoc:1249 upstream/_guides/kafka.adoc:1636
#: upstream/_guides/kafka.adoc:1716 upstream/_guides/kafka.adoc:2092
#: upstream/_guides/kafka.adoc:2172 upstream/_guides/kafka.adoc:2200
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:126
#, fuzzy
msgid "There are several other ways your application can consume incoming messages:"
msgstr "还有其他几种方式，你的应用程序可以消费传入的消息。"

#. type: Block title
#: upstream/_guides/kafka.adoc:127
#, fuzzy, no-wrap
msgid "Message"
msgstr "留言"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:139
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consume(Message<Double> msg) {\n"
"    // access record metadata\n"
"    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();\n"
"    // process the message payload.\n"
"    double price = msg.getPayload();\n"
"    // Acknowledge the incoming message (commit the offset)\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:143
#, fuzzy
msgid "The `Message` type lets the consuming method access the incoming message metadata and handle the acknowledgment manually.  We'll explore different acknowledgment strategies in <<commit-strategies>>."
msgstr " `Message` 类型让消费方法访问传入的消息元数据并手动处理确认。我们将在 link:#commit-strategies[[commit-strategies]] 中探讨不同的确认策略。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:145
#, fuzzy
msgid "If you want to access the Kafka record objects directly, use:"
msgstr "如果你想直接访问Kafka记录对象，请使用。"

#. type: Block title
#: upstream/_guides/kafka.adoc:146
#, fuzzy, no-wrap
msgid "ConsumerRecord"
msgstr "消费者记录"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:157
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(ConsumerRecord<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"    String topic = record.topic();\n"
"    int partition = record.partition();\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:161
#, fuzzy
msgid "`ConsumerRecord` is provided by the underlying Kafka client and can be injected directly to the consumer method.  Another simpler approach consists in using `Record`:"
msgstr " `ConsumerRecord` 是由底层Kafka客户端提供的，可以直接注入到消费者方法中。另一种更简单的方法是使用 。 `Record` "

#. type: Block title
#: upstream/_guides/kafka.adoc:162
#, fuzzy, no-wrap
msgid "Record"
msgstr "记录"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:170
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(Record<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:173
#, fuzzy
msgid "`Record` is a simple wrapper around key and payload of the incoming Kafka record."
msgstr " `Record` 是一个简单的包装器，围绕着传入的Kafka记录的密钥和有效载荷。"

#. type: Block title
#: upstream/_guides/kafka.adoc:174
#, fuzzy, no-wrap
msgid "@Channel"
msgstr "@通道"

#. type: Plain text
#: upstream/_guides/kafka.adoc:177
#, fuzzy
msgid "Alternatively, your application can inject a `Multi` in your bean and subscribe to its events as the following example:"
msgstr "另外，你的应用程序可以在你的Bean中注入一个 `Multi` ，并像下面的例子那样订阅它的事件。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:182
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.annotations.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:189
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import org.jboss.resteasy.reactive.RestStreamElementType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:192 upstream/_guides/kafka.adoc:819
#: upstream/_guides/kafka.adoc:864 upstream/_guides/kafka.adoc:900
#, no-wrap
msgid ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:196
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"prices\")\n"
"    Multi<Double> prices;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:205
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/prices\")\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
"    @RestStreamElementType(MediaType.TEXT_PLAIN)\n"
"    public Multi<Double> stream() {\n"
"        return prices;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:209
#, fuzzy
msgid "This is a good example of how to integrate a Kafka consumer with another downstream, in this example exposing it as a Server-Sent Events endpoint."
msgstr "这是一个很好的例子，说明如何将Kafka消费者与另一个下游整合起来，在这个例子中，将其暴露为一个服务器发送的事件端点。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:215
#, fuzzy
msgid "When consuming messages with `@Channel`, the application code is responsible for the subscription.  In the example above, the RESTEasy Reactive endpoint handles that for you."
msgstr "当用 `@Channel` 消费消息时，应用程序代码要负责订阅。在上面的例子中，RESTEasy Reactive端点为你处理这个问题。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:218
#, fuzzy
msgid "Following types can be injected as channels:"
msgstr "以下类型可以作为通道被注入。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:222
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Double> streamOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:224
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Message<Double>> streamOfMessages;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:226
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Double> publisherOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:228
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Message<Double>> publisherOfMessages;\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:233
#, fuzzy
msgid "As with the previous `Message` example, if your injected channel receives payloads (`Multi<T>`), it acknowledges the message automatically, and support multiple subscribers.  If you injected channel receives Message (`Multi<Message<T>>`), you will be responsible for the acknowledgment and broadcasting.  We will explore sending broadcast messages in <<broadcasting-messages-on-multiple-consumers>>."
msgstr "就像前面 `Message` 的例子一样，如果你的注入通道收到了有效载荷( `Multi<T>` )，它会自动确认消息，并支持多个订阅者。如果你的注入通道收到消息( `Multi<Message<T>>` )，你将负责确认和广播。我们将在 link:#broadcasting-messages-on-multiple-consumers[[broadcast-messages-on-multiple-consumers]] 中探讨发送广播消息。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:238
#, fuzzy
msgid "Injecting `@Channel(\"prices\")` or having `@Incoming(\"prices\")` does not automatically configure the application to consume messages from Kafka.  You need to configure an inbound connector with `mp.messaging.incoming.prices\\...` or have an `@Outgoing(\"prices\")` method somewhere in your application (in which case, `prices` will be an in-memory channel)."
msgstr "注入 `@Channel(\"prices\")` 或拥有 `@Incoming(\"prices\")` 并不能自动配置应用程序从Kafka消费消息。你需要用 `mp.messaging.incoming.prices...` 配置一个入站连接器，或者在你的应用程序的某个地方有一个 `@Outgoing(\"prices\")` 方法（在这种情况下， `prices` 将是一个内存通道）。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:241
#, fuzzy, no-wrap
msgid "Blocking processing"
msgstr "阻断处理"

#. type: Plain text
#: upstream/_guides/kafka.adoc:247
#, fuzzy
msgid "Reactive Messaging invokes your method on an I/O thread.  See the xref:quarkus-reactive-architecture.adoc[Quarkus Reactive Architecture documentation] for further details on this topic.  But, you often need to combine Reactive Messaging with blocking processing such as database interactions.  For this, you need to use the `@Blocking` annotation indicating that the processing is _blocking_ and should not be run on the caller thread."
msgstr "Reactive Messaging在一个I/O线程上调用你的方法。关于这个话题的更多细节，请看 link:quarkus-reactive-architecture.html[Quarkus Reactive Architecture文档] 。但是，你经常需要将反应式消息传递与阻塞式处理结合起来，比如数据库交互。为此，你需要使用 `@Blocking` 注释，表明处理是 _阻塞的_ ，不应该在调用者线程上运行。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:249
#, fuzzy
msgid "For example, The following code illustrates how you can store incoming payloads to a database using Hibernate with Panache:"
msgstr "例如，下面的代码说明了如何使用Hibernate与Panache将传入的有效载荷存储到数据库。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:254
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Blocking;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:257 upstream/_guides/kafka.adoc:2102
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:260
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:268
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    @Transactional\n"
"    public void store(int priceInUsd) {\n"
"        Price price = new Price();\n"
"        price.value = priceInUsd;\n"
"        price.persist();\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:273
#, fuzzy
msgid "The complete example is available in the `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[directory]."
msgstr "完整的例子可以在 `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[目录]。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:277
#, fuzzy
msgid "There are 2 `@Blocking` annotations:"
msgstr "有2个 `@Blocking` 注释。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:279
#, fuzzy
msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgstr " `io.smallrye.reactive.messaging.annotations.Blocking` "

#. type: delimited block =
#: upstream/_guides/kafka.adoc:280
#, fuzzy
msgid "`io.smallrye.common.annotation.Blocking`"
msgstr " `io.smallrye.common.annotation.Blocking` "

#. type: delimited block =
#: upstream/_guides/kafka.adoc:285
#, fuzzy
msgid "They have the same effect.  Thus, you can use both.  The first one provides more fine-grained tuning such as the worker pool to use and whether it preserves the order.  The second one, used also with other reactive features of Quarkus, uses the default worker pool and preserves the order."
msgstr "它们具有相同的效果。因此，你可以同时使用两者。第一个提供了更精细的调整，如使用的工作池和是否保留顺序。第二种，也用于Quarkus的其他反应式功能，使用默认的工作池并保留顺序。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:287
#, fuzzy
msgid "Detailed information on the usage of `@Blocking` annotation can be found in https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/advanced/blocking.html[SmallRye Reactive Messaging – Handling blocking execution]."
msgstr "关于使用 `@Blocking` 注释的详细信息，可以在 link:https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/advanced/blocking.html[SmallRye Reactive Messaging - Handling blocking execution中] 找到。"

#. type: Block title
#: upstream/_guides/kafka.adoc:290
#, fuzzy, no-wrap
msgid "@Transactional"
msgstr "@交易型"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:293
#, fuzzy
msgid "If your method is annotated with `@Transactional`, it will be considered _blocking_ automatically, even if the method is not annotated with `@Blocking`."
msgstr "如果你的方法被注解为 `@Transactional` ，它将被自动视为 _阻塞_ ，即使该方法没有被注解为 `@Blocking` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:295
#, fuzzy, no-wrap
msgid "Acknowledgment Strategies"
msgstr "鸣谢策略"

#. type: Plain text
#: upstream/_guides/kafka.adoc:303
#, fuzzy
msgid "All messages received by a consumer must be acknowledged.  In the absence of acknowledgment, the processing is considered in error.  If the consumer method receives a `Record` or a payload, the message will be acked on method return, also known as `Strategy.POST_PROCESSING`.  If the consumer method returns another reactive stream or `CompletionStage`, the message will be acked when the downstream message is acked.  You can override the default behavior to ack the message on arrival (`Strategy.PRE_PROCESSING`), or do not ack the message at all (`Strategy.NONE`) on the consumer method as in the following example:"
msgstr "消费者收到的所有信息都必须被确认。在没有确认的情况下，处理被认为是错误的。如果消费者方法收到一个 `Record` 或一个有效载荷，该消息将在方法返回时被acked，也被称为 `Strategy.POST_PROCESSING` 。如果消费者方法返回另一个反应式流或 `CompletionStage` ，当下游消息被acked时，消息将被acked。你可以覆盖默认行为，在消息到达时进行应答（ `Strategy.PRE_PROCESSING` ），或者在消费者方法中根本不应答消息（ `Strategy.NONE` ），如下例所示。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:311
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)\n"
"public void process(double price) {\n"
"    // process price\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:315
#, fuzzy
msgid "If the consumer method receives a `Message`, the acknowledgment strategy is `Strategy.MANUAL` and the consumer method is in charge of ack/nack the message."
msgstr "如果消费者方法收到一个 `Message` ，确认策略是 `Strategy.MANUAL` ，消费者方法负责对消息进行ack/nack。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:323
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> process(Message<Double> msg) {\n"
"    // process price\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:326
#, fuzzy
msgid "As mentioned above, the method can also override the acknowledgment strategy to `PRE_PROCESSING` or `NONE`."
msgstr "如上所述，该方法还可以将确认策略覆盖为 `PRE_PROCESSING` 或 `NONE` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:328
#, fuzzy, no-wrap
msgid "Commit Strategies"
msgstr "承诺战略"

#. type: Plain text
#: upstream/_guides/kafka.adoc:334
#, fuzzy
msgid "When a message produced from a Kafka record is acknowledged, the connector invokes a commit strategy.  These strategies decide when the consumer offset for a specific topic/partition is committed.  Committing an offset indicates that all previous records have been processed.  It is also the position where the application would restart the processing after a crash recovery or a restart."
msgstr "当一条由Kafka记录产生的消息被确认时，连接器会调用一个提交策略。这些策略决定了特定主题/分区的消费者偏移何时被提交。提交一个偏移量表明所有之前的记录已经被处理了。它也是应用程序在崩溃恢复或重启后重新开始处理的位置。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:337
#, fuzzy
msgid "Committing every offset has performance penalties as Kafka offset management can be slow.  However, not committing the offset often enough may lead to message duplication if the application crashes between two commits."
msgstr "由于Kafka的偏移量管理可能很慢，所以每次提交都会有性能上的损失。然而，如果应用程序在两次提交之间崩溃，不经常提交偏移量可能会导致消息的重复。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:339
#, fuzzy
msgid "The Kafka connector supports three strategies:"
msgstr "Kafka连接器支持三种策略。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:348
#, fuzzy
msgid "`throttled` keeps track of received messages and commits an offset of the latest acked message in sequence (meaning, all previous messages were also acked).  This strategy guarantees at-least-once delivery even if the channel performs asynchronous processing.  The connector tracks the received records and periodically (period specified by `auto.commit.interval.ms`, default: 5000 ms) commits the highest consecutive offset.  The connector will be marked as unhealthy if a message associated with a record is not acknowledged in `throttled.unprocessed-record-max-age.ms` (default: 60000 ms).  Indeed, this strategy cannot commit the offset as soon as a single record processing fails (see <<error-handling>> to configure what happens on failing processing).  If `throttled.unprocessed-record-max-age.ms` is set to less than or equal to `0`, it does not perform any health check verification.  Such a setting might lead to running out of memory if there are \"poison pill\" messages (that are never acked).  This strategy is the default if `enable.auto.commit` is not explicitly set to true."
msgstr " `throttled` 追踪收到的消息，并提交最新的被应答消息的偏移量（意思是，所有以前的消息也被应答了）。这种策略保证了至少一次的交付，即使通道执行异步处理。连接器跟踪收到的记录，并定期（周期由 ，默认：5000ms）提交最高的连续偏移。如果一个与记录相关的消息在 （默认：60000 ms）中没有被确认，连接器将被标记为不健康。事实上，这个策略不能在单条记录处理失败后立即提交偏移量（见 `auto.commit.interval.ms` `throttled.unprocessed-record-max-age.ms` link:#error-handling[[error-handling]] ，以配置处理失败时的情况）。如果 被设置为小于或等于 ，它就不执行任何健康检查验证。如果有 \"毒丸 \"信息（从未被接受），这样的设置可能会导致内存耗尽。如果 没有明确地设置为 \"true\"，这个策略是默认的。 `throttled.unprocessed-record-max-age.ms` `0` `enable.auto.commit` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:352
#, fuzzy
msgid "`latest` commits the record offset received by the Kafka consumer as soon as the associated message is acknowledged (if the offset is higher than the previously committed offset).  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous processing.  This strategy should not be used in high load environment, as offset commit is expensive. However, it reduces the risk of duplicates."
msgstr " `latest` 一旦相关的消息被确认，Kafka消费者就会提交所收到的记录偏移量（如果偏移量高于之前提交的偏移量）。如果通道在不执行任何异步处理的情况下处理消息，这种策略提供了至少一次的交付。这种策略不应该在高负载环境中使用，因为偏移量的提交很昂贵。然而，它减少了重复的风险。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:358
#, fuzzy
msgid "`ignore` performs no commit. This strategy is the default strategy when the consumer is explicitly configured with `enable.auto.commit` to true.  It delegates the offset commit to the underlying Kafka client.  When `enable.auto.commit` is `true` this strategy **DOES NOT** guarantee at-least-once delivery.  SmallRye Reactive Messaging processes records asynchronously, so offsets may be committed for records that have been polled but not yet processed.  In case of a failure, only records that were not committed yet will be re-processed."
msgstr " `ignore` 不执行提交。当消费者被明确配置为 ，该策略是默认策略。它将偏移提交委托给底层Kafka客户端。当 是 ，该策略 `enable.auto.commit` `enable.auto.commit` `true` *不* 保证至少一次的交付。SmallRye Reactive Messaging是异步处理记录的，所以偏移量可能被提交给已经被轮询但尚未处理的记录。在失败的情况下，只有尚未提交的记录才会被重新处理。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:363
#, fuzzy
msgid "The Kafka connector disables the Kafka auto commit when it is not explicitly enabled. This behavior differs from the traditional Kafka consumer.  If high throughput is important for you, and you are not limited by the downstream, we recommend to either:"
msgstr "当Kafka连接器没有明确启用时，它将禁用Kafka自动提交。这种行为与传统的Kafka消费者不同。如果高吞吐量对你来说很重要，而且你不受下游的限制，我们建议要么。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:365
#, fuzzy
msgid "use the `throttled` policy,"
msgstr "使用 `throttled` 政策。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:366
#, fuzzy
msgid "or set `enable.auto.commit` to true and annotate the consuming method with `@Acknowledgment(Acknowledgment.Strategy.NONE)`."
msgstr "或者将 `enable.auto.commit` 设置为true，并在消费方法中注解 `@Acknowledgment(Acknowledgment.Strategy.NONE)` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:369
#, fuzzy, no-wrap
msgid "Error Handling Strategies"
msgstr "错误处理策略"

#. type: Plain text
#: upstream/_guides/kafka.adoc:372
#, fuzzy
msgid "If a message produced from a Kafka record is nacked, a failure strategy is applied. The Kafka connector supports three strategies:"
msgstr "如果从Kafka记录中产生的消息被破解，就会应用一个失败策略。Kafka连接器支持三种策略。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:374
#, fuzzy
msgid "`fail`: fail the application, no more records will be processed (default strategy). The offset of the record that has not been processed correctly is not committed."
msgstr " `fail` ：应用程序失败，将不再处理更多的记录（默认策略）。未被正确处理的记录的偏移量不会被提交。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:375
#, fuzzy
msgid "`ignore`: the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed."
msgstr " `ignore` 纪录：失败被记录下来，但处理继续进行。没有被正确处理的记录的偏移量被提交。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:376
#, fuzzy
msgid "`dead-letter-queue`: the offset of the record that has not been processed correctly is committed, but the record is written to a Kafka dead letter topic."
msgstr " `dead-letter-queue` ：未被正确处理的记录的偏移量被提交，但该记录被写入Kafka死信主题。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:378
#, fuzzy
msgid "The strategy is selected using the `failure-strategy` attribute."
msgstr "该策略是使用 `failure-strategy` 属性选择的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:380
#, fuzzy
msgid "In the case of `dead-letter-queue`, you can configure the following attributes:"
msgstr "在 `dead-letter-queue` ，你可以配置以下属性。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:382
#, fuzzy
msgid "`dead-letter-queue.topic`: the topic to use to write the records not processed correctly, default is `dead-letter-topic-$channel`, with `$channel` being the name of the channel."
msgstr " `dead-letter-queue.topic` : 用来写入未正确处理的记录的主题，默认为 `dead-letter-topic-$channel` ， `$channel` 是通道的名称。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:383
#, fuzzy
msgid "`dead-letter-queue.key.serializer`: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer."
msgstr " `dead-letter-queue.key.serializer` 指用于在死信队列中写入记录键的序列化器。默认情况下，它从键的反序列化器推断出序列化器。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:384
#, fuzzy
msgid "`dead-letter-queue.value.serializer`: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer."
msgstr " `dead-letter-queue.value.serializer` :用于在死信队列中写入记录值的序列化器。默认情况下，它从值反序列化器中推断出序列化器。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:386
#, fuzzy
msgid "The record written on the dead letter queue contains a set of additional headers about the original record:"
msgstr "写在死信队列上的记录包含一组关于原始记录的附加标题。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:388
#, fuzzy, no-wrap
msgid "*dead-letter-reason*: the reason of the failure\n"
msgstr " *dead-letter-reason* ：失败的原因"

#. type: Plain text
#: upstream/_guides/kafka.adoc:389
#, fuzzy, no-wrap
msgid "*dead-letter-cause*: the cause of the failure if any\n"
msgstr " *dead-letter-cause* ：失败的原因（如果有）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:390
#, fuzzy, no-wrap
msgid "*dead-letter-topic*: the original topic of the record\n"
msgstr " *dead-letter-topic* ：记录的原始主题"

#. type: Plain text
#: upstream/_guides/kafka.adoc:391
#, fuzzy, no-wrap
msgid "*dead-letter-partition*: the original partition of the record (integer mapped to String)\n"
msgstr " *dead-letter-partition* ：记录的原始分区（整数映射为String）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:392
#, fuzzy, no-wrap
msgid "*dead-letter-offset*: the original offset of the record (long mapped to String)\n"
msgstr " *dead-letter-offset* ：记录的原始偏移量（长映射到String）。"

#. type: Title ====
#: upstream/_guides/kafka.adoc:393
#, fuzzy, no-wrap
msgid "Retrying processing"
msgstr "重试处理"

#. type: Plain text
#: upstream/_guides/kafka.adoc:396
#, fuzzy
msgid "You can combine Reactive Messaging with https://github.com/smallrye/smallrye-fault-tolerance[SmallRye Fault Tolerance], and retry processing if it failed:"
msgstr "你可以将反应式消息传递与 link:https://github.com/smallrye/smallrye-fault-tolerance[SmallRye容错] 结合起来，如果处理失败，可以重试。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:404
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"public void consume(String v) {\n"
"   // ... retry if this method throws an exception\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:407
#, fuzzy
msgid "You can configure the delay, the number of retries, the jitter, etc."
msgstr "你可以配置延迟、重试次数、抖动等。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:409
#, fuzzy
msgid "If your method returns a `Uni` or `CompletionStage`, you need to add the `@NonBlocking` annotation:"
msgstr "如果你的方法返回一个 `Uni` 或 `CompletionStage` ，你需要添加 `@NonBlocking` 注释。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:418
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"@NonBlocking\n"
"public Uni<String> consume(String v) {\n"
"   // ... retry if this method throws an exception or the returned Uni produce a failure\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:423
#, fuzzy
msgid "The `@NonBlocking` annotation is only required with SmallRye Fault Tolerance 5.1.0 and earlier.  Starting with SmallRye Fault Tolerance 5.2.0 (available since Quarkus 2.1.0.Final), it is not necessary.  See https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode[SmallRye Fault Tolerance documentation] for more information."
msgstr " `@NonBlocking` 注释仅在SmallRye Fault Tolerance 5.1.0及以前版本中需要。从SmallRye Fault Tolerance 5.2.0开始（从Quarkus 2.1.0.Final开始），它就不需要了。更多信息请参见 link:https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode[SmallRye Fault Tolerance文档] 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:427
#, fuzzy
msgid "The incoming messages are acknowledged only once the processing completes successfully.  So, it commits the offset after the successful processing.  If the processing still fails, even after all retries, the message is _nacked_ and the failure strategy is applied."
msgstr "传入的消息只有在处理成功完成后才会被确认。所以，它在处理成功后会提交偏移。如果处理仍然失败，甚至在所有的重试之后，消息就会被 _acked_ ，并应用失败策略。"

#. type: Title ====
#: upstream/_guides/kafka.adoc:428
#, fuzzy, no-wrap
msgid "Handling Deserialization Failures"
msgstr "处理反序列化失败"

#. type: Plain text
#: upstream/_guides/kafka.adoc:432
#, fuzzy
msgid "When a deserialization failure occurs, you can intercept it and provide a failure strategy.  To achieve this, you need to create a bean implementing `DeserializationFailureHandler<T>` interface:"
msgstr "当反序列化失败发生时，你可以拦截它并提供一个失败策略。为了实现这一点，你需要创建一个实现 `DeserializationFailureHandler<T>` 接口的bean。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:439
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"failure-retry\") // Set the name of the failure handler\n"
"public class MyDeserializationFailureHandler\n"
"    implements DeserializationFailureHandler<JsonObject> { // Specify the expected type\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:448
#, no-wrap
msgid ""
"    @Override\n"
"    public JsonObject decorateDeserialization(Uni<JsonObject> deserialization, String topic, boolean isKey,\n"
"            String deserializer, byte[] data, Headers headers) {\n"
"        return deserialization\n"
"                    .onFailure().retry().atMost(3)\n"
"                    .await().atMost(Duration.ofMillis(200));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:451
#, fuzzy
msgid "To use this failure handler, the bean must be exposed with the `@Identifier` qualifier and the connector configuration must specify the attribute `mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler` (for key or value deserializers)."
msgstr "要使用这个故障处理程序，Bean必须用 `@Identifier` 限定符来暴露，并且连接器配置必须指定属性 `mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler` （对于键或值反序列化器）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:454
#, fuzzy
msgid "The handler is called with details of the deserialization, including the action represented as `Uni<T>`.  On the deserialization `Uni` failure strategies like retry, providing a fallback value or applying timeout can be implemented."
msgstr "处理程序被调用，并提供反序列化的细节，包括以 `Uni<T>` 表示的动作。在反序列化 `Uni` ，可以实现重试、提供回退值或应用超时等失败策略。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:455
#, fuzzy, no-wrap
msgid "Consumer Groups"
msgstr "消费者团体"

#. type: Plain text
#: upstream/_guides/kafka.adoc:462
#, fuzzy
msgid "In Kafka, a consumer group is a set of consumers which cooperate to consume data from a topic.  A topic is divided into a set of partitions.  The partitions of a topic are assigned among the consumers in the group, effectively allowing to scale consumption throughput.  Note that each partition is assigned to a single consumer from a group.  However, a consumer can be assigned multiple partitions if the number of partitions is greater than the number of consumer in the group."
msgstr "在Kafka中，消费者组是一组消费者，他们合作消费来自一个主题的数据。一个主题被划分为一组分区。一个主题的分区在组内的消费者之间分配，有效地允许扩展消费吞吐量。请注意，每个分区被分配给一个组中的一个消费者。然而，如果分区的数量大于组中消费者的数量，一个消费者可以被分配多个分区。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:464
#, fuzzy
msgid "Let's explore briefly different producer/consumer patterns and how to implement them using Quarkus:"
msgstr "让我们简单探讨一下不同的生产者/消费者模式以及如何使用Quarkus实现它们。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:466
#, fuzzy, no-wrap
msgid "*Single consumer thread inside a consumer group*\n"
msgstr " *消费者组内的单一消费者线程* "

#. type: Plain text
#: upstream/_guides/kafka.adoc:470
#, fuzzy
msgid "This is the default behavior of an application subscribing to a Kafka topic: Each Kafka connector will create a single consumer thread and place it inside a single consumer group.  Consumer group id defaults to the application name as set by the `quarkus.application.name` configuration property.  It can also be set using the `kafka.group.id` property."
msgstr "这是一个应用程序订阅Kafka主题的默认行为。每个Kafka连接器将创建一个消费者线程，并将其置于一个消费者组内。消费者组id默认为 `quarkus.application.name` 配置属性所设定的应用程序名称。它也可以使用 `kafka.group.id` 属性来设置。"

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_guides/kafka.adoc:471 upstream/_guides/kafka.adoc:479
#: upstream/_guides/kafka.adoc:486 upstream/_guides/kafka.adoc:494
#, fuzzy, no-wrap
msgid "Architecture,"
msgstr "建筑。"

#. type: Target for macro image
#: upstream/_guides/kafka.adoc:471
#, no-wrap
msgid "kafka-one-app-one-consumer.png"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:474
#, fuzzy, no-wrap
msgid "*Multiple consumer threads inside a consumer group*\n"
msgstr " *一个消费者组内有多个消费者线程* "

#. type: Plain text
#: upstream/_guides/kafka.adoc:478
#, fuzzy
msgid "For a given application instance, the number of consumers inside the consumer group can be configured using `mp.messaging.incoming.$channel.partitions` property.  The partitions of the subscribed topic will be divided among the consumer threads.  Note that if the `partitions` value exceed the number of partitions of the topic, some consumer threads won't be assigned any partitions."
msgstr "对于一个给定的应用程序实例，消费者组内的消费者数量可以使用 `mp.messaging.incoming.$channel.partitions` 属性进行配置。订阅的主题的分区将被分配给消费者线程。请注意，如果 `partitions` 值超过主题的分区数量，一些消费者线程将不会被分配任何分区。"

#. type: Target for macro image
#: upstream/_guides/kafka.adoc:479
#, no-wrap
msgid "kafka-one-app-two-consumers.png"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:482
#, fuzzy, no-wrap
msgid "*Multiple consumer applications inside a consumer group*\n"
msgstr " *一个消费者组内的多个消费者应用程序* "

#. type: Plain text
#: upstream/_guides/kafka.adoc:485
#, fuzzy
msgid "Similar to the previous example, multiple instances of an application can subscribe to a single consumer group, configured via `mp.messaging.incoming.$channel.group.id` property, or left default to the application name.  This in turn will divide partitions of the topic among application instances."
msgstr "与前面的例子类似，一个应用程序的多个实例可以订阅一个消费者组，通过 `mp.messaging.incoming.$channel.group.id` 属性进行配置，或者默认为应用程序名称。这又会在应用程序实例之间划分出主题的分区。"

#. type: Target for macro image
#: upstream/_guides/kafka.adoc:486
#, no-wrap
msgid "kafka-two-app-one-consumer-group.png"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:489
#, fuzzy, no-wrap
msgid "*Pub/Sub: Multiple consumer groups subscribed to a topic*\n"
msgstr " *发布/发布：多个消费者群体订阅了一个主题* "

#. type: Plain text
#: upstream/_guides/kafka.adoc:493
#, fuzzy
msgid "Lastly different applications can subscribe independently to same topics using different *consumer group ids*.  For example, messages published to a topic called _orders_ can be consumed independently on two consumer applications, one with `mp.messaging.incoming.orders.group.id=invoicing` and second with `mp.messaging.incoming.orders.group.id=shipping`.  Different consumer groups can thus scale independently according to the message consumption requirements."
msgstr "最后，不同的应用程序可以使用不同的 *消费者组ID* 独立订阅同一主题。例如，发布在一个名为 _订单_ 的主题上的消息可以在两个消费者应用程序上独立消费，一个是 `mp.messaging.incoming.orders.group.id=invoicing` ，第二个是 `mp.messaging.incoming.orders.group.id=shipping` 。因此，不同的消费者组可以根据消息消费的要求独立扩展。"

#. type: Target for macro image
#: upstream/_guides/kafka.adoc:494
#, no-wrap
msgid "kafka-two-app-two-consumer-groups.png"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:502
#, fuzzy
msgid "A common business requirement is to consume and process Kafka records in order.  The Kafka broker preserves order of records inside a partition and not inside a topic.  Therefore it is important to think about how records are partitioned inside a topic.  The default partitioner uses record key hash to compute the partition for a record, or when the key is not defined, chooses a partition randomly per batch or records."
msgstr "一个常见的业务需求是按顺序消费和处理Kafka记录。Kafka代理保留了分区内记录的顺序，而不是主题内记录的顺序。因此，考虑记录在主题内如何分区是很重要的。默认的分区器使用记录键哈希来计算记录的分区，或者当键没有被定义时，会在每个批次或记录中随机选择一个分区。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:505
#, fuzzy
msgid "During normal operation, a Kafka consumer preserves the order of records inside each partition assigned to it.  Smallrye Reactive Messaging keeps this order for processing, unless `@Blocking(ordered = false)` is used (see <<blocking-processing>>)."
msgstr "在正常操作中，Kafka消费者会保留分配给它的每个分区里面的记录的顺序。Smallrye Reactive Messaging保持这个顺序进行处理，除非使用 `@Blocking(ordered = false)` （见 link:#blocking-processing[[blocking-processing]] ）。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:507
#, fuzzy
msgid "Note that due to consumer rebalances, Kafka consumers only guarantee at-least-once processing of single records, meaning that uncommitted records _can_ be processed again by consumers."
msgstr "请注意，由于消费者的再平衡，Kafka消费者只保证对单一记录的至少一次处理，这意味着未承诺的记录 _可以_ 被消费者再次处理。"

#. type: Title ====
#: upstream/_guides/kafka.adoc:509
#, fuzzy, no-wrap
msgid "Consumer Rebalance Listener"
msgstr "消费者再平衡听证会"

#. type: Plain text
#: upstream/_guides/kafka.adoc:516
#, fuzzy
msgid "Inside a consumer group, as new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.  This is known as rebalancing the group.  To handle offset commit and assigned partitions yourself, you can provide a consumer rebalance listener.  To achieve this, implement the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` interface and expose it as a CDI bean with the `@Idenfier` qualifier.  A common use case is to store offset in a separate data store to implement exactly-once semantic, or starting the processing at a specific offset."
msgstr "在一个消费者组内，随着新组员的到来和老组员的离开，分区被重新分配，以便每个组员都能得到相应的分区份额。这就是所谓的重新平衡组。为了自己处理偏移提交和分配分区，你可以提供一个消费者重新平衡监听器。为了实现这一点，请实现 `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` 接口，并将其作为CDI bean与 `@Idenfier` 修饰语公开。一个常见的用例是将偏移量存储在一个单独的数据存储中，以实现完全一次的语义，或者在一个特定的偏移量开始处理。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:520
#, fuzzy
msgid "The listener is invoked every time the consumer topic/partition assignment changes.  For example, when the application starts, it invokes the `partitionsAssigned` callback with the initial set of topics/partitions associated with the consumer.  If, later, this set changes, it calls the `partitionsRevoked` and `partitionsAssigned` callbacks again, so you can implement custom logic."
msgstr "每次消费者的主题/分区分配发生变化时，监听器就会被调用。例如，当应用程序启动时，它用与消费者相关的初始主题/分区集合调用 `partitionsAssigned` 回调。如果后来这个集合改变了，它会再次调用 `partitionsRevoked` 和 `partitionsAssigned` 回调，所以你可以实现自定义逻辑。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:523
#, fuzzy
msgid "Note that the rebalance listener methods are called from the Kafka polling thread and **will** block the caller thread until completion.  That’s because the rebalance protocol has synchronization barriers, and using asynchronous code in a rebalance listener may be executed after the synchronization barrier."
msgstr "请注意，rebalance监听器方法是从Kafka轮询线程中调用的，并且 *会* 阻塞调用者线程，直到完成。这是因为再平衡协议有同步障碍，而在再平衡监听器中使用异步代码可能会在同步障碍之后执行。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:525
#, fuzzy
msgid "When topics/partitions are assigned or revoked from a consumer, it pauses the message delivery and resumes once the rebalance completes."
msgstr "当主题/分区被分配或从消费者那里撤销时，它会暂停消息传递，一旦重新平衡完成就会恢复。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:529
#, fuzzy
msgid "If the rebalance listener handles offset commit on behalf of the user (using the `NONE` commit strategy), the rebalance listener must commit the offset synchronously in the partitionsRevoked callback.  We also recommend applying the same logic when the application stops."
msgstr "如果再平衡监听器代表用户处理偏移量提交（使用 `NONE` 提交策略），再平衡监听器必须在partitionRevoked回调中同步提交偏移量。我们也建议在应用程序停止时应用同样的逻辑。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:531
#, fuzzy
msgid "Unlike the `ConsumerRebalanceListener` from Apache Kafka, the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` methods pass the Kafka Consumer and the set of topics/partitions."
msgstr "与Apache Kafka的 `ConsumerRebalanceListener` 不同， `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` 方法传递Kafka消费者和主题/分区集合。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:535
#, fuzzy
msgid "In the following example we set-up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).  First we need to provide a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` and is annotated with `io.smallrye.common.annotation.Identifier`.  We then must configure our inbound connector to use this bean."
msgstr "在下面的例子中，我们设置了一个消费者，它总是在最多10分钟前（或偏移量0）的消息上启动。首先，我们需要提供一个实现了 `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` 并被注解为 `io.smallrye.common.annotation.Identifier` 的bean。然后我们必须配置我们的入站连接器来使用这个Bean。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:539 upstream/_guides/kafka.adoc:589
#, no-wrap
msgid "package inbound;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:545
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;\n"
"import org.apache.kafka.clients.consumer.Consumer;\n"
"import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n"
"import org.apache.kafka.clients.consumer.TopicPartition;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:551
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.Collection;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
"import java.util.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:555
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"rebalanced-example.rebalancer\")\n"
"public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:557
#, no-wrap
msgid "    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:569
#, no-wrap
msgid ""
"    /**\n"
"     * When receiving a list of partitions, will search for the earliest offset within 10 minutes\n"
"     * and seek the consumer to it.\n"
"     *\n"
"     * @param consumer   underlying consumer\n"
"     * @param partitions set of assigned topic partitions\n"
"     */\n"
"    @Override\n"
"    public void onPartitionsAssigned(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {\n"
"        long now = System.currentTimeMillis();\n"
"        long shouldStartAt = now - 600_000L; //10 minute ago\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:582
#, no-wrap
msgid ""
"        Map<TopicPartition, Long> request = new HashMap<>();\n"
"        for (TopicPartition partition : partitions) {\n"
"            LOGGER.info(\"Assigned \" + partition);\n"
"            request.put(partition, shouldStartAt);\n"
"        }\n"
"        Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(request);\n"
"        for (Map.Entry<TopicPartition, OffsetAndTimestamp> position : offsets.entrySet()) {\n"
"            long target = position.getValue() == null ? 0L : position.getValue().offset();\n"
"            LOGGER.info(\"Seeking position \" + target + \" for \" + position.getKey());\n"
"            consumer.seek(position.getKey(), target);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:593
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;\n"
"import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:597
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.concurrent.CompletableFuture;\n"
"import java.util.concurrent.CompletionStage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:600
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaRebalancedConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:608
#, no-wrap
msgid ""
"    @Incoming(\"rebalanced-example\")\n"
"    @Acknowledgment(Acknowledgment.Strategy.NONE)\n"
"    public CompletionStage<Void> consume(IncomingKafkaRecord<Integer, String> message) {\n"
"        // We don't need to ACK messages because in this example,\n"
"        // we set offset during consumer rebalance\n"
"        return CompletableFuture.completedFuture(null);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:614
#, fuzzy
msgid "To configure the inbound connector to use the provided listener, we either set the consumer rebalance listener’s identifier: `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer`"
msgstr "为了配置入站连接器使用所提供的监听器，我们要么设置消费者再平衡监听器的标识符。 `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:616
#, fuzzy
msgid "Or have the listener’s name be the same as the group id:"
msgstr "或者让听众的名字与组的ID相同。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:618
#, fuzzy
msgid "`mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer`"
msgstr " `mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:620
#, fuzzy
msgid "Setting the consumer rebalance listener’s name takes precedence over using the group id."
msgstr "设置消费者再平衡监听器的名称优先于使用组的ID。"

#. type: Title ====
#: upstream/_guides/kafka.adoc:621
#, fuzzy, no-wrap
msgid "Using unique consumer groups"
msgstr "利用独特的消费者群体"

#. type: Plain text
#: upstream/_guides/kafka.adoc:624
#, fuzzy
msgid "If you want to process all the records from a topic (from its beginning), you need:"
msgstr "如果你想处理一个主题的所有记录（从其开始），你需要。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:626
#, fuzzy
msgid "to set `auto.offset.reset = earliest`"
msgstr "来设置 `auto.offset.reset = earliest` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:627
#, fuzzy
msgid "assign your consumer to a consumer group not used by any other application."
msgstr "将你的消费者分配到一个不被任何其他应用程序使用的消费者组。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:630
#, fuzzy
msgid "Quarkus generates a UUID that changes between two executions (including in dev mode).  So, you are sure no other consumer uses it, and you receive a new unique group id every time your application starts."
msgstr "Quarkus生成的UUID在两次执行之间会发生变化（包括在dev模式下）。因此，你可以确定没有其他消费者使用它，而且每次你的应用程序启动时都会收到一个新的唯一的组ID。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:632
#, fuzzy
msgid "You can use that generated UUID as the consumer group as follows:"
msgstr "你可以使用该生成的UUID作为消费者组，如下所示。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:637
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.auto.offset.reset=earliest\n"
"mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:640
#, fuzzy
msgid "If the `group.id` attribute is not set, it defaults the `quarkus.application.name` configuration property."
msgstr "如果没有设置 `group.id` 属性，则默认为 `quarkus.application.name` 配置属性。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:641
#, fuzzy, no-wrap
msgid "Receiving Kafka Records in Batches"
msgstr "分批接收Kafka记录"

#. type: Plain text
#: upstream/_guides/kafka.adoc:645
#, fuzzy
msgid "By default, incoming methods receive each Kafka record individually.  Under the hood, Kafka consumer clients poll the broker constantly and receive records in batches, presented inside the `ConsumerRecords` container."
msgstr "默认情况下，传入方法会单独接收每条Kafka记录。在引擎盖下，Kafka消费者客户端不断地轮询代理，并分批接收记录，呈现在 `ConsumerRecords` 容器中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:647
#, fuzzy
msgid "In *batch* mode, your application can receive all the records returned by the consumer *poll* in one go."
msgstr "在 *批处理* 模式下，你的应用程序可以一次性接收消费者 *投票* 返回的所有记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:649
#, fuzzy
msgid "To achieve this you need to specify a compatible container type to receive all the data:"
msgstr "为了实现这一点，你需要指定一个兼容的容器类型来接收所有数据。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:658
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(List<Double> prices) {\n"
"    for (double price : prices) {\n"
"        // process price\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:662
#, fuzzy
msgid "The incoming method can also receive `Message<List<Payload>>`, `KafkaRecordBatch<Key, Payload>` `ConsumerRecords<Key, Payload>` types.  They give access to record details such as offset or timestamp:"
msgstr "传入方法也可以接收 `Message<List<Payload>>` , `KafkaRecordBatch<Key, Payload>` `ConsumerRecords<Key, Payload>` 类型。他们可以访问记录的细节，如偏移量或时间戳。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:675
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consumeMessage(KafkaRecordBatch<String, Double> records) {\n"
"    for (KafkaRecord<String, Double> record : records) {\n"
"        String payload = record.getPayload();\n"
"        String topic = record.getTopic();\n"
"        // process messages\n"
"    }\n"
"    // ack will commit the latest offsets (per partition) of the batch.\n"
"    return records.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:680
#, fuzzy
msgid "Note that the successful processing of the incoming record batch will commit the latest offsets for each partition received inside the batch.  The configured commit strategy will be applied for these records only."
msgstr "注意，成功处理传入的记录批，将提交批内收到的每个分区的最新偏移量。配置的提交策略将只应用于这些记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:682
#, fuzzy
msgid "Conversely, if the processing throws an exception, all messages are _nacked_, applying the failure strategy for all the records inside the batch."
msgstr "反之，如果处理过程抛出一个异常，所有的消息都会被 _剔除_ ，对批处理中的所有记录采用失败策略。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:687
#, fuzzy
msgid "Quarkus autodetects batch types for incoming channels and sets batch configuration automatically.  You can configure batch mode explicitly with `mp.messaging.incoming.$channel.batch` property."
msgstr "Quarkus自动检测传入通道的批处理类型并自动设置批处理配置。你可以用 `mp.messaging.incoming.$channel.batch` 属性明确地配置批处理模式。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:689
#, fuzzy, no-wrap
msgid "Sending messages to Kafka"
msgstr "向Kafka发送消息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:692
#, fuzzy
msgid "Configuration for the Kafka connector outgoing channels is similar to that of incoming:"
msgstr "Kafka连接器传出通道的配置与传入通道的配置类似。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:698
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.outgoing.prices-out.connector=smallrye-kafka <2>\n"
"mp.messaging.outgoing.prices-out.topic=prices <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:703
#, fuzzy
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.outgoing.$channel.bootstrap.servers` property.  In dev mode and when running tests, <<kafka-dev-services>> automatically starts a Kafka broker.  When not provided, this property defaults to `localhost:9092`."
msgstr "配置生产配置文件的经纪人位置。你可以使用 `mp.messaging.outgoing.$channel.bootstrap.servers` 属性在全局或每个通道配置它。在开发模式和运行测试时， link:#kafka-dev-services[[kafka-dev-services]] 自动启动一个Kafka代理。如果没有提供，这个属性默认为 `localhost:9092` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:704
#, fuzzy
msgid "Configure the connector to manage the `prices-out` channel."
msgstr "配置连接器以管理 `prices-out` 通道。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:705
#, fuzzy
msgid "By default, the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr "默认情况下，主题名称与频道名称相同。你可以配置主题属性来覆盖它。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:710
#, fuzzy
msgid "Inside application configuration, channel names are unique.  Therefore, if you'd like to configure an incoming and outgoing channel on the same topic, you will need to name channels differently (like in the examples of this guide, `mp.messaging.incoming.prices` and `mp.messaging.outgoing.prices-out`)."
msgstr "在应用配置里面，通道名称是唯一的。因此，如果你想在同一个主题上配置一个传入和传出的通道，你需要以不同的方式命名通道（比如本指南的例子， `mp.messaging.incoming.prices` 和 `mp.messaging.outgoing.prices-out` ）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:714
#, fuzzy
msgid "Then, your application can generate messages and publish them to the `prices-out` channel.  It can use `double` payloads as in the following snippet:"
msgstr "然后，你的应用程序可以生成消息并将其发布到 `prices-out` 频道。它可以使用 `double` 的有效载荷，如下面的片段。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:719
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:723
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.time.Duration;\n"
"import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:726
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaPriceProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:728 upstream/_guides/kafka.adoc:1029
#, no-wrap
msgid "    private final Random random = new Random();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:736
#, no-wrap
msgid ""
"    @Outgoing(\"prices-out\")\n"
"    public Multi<Double> generate() {\n"
"        // Build an infinite stream of random prices\n"
"        // It emits a price every second\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> random.nextDouble());\n"
"    }\n"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:743
#, fuzzy
msgid "You should not call methods annotated with `@Incoming` and/or `@Outgoing` directly from your code. They are invoked by the framework. Having user code invoking them would not have the expected outcome."
msgstr "你不应该从你的代码中直接调用用 `@Incoming` 和/或 `@Outgoing` 注释的方法。它们是由框架调用的。让用户代码调用它们，不会有预期的结果。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:747
#, fuzzy
msgid "Note that the `generate` method returns a `Multi<Double>`, which implements the Reactive Streams `Publisher` interface.  This publisher will be used by the framework to generate messages and send them to the configured Kafka topic."
msgstr "请注意， `generate` 方法返回一个 `Multi<Double>` ，它实现了Reactive Streams `Publisher` 接口。这个发布器将被框架用来生成消息，并将其发送到配置的Kafka主题。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:749
#, fuzzy
msgid "Instead of returning a payload, you can return a `io.smallrye.reactive.messaging.kafka.Record` to send key/value pairs:"
msgstr "你可以返回一个 `io.smallrye.reactive.messaging.kafka.Record` ，而不是返回一个有效载荷，以发送键/值对。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:757
#, no-wrap
msgid ""
"@Outgoing(\"out\")\n"
"public Multi<Record<String, Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"        .map(x -> Record.of(\"my-key\", random.nextDouble()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:760
#, fuzzy
msgid "Payload can be wrapped inside `org.eclipse.microprofile.reactive.messaging.Message` to have more control on the written records:"
msgstr "有效载荷可以被包裹在 `org.eclipse.microprofile.reactive.messaging.Message` ，以便对书面记录有更多的控制。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:773
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Message<Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> Message.of(random.nextDouble())\n"
"                    .addMetadata(OutgoingKafkaRecordMetadata.<String>builder()\n"
"                            .withKey(\"my-key\")\n"
"                            .withTopic(\"my-key-prices\")\n"
"                            .withHeaders(new RecordHeaders().add(\"my-header\", \"value\".getBytes()))\n"
"                            .build()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:778
#, fuzzy
msgid "`OutgoingKafkaRecordMetadata` allows to set metadata attributes of the Kafka record, such as `key`, `topic`, `partition` or `timestamp`.  One use case is to dynamically select the destination topic of a message.  In this case, instead of configuring the topic inside your application configuration file, you need to use the outgoing metadata to set the name of the topic."
msgstr " `OutgoingKafkaRecordMetadata` 允许设置Kafka记录的元数据属性，如 , , 或 。一个用例是动态地选择消息的目标主题。在这种情况下，你需要使用出站元数据来设置主题的名称，而不是在你的应用程序配置文件中配置主题。 `key` `topic` `partition` `timestamp` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:781
#, fuzzy
msgid "Other than method signatures returning a Reactive Stream `Publisher` (`Multi` being an implementation of `Publisher`), outgoing method can also return single message.  In this case the producer will use this method as generator to create an infinite stream."
msgstr "除了返回Reactive Stream `Publisher` ( `Multi` 是 `Publisher` 的实现)的方法签名外，出站方法也可以返回单个消息。在这种情况下，生产者将使用这个方法作为生成器来创建一个无限的流。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:785
#, no-wrap
msgid "@Outgoing(\"prices-out\") T generate(); // T excluding void\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:787
#, no-wrap
msgid "@Outgoing(\"prices-out\") Message<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:789
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:791
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<Message<T>> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:793
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:795
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<Message<T>> generate();\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka.adoc:797
#, fuzzy, no-wrap
msgid "Sending messages with @Emitter"
msgstr "用@Emitter发送消息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:800
#, fuzzy
msgid "Sometimes, you need to have an imperative way of sending messages."
msgstr "有时，你需要有一种势在必行的方式来发送消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:803
#, fuzzy
msgid "For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint.  In this case, you cannot use `@Outgoing` because your method has parameters."
msgstr "例如，如果你需要在REST端点内收到一个POST请求时向一个流发送一个消息。在这种情况下，你不能使用 `@Outgoing` ，因为你的方法有参数。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:805
#, fuzzy
msgid "For this, you can use an `Emitter`."
msgstr "为此，你可以使用一个 `Emitter` 。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:810 upstream/_guides/kafka.adoc:2002
#: upstream/_guides/kafka.adoc:2050 upstream/_guides/kafka.adoc:2267
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:816 upstream/_guides/kafka.adoc:861
#: upstream/_guides/kafka.adoc:895
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:823
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:830
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        CompletionStage<Void> ack = priceEmitter.send(price);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:833
#, fuzzy
msgid "Sending a payload returns a `CompletionStage`, completed when the message is acked. If the message transmission fails, the `CompletionStage` is completed exceptionally with the reason of the nack."
msgstr "发送一个有效载荷返回一个 `CompletionStage` ，在消息被acked时完成。如果消息传输失败， `CompletionStage` ，例外地完成，并说明被拒绝的原因。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:837
#, fuzzy
msgid "The `Emitter` configuration is done the same way as the other stream configuration used by `@Incoming` and `@Outgoing`."
msgstr " `Emitter` 的配置方式与 `@Incoming` 和 `@Outgoing` 使用的其他流配置相同。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:846
#, fuzzy
msgid "Using the `Emitter` you are sending messages from your imperative code to reactive messaging.  These messages are stored in a queue until they are sent.  If the Kafka producer client can't keep up with messages trying to be sent over to Kafka, this queue can become a memory hog and you may even run out of memory.  You can use `@OnOverflow` to configure back-pressure strategy.  It lets you configure the size of the queue (default is 256) and the strategy to apply when the buffer size is reached. Available strategies are `DROP`, `LATEST`, `FAIL`, `BUFFER`, `UNBOUNDED_BUFFER` and `NONE`."
msgstr "使用 `Emitter` ，你正在从你的指令性代码中发送消息到反应性消息。这些消息被存储在一个队列中，直到它们被发送。如果Kafka生产者客户端不能跟上试图发送到Kafka的消息，这个队列就会成为一个内存占用者，你甚至会耗尽内存。你可以使用 `@OnOverflow` 来配置背压策略。它可以让你配置队列的大小（默认是256）和达到缓冲区大小时要应用的策略。可用的策略有 `DROP` , `LATEST` , `FAIL` , `BUFFER` , `UNBOUNDED_BUFFER` 和 `NONE` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:849
#, fuzzy
msgid "With the `Emitter` API, you can also encapsulate the outgoing payload inside `Message<T>`. As with the previous examples, `Message` lets you handle the ack/nack cases differently."
msgstr "通过 `Emitter` API，你也可以将传出的有效载荷封装在 `Message<T>` 。与前面的例子一样， `Message` 让你以不同的方式处理 ack/nack 情况。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:855
#, no-wrap
msgid ""
"import java.util.concurrent.CompletableFuture;\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:866
#, no-wrap
msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:881
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(Message.of(price)\n"
"            .withAck(() -> {\n"
"                // Called when the message is acked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            })\n"
"            .withNack(throwable -> {\n"
"                // Called when the message is nacked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            }));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:885
#, fuzzy
msgid "If you prefer using Reactive Stream APIs, you can use `MutinyEmitter` that will return `Uni<Void>` from the `send` method.  You can therefore use Mutiny APIs for handling downstream messages and errors."
msgstr "如果你喜欢使用Reactive Stream APIs，你可以使用 `MutinyEmitter` ，它将从 `send` 方法返回 `Uni<Void>` 。因此，你可以使用Mutiny APIs来处理下游的信息和错误。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:889 upstream/_guides/kafka.adoc:2304
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:897
#, no-wrap
msgid "import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:904
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    MutinyEmitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:913
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public Uni<String> addPrice(Double price) {\n"
"        return quoteRequestEmitter.send(price)\n"
"                .map(x -> \"ok\")\n"
"                .onFailure().recoverWithItem(\"ko\");\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:917
#, fuzzy
msgid "It is also possible to block on sending the event to the emitter with the `sendAndAwait` method.  It will only return from the method when the event is acked or nacked by the receiver."
msgstr "也可以用 `sendAndAwait` 方法阻断向发射器发送事件的过程。只有当事件被接收者接受或拒绝时，它才会从该方法返回。"

#. type: Block title
#: upstream/_guides/kafka.adoc:919
#, fuzzy, no-wrap
msgid "Deprecation"
msgstr "撤消"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:922
#, fuzzy
msgid "The `io.smallrye.reactive.messaging.annotations.Emitter`, `io.smallrye.reactive.messaging.annotations.Channel` and `io.smallrye.reactive.messaging.annotations.OnOverflow` classes are now deprecated and replaced by:"
msgstr " `io.smallrye.reactive.messaging.annotations.Emitter` , `io.smallrye.reactive.messaging.annotations.Channel` 和 `io.smallrye.reactive.messaging.annotations.OnOverflow` 类现在已被废弃，并被替换为。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:924
#, fuzzy
msgid "`org.eclipse.microprofile.reactive.messaging.Emitter`"
msgstr " `org.eclipse.microprofile.reactive.messaging.Emitter` "

#. type: delimited block =
#: upstream/_guides/kafka.adoc:925
#, fuzzy
msgid "`org.eclipse.microprofile.reactive.messaging.Channel`"
msgstr " `org.eclipse.microprofile.reactive.messaging.Channel` "

#. type: delimited block =
#: upstream/_guides/kafka.adoc:926
#, fuzzy
msgid "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"
msgstr " `org.eclipse.microprofile.reactive.messaging.OnOverflow` "

#. type: delimited block =
#: upstream/_guides/kafka.adoc:928
#, fuzzy
msgid "The new `Emitter.send` method returns a `CompletionStage` completed when the produced message is acknowledged."
msgstr "新的 `Emitter.send` 方法在产生的消息被确认时返回一个 `CompletionStage` 完成。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:931
#, fuzzy
msgid "More information on how to use `Emitter` can be found in https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/emitter/emitter.html#_emitter_and_channel[SmallRye Reactive Messaging – Emitters and Channels]"
msgstr "关于如何使用 `Emitter` ，可在 link:https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/emitter/emitter.html#_emitter_and_channel[SmallRye Reactive Messaging - Emitters and Channels] 中找到更多信息。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:932
#, fuzzy, no-wrap
msgid "Write Acknowledgement"
msgstr "写确认书"

#. type: Plain text
#: upstream/_guides/kafka.adoc:936
#, fuzzy
msgid "When Kafka broker receives a record, its acknowledgement can take time depending on the configuration.  Also, it stores in-memory the records that cannot be written."
msgstr "当Kafka代理收到一条记录时，它的确认可能需要时间，这取决于配置。此外，它还会在内存中存储不能写入的记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:939
#, fuzzy
msgid "By default, the connector does wait for Kafka to acknowledge the record to continue the processing (acknowledging the received Message).  You can disable this by setting the `waitForWriteCompletion` attribute to `false`."
msgstr "默认情况下，连接器会等待Kafka确认记录以继续处理（确认收到的Message）。你可以通过将 `waitForWriteCompletion` 属性设置为 `false` 来禁用这个功能。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:941
#, fuzzy
msgid "Note that the `acks` attribute has a huge impact on the record acknowledgement."
msgstr "请注意， `acks` 属性对记录的确认有巨大影响。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:943
#, fuzzy
msgid "If a record cannot be written, the message is nacked."
msgstr "如果不能写入记录，信息就会被剔除。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:944
#, fuzzy, no-wrap
msgid "Backpressure"
msgstr "背压"

#. type: Plain text
#: upstream/_guides/kafka.adoc:948
#, fuzzy
msgid "The Kafka outbound connector handles back-pressure, monitoring the number of in-flight messages waiting to be written to the Kafka broker.  The number of in-flight messages is configured using the `max-inflight-messages` attribute and defaults to 1024."
msgstr "Kafka出站连接器处理背压，监测等待写入Kafka代理的飞行中的消息数量。飞行中的消息的数量是通过 `max-inflight-messages` 属性配置的，默认为1024。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:953
#, fuzzy
msgid "The connector only sends that amount of messages concurrently.  No other messages will be sent until at least one in-flight message gets acknowledged by the broker.  Then, the connector writes a new message to Kafka when one of the broker’s in-flight messages get acknowledged.  Be sure to configure Kafka’s `batch.size` and `linger.ms` accordingly."
msgstr "连接器只同时发送该数量的消息。在至少有一个飞行中的消息被经纪人确认之前，不会有其他消息被发送。然后，当代理的一个飞行中的消息得到确认时，连接器会向Kafka写一个新的消息。请确保相应地配置Kafka的 `batch.size` 和 `linger.ms` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:956
#, fuzzy
msgid "You can also remove the limit of in-flight messages by setting `max-inflight-messages` to `0`.  However, note that the Kafka producer may block if the number of requests reaches `max.in.flight.requests.per.connection`."
msgstr "你也可以通过将 `max-inflight-messages` 设置为 `0` 来移除飞行中消息的限制。然而，请注意，如果请求的数量达到 `max.in.flight.requests.per.connection` ，Kafka生产者可能会阻塞。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:957
#, fuzzy, no-wrap
msgid "Retrying message dispatch"
msgstr "重试信息调度"

#. type: Plain text
#: upstream/_guides/kafka.adoc:962
#, fuzzy
msgid "When the Kafka producer receives an error from the server, if it is a transient, recoverable error, the client will retry sending the batch of messages.  This behavior is controlled by `retries` and `retry.backoff.ms` parameters.  In addition to this, SmallRye Reactive Messaging will retry individual messages on recoverable errors, depending on the `retries` and `delivery.timeout.ms` parameters."
msgstr "当Kafka生产者收到来自服务器的错误时，如果它是一个短暂的、可恢复的错误，客户端将重试发送这批消息。这种行为是由 `retries` 和 `retry.backoff.ms` 参数控制的。除此之外，SmallRye Reactive Messaging还会在可恢复的错误中重试单个消息，这取决于 `retries` 和 `delivery.timeout.ms` 参数。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:965
#, fuzzy
msgid "Note that while having retries in a reliable system is a best practice, the `max.in.flight.requests.per.connection` parameter defaults to `5`, meaning that the order of the messages is not guaranteed.  If the message order is a must for your use case, setting `max.in.flight.requests.per.connection` to `1` will make sure a single batch of messages is sent at a time, in the expense of limiting the throughput of the producer."
msgstr "请注意，虽然在一个可靠的系统中拥有重试是一个最好的做法，但 `max.in.flight.requests.per.connection` 参数默认为 `5` ，这意味着消息的顺序不被保证。如果消息的顺序对你的用例来说是必须的，将 `max.in.flight.requests.per.connection` 设置为 `1` ，将确保一次只发送一批消息，代价是限制生产商的吞吐量。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:967
#, fuzzy
msgid "For applying retry mechanism on processing errors, see the section on <<retrying-processing>>."
msgstr "关于对处理错误应用重试机制，请参见 link:#retrying-processing[[重试-处理]] 一节。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:968
#, fuzzy, no-wrap
msgid "Handling Serialization Failures"
msgstr "处理序列化失败"

#. type: Plain text
#: upstream/_guides/kafka.adoc:972
#, fuzzy
msgid "For Kafka producer client serialization failures are not recoverable, thus the message dispatch is not retried. In these cases you may need to apply a failure strategy for the serializer.  To achieve this, you need to create a bean implementing `SerializationFailureHandler<T>` interface:"
msgstr "对于Kafka生产者客户端的序列化失败是不可恢复的，因此消息调度不会被重试。在这些情况下，你可能需要为序列化器应用一个失败策略。为了实现这一点，你需要创建一个实现 `SerializationFailureHandler<T>` 接口的bean。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:979
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"failure-fallback\") // Set the name of the failure handler\n"
"public class MySerializationFailureHandler\n"
"    implements SerializationFailureHandler<JsonObject> { // Specify the expected type\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:988
#, no-wrap
msgid ""
"    @Override\n"
"    public byte[] decorateSerialization(Uni<byte[]> serialization, String topic, boolean isKey,\n"
"        String serializer, Object data, Headers headers) {\n"
"        return serialization\n"
"                    .onFailure().retry().atMost(3)\n"
"                    .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:991
#, fuzzy
msgid "To use this failure handler, the bean must be exposed with the `@Identifier` qualifier and the connector configuration must specify the attribute `mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler` (for key or value serializers)."
msgstr "要使用这个故障处理程序，Bean必须用 `@Identifier` 限定符来暴露，并且连接器配置必须指定属性 `mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler` （对于键或值序列化器）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:994
#, fuzzy
msgid "The handler is called with details of the serialization, including the action represented as `Uni<byte[]>`.  Note that the method must await on the result and return the serialized byte array."
msgstr "处理程序被调用，并提供序列化的细节，包括以 `Uni<byte[]>` 表示的动作。注意，该方法必须对结果进行等待，并返回序列化的字节数组。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:995
#, fuzzy, no-wrap
msgid "In-memory channels"
msgstr "记忆中的通道"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1000
#, fuzzy
msgid "In some use cases, it is convenient to use the messaging patterns to transfer messages inside the same application.  When you don't connect a channel to a messaging backend like Kafka, everything happens in-memory, and the streams are created by chaining methods together.  Each chain is still a reactive stream and enforces the back-pressure protocol."
msgstr "在一些用例中，使用消息传递模式在同一个应用程序内传输消息是很方便的。当你不把通道连接到像Kafka这样的消息传递后端时，一切都发生在内存中，流是通过把方法链在一起创建的。每个链仍然是一个反应式流，并执行背压协议。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1004
#, fuzzy
msgid "The framework verifies that the producer/consumer chain is complete, meaning that if the application writes messages into an in-memory channel (using a method with only `@Outgoing`, or an `Emitter`), it must also consume the messages from within the application (using a method with only `@Incoming` or using an unmanaged stream)."
msgstr "该框架验证生产者/消费者链是否完整，这意味着如果应用程序将消息写入内存通道（使用只有 `@Outgoing` ，或 `Emitter` 的方法），它也必须从应用程序内部消费消息（使用只有 `@Incoming` ，或使用非管理流的方法）。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1006
#, fuzzy, no-wrap
msgid "Broadcasting messages on multiple consumers"
msgstr "在多个消费者身上广播信息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1011
#, fuzzy
msgid "By default, a channel can be linked to a single consumer, using `@Incoming` method or `@Channel` reactive stream.  At application startup, channels are verified to form a chain of consumers and producers with single consumer and producer.  You can override this behavior by setting `mp.messaging.$channel.broadcast=true` on a channel."
msgstr "默认情况下，一个通道可以被链接到一个单一的消费者，使用 `@Incoming` 方法或 `@Channel` 反应式流。在应用程序启动时，通道会被验证，以形成一个由单个消费者和生产者组成的消费者和生产者链。你可以通过在通道上设置 `mp.messaging.$channel.broadcast=true` 来覆盖这种行为。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1013
#, fuzzy
msgid "In case of in-memory channels, `@Broadcast` annotation can be used on the `@Outgoing` method. For example,"
msgstr "在内存通道的情况下， `@Broadcast` 注释可以用在 `@Outgoing` 方法上。比如说。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1017
#, no-wrap
msgid "import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1022 upstream/_guides/kafka.adoc:1064
#: upstream/_guides/kafka.adoc:1092
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1024
#, no-wrap
msgid "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1027
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MultipleConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1035
#, no-wrap
msgid ""
"    @Outgoing(\"in-memory-channel\")\n"
"    @Broadcast\n"
"    double generate() {\n"
"        return random.nextDouble();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1040
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    void consumeAndLog(double price) {\n"
"        System.out.println(price);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1047
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    @Outgoing(\"prices2\")\n"
"    double consumeAndSend(double price) {\n"
"        return price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1053
#, fuzzy
msgid "Reciprocally, multiple producers on the same channel can be merged by setting `mp.messaging.incoming.$channel.merge=true`.  On the `@Incoming` methods, you can control how multiple channels are merged using the `@Merge` annotation."
msgstr "相应地，同一通道上的多个生产者可以通过设置 `mp.messaging.incoming.$channel.merge=true` 来进行合并。在 `@Incoming` 方法上，你可以使用 `@Merge` 注释来控制多个通道的合并方式。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1055
#, fuzzy, no-wrap
msgid "Processing Messages"
msgstr "处理信息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1059
#, fuzzy
msgid "Applications streaming data often need to consume some events from a topic, process them and publish the result to a different topic.  A processor method can be simply implemented using both the `@Incoming` and `@Outgoing` annotations:"
msgstr "流式数据的应用常常需要从一个主题中消费一些事件，处理它们并将结果发布到不同的主题中。一个处理器方法可以简单地使用 `@Incoming` 和 `@Outgoing` 注解来实现。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1069 upstream/_guides/kafka.adoc:1097
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1071 upstream/_guides/kafka.adoc:1099
#: upstream/_guides/kafka.adoc:1239
#, no-wrap
msgid "    private static final double CONVERSION_RATE = 0.88;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1077
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public double process(double price) {\n"
"        return price * CONVERSION_RATE;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1083
#, fuzzy
msgid "The parameter of the `process` method is the incoming message payload, whereas the return value will be used as the outgoing message payload.  Previously mentioned signatures for parameter and return types are also supported, such as `Message<T>`, `Record<K, V>`, etc."
msgstr " `process` 方法的参数是传入的消息有效载荷，而返回值将被用作传出的消息有效载荷。之前提到的参数和返回类型的签名也被支持，如 `Message<T>` ， `Record<K, V>` ，等等。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1085
#, fuzzy
msgid "You can apply asynchronous stream processing by consuming and returning reactive stream `Multi<T>` type:"
msgstr "你可以通过消耗和返回反应式流 `Multi<T>` 型来应用异步流处理。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1094
#, no-wrap
msgid "import io.smallrye.mutiny.Multi;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1105
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public Multi<Double> process(Multi<Integer> prices) {\n"
"        return prices.filter(p -> p > 100).map(p -> p * CONVERSION_RATE);\n"
"    }\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka.adoc:1109
#, fuzzy, no-wrap
msgid "Propagating Record Key"
msgstr "传播记录键"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1112
#, fuzzy
msgid "When processing messages, you can propagate incoming record key to the outgoing record."
msgstr "在处理信息时，你可以将传入的记录键传播到传出的记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1115
#, fuzzy
msgid "Enabled with `mp.messaging.outgoing.$channel.propagate-record-key=true` configuration, record key propagation produces the outgoing record with the same _key_ as the incoming record."
msgstr "在 `mp.messaging.outgoing.$channel.propagate-record-key=true` 配置中启用，记录密钥传播产生的传出记录与传入记录的 _密钥_ 相同。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1118
#, fuzzy
msgid "If the outgoing record already contains a _key_, it *won't be overridden* by the incoming record key.  If the incoming record does have a _null_ key, the `mp.messaging.outgoing.$channel.key` property is used."
msgstr "如果传出的记录已经包含一个 _键_ ，它 *不会* 被传入的记录键所覆盖。如果传入的记录确实有一个 _空键_ ，则使用 `mp.messaging.outgoing.$channel.key` 属性。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1120
#, fuzzy, no-wrap
msgid "Accessing Kafka clients directly"
msgstr "直接访问Kafka客户端"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1124
#, fuzzy
msgid "In rare cases, you may need to access the underlying Kafka clients.  `KafkaClientService` provides thread-safe access to `Producer` and `Consumer`."
msgstr "在少数情况下，你可能需要访问底层的Kafka客户端。 `KafkaClientService` ，提供线程安全的访问 `Producer` 和 `Consumer` 。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1130
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.event.Observes;\n"
"import javax.inject.Inject;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1132
#, no-wrap
msgid "import org.apache.kafka.clients.producer.ProducerRecord;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1137
#, no-wrap
msgid ""
"import io.quarkus.runtime.StartupEvent;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaClientService;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumer;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1140
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceSender {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1143
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaClientService clientService;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1150
#, no-wrap
msgid ""
"    void onStartup(@Observes StartupEvent startupEvent) {\n"
"        KafkaProducer<String, Double> producer = clientService.getProducer(\"generated-price\");\n"
"        producer.runOnSendingThread(client -> client.send(new ProducerRecord<>(\"prices\", 2.4)))\n"
"            .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1155
#, fuzzy
msgid "The `KafkaClientService` is an experimental API and can change in the future."
msgstr " `KafkaClientService` 是一个实验性的API，在未来可能会发生变化。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1158
#, fuzzy
msgid "You can also get the Kafka configuration injected to your application and create Kafka producer, consumer and admin clients directly:"
msgstr "你也可以把Kafka配置注入到你的应用程序中，并直接创建Kafka生产者、消费者和管理客户端。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1165
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import org.apache.kafka.clients.admin.AdminClient;\n"
"import org.apache.kafka.clients.admin.AdminClientConfig;\n"
"import org.apache.kafka.clients.admin.KafkaAdminClient;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1171
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.inject.Produces;\n"
"import javax.inject.Inject;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1174
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaClients {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1178
#, no-wrap
msgid ""
"    @Inject\n"
"    @Identifier(\"default-kafka-broker\")\n"
"    Map<String, Object> config;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1189
#, no-wrap
msgid ""
"    @Produces\n"
"    AdminClient getAdmin() {\n"
"        Map<String, Object> copy = new HashMap<>();\n"
"        for (Map.Entry<String, Object> entry : config.entrySet()) {\n"
"            if (AdminClientConfig.configNames().contains(entry.getKey())) {\n"
"                copy.put(entry.getKey(), entry.getValue());\n"
"            }\n"
"        }\n"
"        return KafkaAdminClient.create(copy);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1196
#, fuzzy
msgid "The `default-kafka-broker` configuration map contains all application properties prefixed with `kafka.` or `KAFKA_`.  For more configuration options check out <<kafka-configuration-resolution>>."
msgstr " `default-kafka-broker` 配置图包含所有以 `kafka.` 或 `KAFKA_` 为前缀的应用属性。关于更多的配置选项，请查看 link:#kafka-configuration-resolution[[kafka-configuration-resolution]] 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1198
#, fuzzy, no-wrap
msgid "JSON serialization"
msgstr "JSON序列化"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1201
#, fuzzy
msgid "Quarkus has built-in capabilities to deal with JSON Kafka messages."
msgstr "Quarkus有内置的能力来处理JSON Kafka消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1203
#, fuzzy
msgid "Imagine we have a `Fruit` data class as follows:"
msgstr "想象一下，我们有一个 `Fruit` 数据类，如下所示。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1207
#, no-wrap
msgid "public class Fruit {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1210
#, no-wrap
msgid ""
"    public String name;\n"
"    public int price;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1213
#, no-wrap
msgid ""
"    public Fruit() {\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1219
#, no-wrap
msgid ""
"    public Fruit(String name, int price) {\n"
"        this.name = name;\n"
"        this.price = price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1222
#, fuzzy
msgid "And we want to use it to receive messages from Kafka, make some price transformation, and send messages back to Kafka."
msgstr "而我们想用它来接收来自Kafka的消息，进行一些价格转换，并将消息送回Kafka。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1228
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1237
#, no-wrap
msgid ""
"/**\n"
"* A bean consuming data from the \"fruit-in\" channel and applying some price conversion.\n"
"* The result is pushed to the \"fruit-out\" channel.\n"
"*/\n"
"@ApplicationScoped\n"
"public class FruitProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1247
#, no-wrap
msgid ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1252
#, fuzzy
msgid "To do this, we will need to setup JSON serialization with Jackson or JSON-B."
msgstr "要做到这一点，我们需要用Jackson或JSON-B来设置JSON序列化。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1254
#, fuzzy
msgid "With JSON serialization correctly configured, you can also use `Publisher<Fruit>` and `Emitter<Fruit>`."
msgstr "在正确配置了JSON序列化后，你还可以使用 `Publisher<Fruit>` 和 `Emitter<Fruit>` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1256
#, fuzzy, no-wrap
msgid "Serializing via Jackson"
msgstr "通过杰克逊进行序列化"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1261
#, fuzzy
msgid "Quarkus has built-in support for JSON serialization and deserialization based on Jackson.  It will also <<serialization-generation, generate>> the serializer and deserializer for you, so you do not have to configure anything.  When generation is disabled, you can use the provided `ObjectMapperSerializer` and `ObjectMapperDeserializer` as explained below."
msgstr "Quarkus内置了对基于Jackson的JSON序列化和反序列化的支持。它也会为你 link:#serialization-generation[生成] 序列化器和反序列化器，所以你不需要配置任何东西。当生成器被禁用时，你可以使用提供的 `ObjectMapperSerializer` 和 `ObjectMapperDeserializer` ，如下所述。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1264
#, fuzzy
msgid "There is an existing `ObjectMapperSerializer` that can be used to serialize all data objects via Jackson.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr "有一个现有的 `ObjectMapperSerializer` ，可以用来通过Jackson来序列化所有的数据对象。如果你想使用 link:#serialization-autodetection[[serialization-autodetection]] ，你可以创建一个空的子类。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1268
#, fuzzy
msgid "By default, the `ObjectMapperSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr "默认情况下， `ObjectMapperSerializer` 将null序列化为 `\"null\"` 字符串，这可以通过设置Kafka配置属性 `json.serialize.null-as-null=true` ，将null序列化为 `null` 。这在使用压缩的主题时很方便，因为 `null` 被用作墓碑，以了解在压缩阶段删除哪些消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1271
#, fuzzy
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the `ObjectMapperDeserializer`."
msgstr "相应的反序列化器类需要被子类化。因此，让我们创建一个扩展了 `ObjectMapperDeserializer` 的 `FruitDeserializer` 。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1275 upstream/_guides/kafka.adoc:1306
#, no-wrap
msgid "package com.acme.fruit.jackson;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1277 upstream/_guides/kafka.adoc:2131
#: upstream/_guides/kafka.adoc:2217
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1283 upstream/_guides/kafka.adoc:2137
#: upstream/_guides/kafka.adoc:2223
#, no-wrap
msgid ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1286
#, fuzzy
msgid "Finally, configure your channels to use the Jackson serializer and deserializer."
msgstr "最后，配置你的通道以使用杰克逊的序列化器和反序列化器。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1292
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1296
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1300
#, fuzzy
msgid "Now, your Kafka messages will contain a Jackson serialized representation of your `Fruit` data object.  In this case, the `deserializer` configuration is not necessary as the <<serialization-autodetection>> is enabled by default."
msgstr "现在，你的Kafka消息将包含你的 `Fruit` 数据对象的杰克逊序列化表示。在这种情况下， `deserializer` 的配置是不必要的，因为 link:#serialization-autodetection[[serialization-autodetection]] 是默认启用的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1302
#, fuzzy
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a Jackson `TypeReference` denoted the generic collection used."
msgstr "如果你想反序列化一个水果列表，你需要创建一个反序列化器，用杰克逊 `TypeReference` 表示所用的通用集合。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1310
#, no-wrap
msgid ""
"import java.util.List;\n"
"import com.fasterxml.jackson.core.type.TypeReference;\n"
"import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1316
#, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends ObjectMapperDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        super(new TypeReference<List<Fruit>>() {});\n"
"    }\n"
"}\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka.adoc:1319
#, fuzzy, no-wrap
msgid "Serializing via JSON-B"
msgstr "通过JSON-B进行序列化"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1322
#, fuzzy
msgid "First, you need to include the `quarkus-jsonb` extension."
msgstr "首先，你需要包括 `quarkus-jsonb` 扩展。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1330
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jsonb</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1336
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-jsonb\")\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1340
#, fuzzy
msgid "There is an existing `JsonbSerializer` that can be used to serialize all data objects via JSON-B.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr "有一个现有的 `JsonbSerializer` ，可以用来通过JSON-B来序列化所有的数据对象。如果你想使用 link:#serialization-autodetection[[serialization-autodetection]] ，你可以创建一个空的子类。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1344
#, fuzzy
msgid "By default, the `JsonbSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr "默认情况下， `JsonbSerializer` 将null序列化为 `\"null\"` 字符串，这可以通过设置Kafka配置属性 `json.serialize.null-as-null=true` ，将null序列化为 `null` 。这在使用压缩的主题时很方便，因为 `null` 被用作墓碑，以了解在压缩阶段删除哪些消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1347
#, fuzzy
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the generic `JsonbDeserializer`."
msgstr "相应的反序列化器类需要被子类化。因此，让我们创建一个扩展了通用 `JsonbDeserializer` 的 `FruitDeserializer` 。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1351
#, no-wrap
msgid "package com.acme.fruit.jsonb;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1353
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1359
#, no-wrap
msgid ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1362
#, fuzzy
msgid "Finally, configure your channels to use the JSON-B serializer and deserializer."
msgstr "最后，配置你的通道以使用JSON-B串行器和反串行器。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1369
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1374
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1377
#, fuzzy
msgid "Now, your Kafka messages will contain a JSON-B serialized representation of your `Fruit` data object."
msgstr "现在，你的Kafka消息将包含你的 `Fruit` 数据对象的JSON-B序列化表示。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1379
#, fuzzy
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a `Type` denoted the generic collection used."
msgstr "如果你想反序列化一个水果列表，你需要创建一个反序列化器，用一个 `Type` 表示所用的通用集合。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1387
#, no-wrap
msgid ""
"package com.acme.fruit.jsonb;\n"
"import java.lang.reflect.Type;\n"
"import java.util.ArrayList;\n"
"import java.util.List;\n"
"import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1393
#, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends JsonbDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        super(new ArrayList<MyEntity>() {}.getClass().getGenericSuperclass());\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1397
#, fuzzy
msgid "If you don't want to create a deserializer for each data object, you can use the generic `io.vertx.kafka.client.serialization.JsonObjectDeserializer` that will deserialize to a `io.vertx.core.json.JsonObject`. The corresponding serializer can also be used: `io.vertx.kafka.client.serialization.JsonObjectSerializer`."
msgstr "如果你不想为每个数据对象创建一个反序列化器，你可以使用通用的 `io.vertx.kafka.client.serialization.JsonObjectDeserializer` ，它将反序列化为一个 `io.vertx.core.json.JsonObject` 。也可以使用相应的序列化器： `io.vertx.kafka.client.serialization.JsonObjectSerializer` 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1398
#, fuzzy, no-wrap
msgid "Avro Serialization"
msgstr "Avro序列化"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1401 upstream/_guides/kafka.adoc:1495
#, fuzzy
msgid "This is described in a dedicated guide: xref:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro]."
msgstr "这在一个专门的指南中有所描述。 link:kafka-schema-registry-avro.html[使用Apache Kafka与Schema Registry和Avro] 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1403
#, fuzzy, no-wrap
msgid "Serializer/deserializer autodetection"
msgstr "串行器/反串行器自动检测"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1407
#, fuzzy
msgid "When using SmallRye Reactive Messaging with Kafka (`io.quarkus:quarkus-smallrye-reactive-messaging-kafka`), Quarkus can often automatically detect the correct serializer and deserializer class.  This autodetection is based on declarations of `@Incoming` and `@Outgoing` methods, as well as injected ``@Channel``s."
msgstr "当使用SmallRye Reactive Messaging with Kafka ( `io.quarkus:quarkus-smallrye-reactive-messaging-kafka` )时，Quarkus通常可以自动检测正确的序列化器和反序列化器类。这种自动检测是基于 `@Incoming` 和 `@Outgoing` 方法的声明，以及注入的 `@Channel` s。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1409
#, fuzzy
msgid "For example, if you declare"
msgstr "例如，如果你声明"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1416
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Integer> generate() {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1419
#, fuzzy
msgid "and your configuration indicates that the `generated-price` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `IntegerSerializer`."
msgstr "而你的配置表明 `generated-price` 通道使用 `smallrye-kafka` 连接器，那么Quarkus会自动将 `value.serializer` 设置为Kafka的内置 `IntegerSerializer` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1421
#, fuzzy
msgid "Similarly, if you declare"
msgstr "同样地，如果你声明"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1428
#, no-wrap
msgid ""
"@Incoming(\"my-kafka-records\")\n"
"public void consume(KafkaRecord<Long, byte[]> record) {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1431
#, fuzzy
msgid "and your configuration indicates that the `my-kafka-records` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `key.deserializer` to Kafka's built-in `LongDeserializer`, as well as the `value.deserializer` to `ByteArrayDeserializer`."
msgstr "并且你的配置表明 `my-kafka-records` 通道使用了 `smallrye-kafka` 连接器，那么Quarkus会自动将 `key.deserializer` 设置为Kafka的内置 `LongDeserializer` ，以及 `value.deserializer` 设置为 `ByteArrayDeserializer` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1433
#, fuzzy
msgid "Finally, if you declare"
msgstr "最后，如果你宣布"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1439
#, no-wrap
msgid ""
"@Inject\n"
"@Channel(\"price-create\")\n"
"Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1442
#, fuzzy
msgid "and your configuration indicates that the `price-create` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `DoubleSerializer`."
msgstr "而你的配置表明 `price-create` 通道使用 `smallrye-kafka` 连接器，那么Quarkus将自动把 `value.serializer` 设置为Kafka的内置 `DoubleSerializer` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1444
#, fuzzy
msgid "The full set of types supported by the serializer/deserializer autodetection is:"
msgstr "串行器/反串行器自动检测所支持的全部类型是：。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1446
#, fuzzy
msgid "`short` and `java.lang.Short`"
msgstr " `short` 和 `java.lang.Short` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1447
#, fuzzy
msgid "`int` and `java.lang.Integer`"
msgstr " `int` 和 `java.lang.Integer` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1448
#, fuzzy
msgid "`long` and `java.lang.Long`"
msgstr " `long` 和 `java.lang.Long` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1449
#, fuzzy
msgid "`float` and `java.lang.Float`"
msgstr " `float` 和 `java.lang.Float` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1450
#, fuzzy
msgid "`double` and `java.lang.Double`"
msgstr " `double` 和 `java.lang.Double` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1451
#, fuzzy
msgid "`byte[]`"
msgstr " `byte[]` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1452
#, fuzzy
msgid "`java.lang.String`"
msgstr " `java.lang.String` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1453
#, fuzzy
msgid "`java.util.UUID`"
msgstr " `java.util.UUID` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1454
#, fuzzy
msgid "`java.nio.ByteBuffer`"
msgstr " `java.nio.ByteBuffer` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1455
#, fuzzy
msgid "`org.apache.kafka.common.utils.Bytes`"
msgstr " `org.apache.kafka.common.utils.Bytes` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1456
#, fuzzy
msgid "`io.vertx.core.buffer.Buffer`"
msgstr " `io.vertx.core.buffer.Buffer` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1457
#, fuzzy
msgid "`io.vertx.core.json.JsonObject`"
msgstr " `io.vertx.core.json.JsonObject` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1458
#, fuzzy
msgid "`io.vertx.core.json.JsonArray`"
msgstr " `io.vertx.core.json.JsonArray` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1459
#, fuzzy
msgid "classes for which a direct implementation of `org.apache.kafka.common.serialization.Serializer<T>` / `org.apache.kafka.common.serialization.Deserializer<T>` is present."
msgstr "存在直接实现 `org.apache.kafka.common.serialization.Serializer<T>` / `org.apache.kafka.common.serialization.Deserializer<T>` 的类。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1460
#, fuzzy
msgid "the implementation needs to specify the type argument `T` as the (de-)serialized type."
msgstr "实现需要指定类型参数 `T` 作为（去）序列化的类型。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1461
#, fuzzy
msgid "classes generated from Avro schemas, as well as Avro `GenericRecord`, if Confluent or Apicurio Registry _serde_ is present"
msgstr "如果Confluent或Apicurio Registry _serde_ 存在的话，从Avro模式生成的类，以及Avro `GenericRecord` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1462
#, fuzzy
msgid "in case multiple Avro serdes are present, serializer/deserializer must be configured manually for Avro-generated classes, because autodetection is impossible"
msgstr "如果存在多个Avro serdes，必须为Avro生成的类手动配置序列化器/反序列化器，因为不可能进行自动检测。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1463
#, fuzzy
msgid "see xref:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro] for more information about using Confluent or Apicurio Registry libraries"
msgstr "关于使用Confluent或Apicurio注册库的更多信息，请参见使用 link:kafka-schema-registry-avro.html[Apache Kafka与Schema Registry和Avro] 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1464
#, fuzzy
msgid "classes for which a subclass of `ObjectMapperSerializer` / `ObjectMapperDeserializer` is present, as described in <<jackson-serialization>>"
msgstr " `ObjectMapperSerializer` / `ObjectMapperDeserializer` 的子类的类，如 link:#jackson-serialization[[jackson-serialization]] 中所述。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1465
#, fuzzy
msgid "it is technically not needed to subclass `ObjectMapperSerializer`, but in such case, autodetection isn't possible"
msgstr "技术上不需要对 `ObjectMapperSerializer` ，但在这种情况下，自动检测是不可能的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1466
#, fuzzy
msgid "classes for which a subclass of `JsonbSerializer` / `JsonbDeserializer` is present, as described in <<jsonb-serialization>>"
msgstr " `JsonbSerializer` / `JsonbDeserializer` 的子类的类，如 link:#jsonb-serialization[[jsonb-serialization]] 中所述。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1467
#, fuzzy
msgid "it is technically not needed to subclass `JsonbSerializer`, but in such case, autodetection isn't possible"
msgstr "技术上不需要对 `JsonbSerializer` ，但在这种情况下，自动检测是不可能的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1469
#, fuzzy
msgid "If a serializer/deserializer is set by configuration, it won't be replaced by the autodetection."
msgstr "如果一个序列化器/反序列化器是通过配置设置的，它不会被自动检测所取代。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1472
#, fuzzy
msgid "In case you have any issues with serializer autodetection, you can switch it off completely by setting `quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false`.  If you find you need to do this, please file a bug in the link:https://github.com/quarkusio/quarkus/issues[Quarkus issue tracker] so we can fix whatever problem you have."
msgstr "如果你有任何关于序列化器自动检测的问题，你可以通过设置 `quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false` 来完全关闭它。如果你发现你需要这样做，请在 link:https://github.com/quarkusio/quarkus/issues[Quarkus问题跟踪器] 中提交一个bug，这样我们就能解决你的任何问题。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1474
#, fuzzy, no-wrap
msgid "JSON Serializer/deserializer generation"
msgstr "JSON序列化器/反序列化器的生成"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1476
#, fuzzy
msgid "Quarkus automatically generates serializers and deserializers for channels where:"
msgstr "Quarkus自动为通道生成序列化器和反序列化器，其中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1478
#, fuzzy
msgid "the serializer/deserializer is not configured"
msgstr "串行器/反串行器未被配置"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1479
#, fuzzy
msgid "the auto-detection did not find a matching serializer/deserializer"
msgstr "自动检测没有找到匹配的序列化器/反序列化器"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1481
#, fuzzy
msgid "It uses Jackson underneath."
msgstr "它在下面使用杰克逊。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1483
#, fuzzy
msgid "This generation can be disabled using:"
msgstr "可以用以下方法禁用这种生成。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1487
#, no-wrap
msgid "quarkus.reactive-messaging.kafka.serializer-generation.enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1491
#, fuzzy
msgid "Generation does not support collections such as `List<Fruit>`.  Refer to <<jackson-serialization>> to write your own serializer/deserializer for this case."
msgstr "Generation不支持诸如 `List<Fruit>` 这样的集合。参考 link:#jackson-serialization[[jackson-serialization]] 为这种情况编写你自己的序列化器/解序列化器。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1492
#, fuzzy, no-wrap
msgid "Using Schema Registry"
msgstr "使用模式注册表"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1497
#, fuzzy, no-wrap
msgid "Health Checks"
msgstr "健康检查"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1501
#, fuzzy
msgid "Quarkus provides several health checks for Kafka.  These checks are used in combination with the `quarkus-smallrye-health` extension."
msgstr "Quarkus为Kafka提供了几种健康检查。这些检查是与 `quarkus-smallrye-health` 扩展结合使用的。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1502
#, fuzzy, no-wrap
msgid "Kafka Broker Readiness Check"
msgstr "Kafka Broker的准备情况检查"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1507
#, fuzzy
msgid "When using the `quarkus-kafka-client` extension, you can enable _readiness_ health check by setting the `quarkus.kafka.health.enabled` property to `true` in your `application.properties`.  This check reports the status of the interaction with a _default_ Kafka broker (configured using `kafka.bootstrap.servers`).  It requires an _admin connection_ with the Kafka broker, and it is disabled by default.  If enabled, when you access the `/q/health/ready` endpoint of your application, you will have information about the connection validation status."
msgstr " `application.properties` 当使用 `quarkus-kafka-client` 扩展时，你可以通过在你的 `quarkus.kafka.health.enabled` 属性设置为 `true` 来启用 _就绪_ 健康检查。该检查报告与 _默认的_ Kafka代理（使用 `kafka.bootstrap.servers` 配置）的交互状态。它需要一个与Kafka代理的 _管理员连接_ ，并且默认是禁用的。如果启用，当你访问你的应用程序的 `/q/health/ready` 端点时，你将获得关于连接验证状态的信息。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1508
#, fuzzy, no-wrap
msgid "Kafka Reactive Messaging Health Checks"
msgstr "Kafka反应式消息传递健康检查"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1510
#, fuzzy
msgid "When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides _startup_, _liveness_ and _readiness_ checks."
msgstr "当使用Reactive Messaging和Kafka连接器时，每个配置的通道（传入或传出）都会提供 _启动_ 、 _有效性_ 和 _就绪性_ 检查。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1512
#, fuzzy
msgid "The _startup_ check verifies that the communication with Kafka cluster is established."
msgstr " _启动_ 检查验证了与Kafka集群的通信是否建立。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1513
#, fuzzy
msgid "The _liveness_ check captures any unrecoverable failure happening during the communication with Kafka."
msgstr " _有效性_ 检查可以捕获与Kafka通信过程中发生的任何不可恢复的故障。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1514
#, fuzzy
msgid "The _readiness_ check verifies that the Kafka connector is ready to consume/produce messages to the configured Kafka topics."
msgstr " _准备就绪_ 检查验证Kafka连接器是否准备好向配置的Kafka主题消费/生产消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1516
#, fuzzy
msgid "For each channel, you can disable the checks using:"
msgstr "对于每个通道，你可以使用禁用检查。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1520
#, no-wrap
msgid "# Disable both liveness and readiness checks with `health-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1525
#, no-wrap
msgid ""
"# Incoming channel (receiving records form Kafka)\n"
"mp.messaging.incoming.your-channel.health-enabled=false\n"
"# Outgoing channel (writing records to Kafka)\n"
"mp.messaging.outgoing.your-channel.health-enabled=false\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1527
#, no-wrap
msgid "# Disable only the readiness check with `health-readiness-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1530
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.health-readiness-enabled=false\n"
"mp.messaging.outgoing.your-channel.health-readiness-enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1534
#, fuzzy
msgid "You can configure the `bootstrap.servers` for each channel using `mp.messaging.incoming|outgoing.$channel.bootstrap.servers` property.  Default is `kafka.bootstrap.servers`."
msgstr "你可以使用 `mp.messaging.incoming|outgoing.$channel.bootstrap.servers` 属性为每个通道配置 `bootstrap.servers` 。默认是 `kafka.bootstrap.servers` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1538
#, fuzzy
msgid "Reactive Messaging _startup_ and _readiness_ checks offer two strategies.  The default strategy verifies that an active connection is established with the broker.  This approach is not intrusive as it's based on built-in Kafka client metrics."
msgstr "Reactive Messaging的 _启动_ 和 _准备就绪_ 检查提供了两种策略。默认策略是验证是否与代理建立了活动连接。这种方法不具有侵入性，因为它是基于内置的Kafka客户端指标。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1542
#, fuzzy
msgid "Using the `health-topic-verification-enabled=true` attribute, _startup_ probe uses an _admin client_ to check for the list of topics.  Whereas the _readiness_ probe for an incoming channel checks that at least one partition is assigned for consumption, and for an outgoing channel checks that the topic used by the producer exist in the broker."
msgstr "使用 `health-topic-verification-enabled=true` 属性， _启动_ 探针使用一个 _管理客户端_ 来检查主题列表。而传入通道的 _准备就绪_ 探针检查是否至少有一个分区被分配给消费，而传出通道则检查生产者使用的主题是否存在于经纪人中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1545
#, fuzzy
msgid "Note that to achieve this, an _admin connection_ is required.  You can adjust the timeout for topic verification calls to the broker using the `health-topic-verification-timeout` configuration."
msgstr "注意，要实现这一点，需要一个 _管理员连接_ 。你可以使用 `health-topic-verification-timeout` 配置来调整对经纪人的主题验证调用的超时。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1546
#, fuzzy, no-wrap
msgid "Kafka Streams"
msgstr "Kafka流"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1549
#, fuzzy
msgid "This is described in a dedicated guide: xref:kafka-streams.adoc[Using Apache Kafka Streams]."
msgstr "这在一个专门的指南中有所描述。 link:kafka-streams.html[使用Apache Kafka流] 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1550
#, fuzzy, no-wrap
msgid "Using Snappy for message compression"
msgstr "使用Snappy进行消息压缩"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1553
#, fuzzy
msgid "On _outgoing_ channels, you can enable Snappy compression by setting the `compression.type` attribute to `snappy`:"
msgstr " `snappy` 在 _出站_ 通道上，你可以通过设置 `compression.type` 属性来启用Snappy压缩。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1557
#, no-wrap
msgid "mp.messaging.outgoing.fruit-out.compression.type=snappy\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1561
#, fuzzy
msgid "In JVM mode, it will work out of the box.  However, to compile your application to a native executable, you need to:"
msgstr "在JVM模式下，它可以开箱即用。然而，要把你的应用程序编译成一个本地可执行文件，你需要。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1563
#, fuzzy
msgid "Uses GraalVM 21.+"
msgstr "使用GraalVM 21.+"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1564
#, fuzzy
msgid "Add `quarkus.kafka.snappy.enabled=true` to your `application.properties`"
msgstr "将 `quarkus.kafka.snappy.enabled=true` 添加到您的 `application.properties` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1566
#, fuzzy
msgid "In native mode, Snappy is disabled by default as the use of Snappy requires embedding a native library and unpacking it when the application starts."
msgstr "在本地模式下，Snappy默认是禁用的，因为使用Snappy需要嵌入一个本地库，并在应用程序启动时解包。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1567
#, fuzzy, no-wrap
msgid "Authentication with OAuth"
msgstr "用OAuth进行认证"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1571
#, fuzzy
msgid "If your Kafka broker uses OAuth as authentication mechanism, you need to configure the Kafka consumer to enable this authentication process.  First, add the following dependency to your application:"
msgstr "如果你的Kafka代理使用OAuth作为认证机制，你需要配置Kafka消费者来启用这个认证过程。首先，在你的应用程序中添加以下依赖关系。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1579
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.strimzi</groupId>\n"
"    <artifactId>kafka-oauth-client</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1585
#, no-wrap
msgid "implementation(\"io.strimzi:kafka-oauth-client\")\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1589
#, fuzzy
msgid "This dependency provides the callback handler required to handle the OAuth workflow.  Then, in the `application.properties`, add:"
msgstr "这个依赖关系提供了处理OAuth工作流程所需的回调处理器。然后，在 `application.properties` ，添加。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1599
#, no-wrap
msgid ""
"mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT\n"
"mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER\n"
"mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \\\n"
"  oauth.client.id=\"team-a-client\" \\\n"
"  oauth.client.secret=\"team-a-client-secret\" \\\n"
"  oauth.token.endpoint.uri=\"http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token\" ;\n"
"mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1601
#, no-wrap
msgid "quarkus.ssl.native=true\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1604
#, fuzzy
msgid "Update the `oauth.client.id`, `oauth.client.secret` and `oauth.token.endpoint.uri` values."
msgstr "更新 `oauth.client.id` , `oauth.client.secret` 和 `oauth.token.endpoint.uri` 值。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1606
#, fuzzy
msgid "OAuth authentication works for both JVM and native modes. Since SSL in not enabled by default in native mode, `quarkus.ssl.native=true` must be added to support JaasClientOauthLoginCallbackHandler, which uses SSL. (See the xref:native-and-ssl.adoc[Using SSL with Native Executables] guide for more details.)"
msgstr "OAuth认证对JVM和本地模式都有效。由于SSL在本地模式下默认不启用，必须添加 `quarkus.ssl.native=true` ，以支持JaasClientOauthLoginCallbackHandler，它使用SSL。(更多细节请参见《 link:native-and-ssl.html[在本地可执行文件中使用SSL] 》指南)。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1607
#, fuzzy, no-wrap
msgid "Testing a Kafka application"
msgstr "测试一个Kafka应用程序"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1609
#, fuzzy, no-wrap
msgid "Testing without a broker"
msgstr "没有经纪人的测试"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1613
#, fuzzy
msgid "It can be useful to test the application without having to start a Kafka broker.  To achieve this, you can _switch_ the channels managed by the Kafka connector to _in-memory_."
msgstr "在不启动Kafka代理的情况下测试应用程序可能很有用。为了实现这一点，你可以 _把_ Kafka连接器管理的通道 _切换_ 到内存 _中_ 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1615
#, fuzzy
msgid "This approach only works for JVM tests. It cannot be used for native tests (because they do not support injection)."
msgstr "这种方法只适用于JVM测试。它不能用于本地测试（因为它们不支持注入）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1617
#, fuzzy
msgid "Let's say we want to test the following processor application:"
msgstr "假设我们想测试以下的处理器应用。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1622
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class BeverageProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1634
#, no-wrap
msgid ""
"    @Incoming(\"orders\")\n"
"    @Outgoing(\"beverages\")\n"
"    Beverage process(Order order) {\n"
"        System.out.println(\"Order received \" + order.getProduct());\n"
"        Beverage beverage = new Beverage();\n"
"        beverage.setBeverage(order.getProduct());\n"
"        beverage.setCustomer(order.getCustomer());\n"
"        beverage.setOrderId(order.getOrderId());\n"
"        beverage.setPreparationState(\"RECEIVED\");\n"
"        return beverage;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1639
#, fuzzy
msgid "First, add the following test dependency to your application:"
msgstr "首先，在你的应用程序中添加以下测试依赖关系。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1648
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.smallrye.reactive</groupId>\n"
"    <artifactId>smallrye-reactive-messaging-in-memory</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1654
#, no-wrap
msgid "testImplementation(\"io.smallrye.reactive:smallrye-reactive-messaging-in-memory\")\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1657
#, fuzzy
msgid "Then, create a Quarkus Test Resource as follows:"
msgstr "然后，按以下方法创建Quarkus测试资源。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1661
#, no-wrap
msgid "public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1671
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        Map<String, String> env = new HashMap<>();\n"
"        Map<String, String> props1 = InMemoryConnector.switchIncomingChannelsToInMemory(\"orders\");     // <1>\n"
"        Map<String, String> props2 = InMemoryConnector.switchOutgoingChannelsToInMemory(\"beverages\");  // <2>\n"
"        env.putAll(props1);\n"
"        env.putAll(props2);\n"
"        return env;  // <3>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1677
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        InMemoryConnector.clear();  // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1679
#, fuzzy
msgid "Switch the incoming channel `orders` (expecting messages from Kafka) to in-memory."
msgstr "将传入通道 `orders` （期待来自Kafka的消息）切换到内存中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1680
#, fuzzy
msgid "Switch the outgoing channel `beverages` (writing messages to Kafka) to in-memory."
msgstr "将出站通道 `beverages` （向Kafka写消息）切换到内存中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1681
#, fuzzy
msgid "Builds and returns a `Map` containing all the properties required to configure the application to use in-memory channels."
msgstr "构建并返回一个 `Map` ，包含配置应用程序使用内存通道所需的所有属性。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1682
#, fuzzy
msgid "When the test stops, clear the `InMemoryConnector` (discard all the received and sent messages)"
msgstr "当测试停止时，清除 `InMemoryConnector` （丢弃所有接收和发送的信息）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1684
#, fuzzy
msgid "Create a Quarkus Test using the test resource created above:"
msgstr "使用上面创建的测试资源创建一个Quarkus测试。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1690
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)\n"
"class BaristaTest {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1693
#, no-wrap
msgid ""
"    @Inject\n"
"    InMemoryConnector connector; // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1698
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessOrder() {\n"
"        InMemorySource<Order> ordersIn = connector.source(\"orders\");     // <2>\n"
"        InMemorySink<Beverage> beveragesOut = connector.sink(\"beverages\");  // <3>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1703
#, no-wrap
msgid ""
"        Order order = new Order();\n"
"        order.setProduct(\"coffee\");\n"
"        order.setName(\"Coffee lover\");\n"
"        order.setOrderId(\"1234\");\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1705
#, no-wrap
msgid "        ordersIn.send(order);  // <4>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1707
#, no-wrap
msgid "        await().<List<? extends Message<Beverage>>>until(beveragesOut::received, t -> t.size() == 1); // <5>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1714
#, no-wrap
msgid ""
"        Beverage queuedBeverage = beveragesOut.received().get(0).getPayload();\n"
"        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());\n"
"        Assertions.assertEquals(\"coffee\", queuedBeverage.getBeverage());\n"
"        Assertions.assertEquals(\"Coffee lover\", queuedBeverage.getCustomer());\n"
"        Assertions.assertEquals(\"1234\", queuedBeverage.getOrderId());\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1718
#, fuzzy
msgid "Inject the in-memory connector in your test class."
msgstr "在你的测试类中注入内存中的连接器。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1719
#, fuzzy
msgid "Retrieve the incoming channel (`orders`) - the channel must have been switched to in-memory in the test resource."
msgstr "检索传入的通道( `orders` ) - 该通道必须在测试资源中被切换到内存中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1720
#, fuzzy
msgid "Retrieve the outgoing channel (`beverages`) - the channel must have been switched to in-memory in the test resource."
msgstr "检索出站通道 ( `beverages` ) - 该通道必须在测试资源中被切换到内存中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1722
#, fuzzy
msgid "Use the `send` method to send a message to the `orders` channel.  The application will process this message and send a message to `beverages` channel."
msgstr "使用 `send` 方法向 `orders` 通道发送一个消息。应用程序将处理这个消息并向 `beverages` channel发送消息。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1723
#, fuzzy
msgid "Use the `received` method on `beverages` channel to check the messages produced by the application."
msgstr "在 `beverages` channel上使用 `received` 方法来检查应用程序产生的信息。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1728
#, fuzzy
msgid "With in-memory channels we were able to test application code processing messages without starting a Kafka broker.  Note that different in-memory channels are independent, and switching channel connector to in-memory does not simulate message delivery between channels configured to the same Kafka topic."
msgstr "有了内存通道，我们就可以测试应用程序代码处理消息，而无需启动Kafka代理。请注意，不同的内存通道是独立的，将通道连接器切换到内存中并不能模拟配置到同一Kafka主题的通道之间的消息传递。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1730
#, fuzzy, no-wrap
msgid "Testing using a Kafka broker"
msgstr "使用Kafka经纪人进行测试"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1735
#, fuzzy
msgid "If you are using <<kafka-dev-services>>, a Kafka broker will be started and available throughout the tests, unless it is disabled in `%test` profile.  While it is possible to connect to this broker using Kafka Clients API, https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/[Kafka Companion Library] proposes an easier way of interacting with a Kafka broker and, creating consumer, producer and admin actions inside tests."
msgstr "如果你使用 link:#kafka-dev-services[[kafka-dev-services]] ，Kafka代理将被启动并在整个测试中可用，除非它在 `%test` profile中被禁用。虽然可以使用Kafka客户端API连接到这个代理，但 link:https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/[Kafka Companion Library] 提出了一种更简单的方式来与Kafka代理互动，并在测试中创建消费者、生产者和管理员动作。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1737
#, fuzzy
msgid "For using `KafkaCompanion` API in tests, start by adding the following dependency:"
msgstr "为了在测试中使用 `KafkaCompanion` API，首先要添加以下依赖关系。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1745
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-test-kafka-companion</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1748
#, fuzzy
msgid "which provides `io.quarkus.test.kafka.KafkaCompanionResource` - an implementation of `io.quarkus.test.common.QuarkusTestResourceLifecycleManager`."
msgstr "它提供了 `io.quarkus.test.kafka.KafkaCompanionResource` -- `io.quarkus.test.common.QuarkusTestResourceLifecycleManager` 的实现。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1750
#, fuzzy
msgid "Then use `@QuarkusTestResource` to configure the Kafka Companion in tests, for example:"
msgstr "然后使用 `@QuarkusTestResource` ，在测试中配置Kafka Companion，比如说。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1754
#, no-wrap
msgid "import static org.junit.jupiter.api.Assertions.assertEquals;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1756
#, no-wrap
msgid "import java.util.UUID;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1759
#, no-wrap
msgid ""
"import org.apache.kafka.clients.producer.ProducerRecord;\n"
"import org.junit.jupiter.api.Test;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1766
#, no-wrap
msgid ""
"import io.quarkus.test.common.QuarkusTestResource;\n"
"import io.quarkus.test.junit.QuarkusTest;\n"
"import io.quarkus.test.kafka.InjectKafkaCompanion;\n"
"import io.quarkus.test.kafka.KafkaCompanionResource;\n"
"import io.smallrye.reactive.messaging.kafka.companion.ConsumerTask;\n"
"import io.smallrye.reactive.messaging.kafka.companion.KafkaCompanion;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1770
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaCompanionResource.class)\n"
"public class OrderProcessorTest {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1773
#, no-wrap
msgid ""
"    @InjectKafkaCompanion // <1>\n"
"    KafkaCompanion companion;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1777
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessor() {\n"
"        companion.produceStrings().usingGenerator(i -> new ProducerRecord<>(\"orders\", UUID.randomUUID().toString())); // <2>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1779
#, no-wrap
msgid "        // Expect that the tested application processes orders from 'orders' topic and write to 'orders-processed' topic\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1785
#, no-wrap
msgid ""
"        ConsumerTask<String, String> orders = companion.consumeStrings().fromTopics(\"orders-processed\", 10); // <3>\n"
"        orders.awaitCompletion(); // <4>\n"
"        assertEquals(10, orders.count());\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1788
#, fuzzy
msgid "`@InjectKafkaCompanion` injects the `KafkaCompanion` instance, configured to access the Kafka broker created for tests."
msgstr " `@InjectKafkaCompanion` 注入 实例，配置为访问为测试创建的Kafka代理。 `KafkaCompanion` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1789
#, fuzzy
msgid "Use `KafkaCompanion` to create producer task which writes 10 records to 'orders' topic."
msgstr "使用 `KafkaCompanion` ，创建生产者任务，向 \"订单 \"主题写入10条记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1790
#, fuzzy
msgid "Create consumer task which subscribes to 'orders-processed' topic and consumes 10 records."
msgstr "创建消费者任务，订阅'orders-processed'主题并消耗10条记录。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1791
#, fuzzy
msgid "Await completion of the consumer task."
msgstr "等待消费者任务的完成。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1795
#, fuzzy
msgid "If the Kafka Dev Service is available during tests, `KafkaCompanionResource` uses the created Kafka broker, otherwise it creates a Kafka broker using https://github.com/strimzi/test-container[Strimzi Test Container]."
msgstr "如果Kafka Dev Service在测试期间是可用的， `KafkaCompanionResource` ，则使用创建的Kafka代理，否则就使用 link:https://github.com/strimzi/test-container[Strimzi测试容器] 创建一个Kafka代理。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1797
#, fuzzy
msgid "The configuration of the created Kafka broker can be customized using `@ResourceArg`, for example:"
msgstr "创建的Kafka代理的配置可以使用 `@ResourceArg` ，例如，可以自定义。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1808
#, no-wrap
msgid ""
"@QuarkusTestResource(value = KafkaCompanionResource.class, initArgs = {\n"
"        @ResourceArg(name = \"strimzi.kafka.image\", value = \"quay.io/strimzi/kafka:0.28.0-kafka-3.0.0\"), // Image name\n"
"        @ResourceArg(name = \"kafka.port\", value = \"9092\"), // Fixed port for kafka, by default it will be exposed on a random port\n"
"        @ResourceArg(name = \"kraft\", value = \"true\"), // Enable Kraft mode\n"
"        @ResourceArg(name = \"num.partitions\", value = \"3\"), // Other custom broker configurations\n"
"})\n"
"public class OrderProcessorTest {\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Title ====
#: upstream/_guides/kafka.adoc:1811
#, fuzzy, no-wrap
msgid "Custom test resource"
msgstr "自定义测试资源"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1815
#, fuzzy
msgid "Alternatively, you can start a Kafka broker in a test resource.  The following snippet shows a test resource starting a Kafka broker using https://www.testcontainers.org/modules/kafka/[Testcontainers]:"
msgstr "另外，你也可以在测试资源中启动一个Kafka代理。下面的片段显示了一个测试资源使用 link:https://www.testcontainers.org/modules/kafka/[Testcontainers] 启动一个Kafka代理。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1819
#, no-wrap
msgid "public class KafkaResource implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1821
#, no-wrap
msgid "    private final KafkaContainer kafka = new KafkaContainer();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1827
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        kafka.start();\n"
"        return Collections.singletonMap(\"kafka.bootstrap.servers\", kafka.getBootstrapServers());  // <1>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1833
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        kafka.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1835
#, fuzzy
msgid "Configure the Kafka bootstrap location, so the application connects to this broker."
msgstr "配置Kafka bootstrap位置，这样应用程序就会连接到这个代理。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1839
#, fuzzy, no-wrap
msgid "Kubernetes Service Bindings"
msgstr "Kubernetes服务绑定"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1844
#, fuzzy
msgid "Quarkus Kafka extension supports xref:deploying-to-kubernetes.adoc[Service Binding Specification for Kubernetes].  You can enable this by adding the `quarkus-kubernetes-service-binding` extension to your application."
msgstr "Quarkus Kafka扩展支持 link:deploying-to-kubernetes.html[Kubernetes的服务绑定规范] 。你可以通过在你的应用程序中添加 `quarkus-kubernetes-service-binding` 扩展来启用它。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1846
#, fuzzy
msgid "When running in appropriately configured Kubernetes clusters, Kafka extension will pull its Kafka broker connection configuration from the service binding available inside the cluster, without the need for user configuration."
msgstr "当在适当配置的Kubernetes集群中运行时，Kafka扩展将从集群内部可用的服务绑定中提取其Kafka代理连接配置，而不需要用户配置。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1847
#, fuzzy, no-wrap
msgid "Execution model"
msgstr "执行模式"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1852
#, fuzzy
msgid "Reactive Messaging invokes user's methods on an I/O thread.  Thus, by default, the methods must not block.  As described in <<blocking-processing>>, you need to add the `@Blocking` annotation on the method if this method will block the caller thread."
msgstr "Reactive Messaging在I/O线程上调用用户的方法。因此，默认情况下，这些方法不能阻塞。正如 link:#blocking-processing[[blocking-processing]] 中所述，如果这个方法会阻塞调用者线程，你需要在方法上添加 `@Blocking` 注解。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1854
#, fuzzy
msgid "See the xref:quarkus-reactive-architecture.adoc[Quarkus Reactive Architecture documentation] for further details on this topic."
msgstr "关于这个话题的更多细节，请看 link:quarkus-reactive-architecture.html[Quarkus Reactive Architecture文档] 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1856
#, fuzzy, no-wrap
msgid "Configuration Reference"
msgstr "配置参考"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1859
#, fuzzy
msgid "More details about the SmallRye Reactive Messaging configuration can be found in the https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation]."
msgstr "关于SmallRye Reactive Messaging配置的更多细节可以在 link:https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector文档] 中找到。"

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1863
#, fuzzy
msgid "Each channel can be disabled via configuration using:"
msgstr "每个通道都可以通过配置来禁用。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1867
#, no-wrap
msgid "mp.messaging.[incoming|outgoing].[channel].enabled=false\n"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka.adoc:1871
#, fuzzy
msgid "The most important attributes are listed in the tables below:"
msgstr "最重要的属性列在以下表格中。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1872
#, fuzzy, no-wrap
msgid "Incoming channel configuration (polling from Kafka)"
msgstr "入站通道配置（从Kafka轮询）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1875 upstream/_guides/kafka.adoc:1914
#, fuzzy
msgid "The following attributes are configured using:"
msgstr "使用以下属性进行配置。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1879
#, no-wrap
msgid "mp.messaging.incoming.your-channel-name.attribute=value\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1882 upstream/_guides/kafka.adoc:1921
#, fuzzy
msgid "Some properties have aliases which can be configured globally:"
msgstr "有些属性有别名，可以全局配置。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1886 upstream/_guides/kafka.adoc:1925
#, no-wrap
msgid "kafka.bootstrap.servers=...\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1889
#, fuzzy
msgid "You can also pass any property supported by the underlying https://kafka.apache.org/documentation/#consumerconfigs[Kafka consumer]."
msgstr "你也可以传递底层 link:https://kafka.apache.org/documentation/#consumerconfigs[Kafka消费者] 支持的任何属性。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1891
#, fuzzy
msgid "For example, to configure the `max.poll.records` property, use:"
msgstr "例如，要配置 `max.poll.records` 属性，使用。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1895
#, no-wrap
msgid "mp.messaging.incoming.[channel].max.poll.records=1000\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1898
#, fuzzy
msgid "Some consumer client properties are configured to sensible default values:"
msgstr "一些消费者客户端属性被配置为合理的默认值。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1900 upstream/_guides/kafka.adoc:1939
#, fuzzy
msgid "If not set, `reconnect.backoff.max.ms` is set to `10000` to avoid high load on disconnection."
msgstr " `10000` 如果不设置， `reconnect.backoff.max.ms` ，以避免断开时的高负荷。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1902
#, fuzzy
msgid "If not set, `key.deserializer` is set to `org.apache.kafka.common.serialization.StringDeserializer`."
msgstr "如果不设置， `key.deserializer` ，则设置为 `org.apache.kafka.common.serialization.StringDeserializer` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1904
#, fuzzy
msgid "The consumer `client.id` is configured according to the number of clients to create using `mp.messaging.incoming.[channel].partitions` property."
msgstr "消费者 `client.id` ，根据使用 `mp.messaging.incoming.[channel].partitions` 属性创建的客户数量进行配置。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1906
#, fuzzy
msgid "If a `client.id` is provided, it is used as-is or suffixed with client index if `partitions` property is set."
msgstr "如果提供了一个 `client.id` ，它将被原封不动地使用，如果 `partitions` 属性被设置，则以客户索引为后缀。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1907
#, fuzzy
msgid "If a `client.id` is not provided, it is generated as `kafka-consumer-[channel][-index]`."
msgstr "如果没有提供 `client.id` ，则生成为 `kafka-consumer-[channel][-index]` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1911
#, fuzzy, no-wrap
msgid "Outgoing channel configuration (writing to Kafka)"
msgstr "外发通道配置（写到Kafka）。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1918
#, no-wrap
msgid "mp.messaging.outgoing.your-channel-name.attribute=value\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1928
#, fuzzy
msgid "You can also pass any property supported by the underlying https://kafka.apache.org/documentation/#producerconfigs[Kafka producer]."
msgstr "你也可以传递底层 link:https://kafka.apache.org/documentation/#producerconfigs[Kafka生产者] 支持的任何属性。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1930
#, fuzzy
msgid "For example, to configure the `max.block.ms` property, use:"
msgstr "例如，要配置 `max.block.ms` 属性，使用。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1934
#, no-wrap
msgid "mp.messaging.incoming.[channel].max.block.ms=10000\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1937
#, fuzzy
msgid "Some producer client properties are configured to sensible default values:"
msgstr "一些生产者客户端属性被配置为合理的默认值。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1941
#, fuzzy
msgid "If not set, `key.serializer` is set to `org.apache.kafka.common.serialization.StringSerializer`."
msgstr "如果不设置， `key.serializer` ，则设置为 `org.apache.kafka.common.serialization.StringSerializer` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1943
#, fuzzy
msgid "If not set, producer `client.id` is generated as `kafka-producer-[channel]`."
msgstr "如果不设置，生产者 `client.id` ，则生成为 `kafka-producer-[channel]` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1947
#, fuzzy, no-wrap
msgid "Kafka Configuration Resolution"
msgstr "Kafka配置决议"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1951
#, fuzzy
msgid "Quarkus exposes all Kafka related application properties, prefixed with `kafka.` or `KAFKA_` inside a configuration map with `default-kafka-broker` name.  This configuration is used to establish the connection with the Kafka broker."
msgstr "Quarkus公开了所有与Kafka相关的应用属性，前缀为 `kafka.` 或 `KAFKA_` ，在配置图中有 `default-kafka-broker` 名称。这个配置被用来建立与Kafka代理的连接。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1953
#, fuzzy
msgid "In addition to this default configuration, you can configure the name of the `Map` producer using the `kafka-configuration` attribute:"
msgstr "除了这个默认配置外，你还可以使用 `kafka-configuration` 属性配置 `Map` 生产者的名称。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1958
#, no-wrap
msgid ""
"mp.messaging.incoming.my-channel.connector=smallrye-kafka\n"
"mp.messaging.incoming.my-channel.kafka-configuration=my-configuration\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1962
#, fuzzy
msgid "In this case, the connector looks for the `Map` associated with the `my-configuration` name.  If `kafka-configuration` is not set, an optional lookup for a `Map` exposed with the channel name (`my-channel` in the previous example) is done."
msgstr "在这种情况下，连接器会寻找与 `my-configuration` 名称相关的 `Map` 。如果没有设置 `kafka-configuration` ，就会进行可选的查询，即查询与通道名称相关的 `Map` （在前面的例子中是 `my-channel` ）。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1973
#, no-wrap
msgid ""
"@Produces\n"
"@ApplicationScoped\n"
"@Identifier(\"my-configuration\")\n"
"Map<String, Object> outgoing() {\n"
"    return Map.ofEntries(\n"
"            Map.entry(\"value.serializer\", ObjectMapperSerializer.class.getName())\n"
"    );\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:1976
#, fuzzy
msgid "If `kafka-configuration` is set and no `Map` can be found, the deployment fails."
msgstr "如果设置了 `kafka-configuration` ，但没有找到 `Map` ，则部署失败。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1978
#, fuzzy
msgid "Attribute values are resolved as follows:"
msgstr "属性值的解决方式如下。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1980
#, fuzzy
msgid "the attribute is set directly on the channel configuration (`mp.messaging.incoming.my-channel.attribute=value`),"
msgstr "该属性是直接在通道配置上设置的( `mp.messaging.incoming.my-channel.attribute=value` )。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1981
#, fuzzy
msgid "if not set, the connector looks for a `Map` with the channel name or the configured `kafka-configuration` (if set) and the value is retrieved from that `Map`"
msgstr "如果没有设置，连接器会寻找一个带有通道名称或配置的 `kafka-configuration` （如果设置了）的 `Map` ，并从该值中检索出 `Map` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:1982
#, fuzzy
msgid "If the resolved `Map` does not contain the value the default `Map` is used (exposed with the `default-kafka-broker` name)"
msgstr "如果解决的 `Map` 不包含该值，则使用默认的 `Map` （用 `default-kafka-broker` 的名称暴露）。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:1983
#, fuzzy, no-wrap
msgid "Integrating with Kafka - Common patterns"
msgstr "与Kafka的整合--常见模式"

#. type: Title ===
#: upstream/_guides/kafka.adoc:1985
#, fuzzy, no-wrap
msgid "Writing to Kafka from an HTTP endpoint"
msgstr "从一个HTTP端点写到Kafka"

#. type: Plain text
#: upstream/_guides/kafka.adoc:1988
#, fuzzy
msgid "To send messages to Kafka from an HTTP endpoint, inject an `Emitter` (or a `MutinyEmitter`) in your endpoint:"
msgstr "要从HTTP端点向Kafka发送消息，在你的端点中注入一个 `Emitter` （或一个 `MutinyEmitter` ）。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1992 upstream/_guides/kafka.adoc:2040
#: upstream/_guides/kafka.adoc:2081 upstream/_guides/kafka.adoc:2099
#: upstream/_guides/kafka.adoc:2129 upstream/_guides/kafka.adoc:2161
#: upstream/_guides/kafka.adoc:2180 upstream/_guides/kafka.adoc:2215
#: upstream/_guides/kafka.adoc:2258 upstream/_guides/kafka.adoc:2299
#, no-wrap
msgid "package org.acme;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1994 upstream/_guides/kafka.adoc:2042
#: upstream/_guides/kafka.adoc:2260
#, no-wrap
msgid "import java.util.concurrent.CompletionStage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:1999 upstream/_guides/kafka.adoc:2047
#, no-wrap
msgid ""
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2005 upstream/_guides/kafka.adoc:2055
#: upstream/_guides/kafka.adoc:2270
#, no-wrap
msgid ""
"@Path(\"/\")\n"
"public class ResourceSendingToKafka {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2007
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<String> emitter;          // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2014
#, no-wrap
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) { // <2>\n"
"        return emitter.send(payload);                   // <3>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2016
#, fuzzy
msgid "Inject an `Emitter<String>`"
msgstr "注入一个 `Emitter<String>` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2017
#, fuzzy
msgid "The HTTP method receives the payload and returns a `CompletionStage` completed when the message is written to Kafka"
msgstr "HTTP方法接收有效载荷，并在消息被写入Kafka时返回一个 `CompletionStage` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2018
#, fuzzy
msgid "Send the message to Kafka, the `send` method returns a `CompletionStage`"
msgstr "将消息发送到Kafka， `send` 方法返回一个 `CompletionStage` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2021
#, fuzzy
msgid "The endpoint sends the passed payload (from a `POST` HTTP request) to the emitter.  The emitter's channel is mapped to a Kafka topic in the `application.properties` file:"
msgstr "端点将传递的有效载荷（来自 `POST` HTTP请求）发送给发射器。发射器的通道被映射到 `application.properties` 文件中的一个Kafka主题。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2026
#, no-wrap
msgid ""
"mp.messaging.outgoing.kafka.connector=smallrye-kafka\n"
"mp.messaging.outgoing.kafka.topic=my-topic\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2032
#, fuzzy
msgid "The endpoint returns a `CompletionStage` indicating the asynchronous nature of the method.  The `emitter.send` method returns a `CompletionStage<Void>` .  The returned future is completed when the message has been written to Kafka.  If the writing fails, the returned `CompletionStage` is completed exceptionally."
msgstr "端点返回一个 `CompletionStage` ，表明该方法的异步性质。 `emitter.send` 方法返回一个 `CompletionStage<Void>` 。当消息被写入Kafka时，返回的未来就完成了。如果写入失败，返回的 `CompletionStage` 会例外地完成。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2034
#, fuzzy
msgid "If the endpoint does not return a `CompletionStage`, the HTTP response may be written before the message is sent to Kafka, and so failures won't be reported to the user."
msgstr "如果端点没有返回 `CompletionStage` ，HTTP响应可能会在消息被发送到Kafka之前被写入，因此失败不会被报告给用户。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2036
#, fuzzy
msgid "If you need to send a Kafka record, use:"
msgstr "如果你需要发送一条Kafka记录，请使用。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2052
#, no-wrap
msgid "import io.smallrye.reactive.messaging.kafka.Record;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2057
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<Record<String,String>> emitter;  // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2065
#, no-wrap
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) {\n"
"        return emitter.send(Record.of(\"my-key\", payload));    // <2>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2067
#, fuzzy
msgid "Note the usage of an `Emitter<Record<K, V>>`"
msgstr "注意使用一个 `Emitter<Record<K, V>>` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2068
#, fuzzy
msgid "Create the record using `Record.of(k, v)`"
msgstr "使用以下方法创建记录 `Record.of(k, v)` "

#. type: Title ===
#: upstream/_guides/kafka.adoc:2069
#, fuzzy, no-wrap
msgid "Persisting Kafka messages with Hibernate with Panache"
msgstr "用Hibernate与Panache坚持Kafka消息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2072
#, fuzzy
msgid "To persist objects received from Kafka into a database, you can use Hibernate with Panache."
msgstr "为了将从Kafka收到的对象持久化到数据库中，你可以使用Hibernate与Panache。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2074
#, fuzzy
msgid "If you use Hibernate Reactive, look at <<persisting-kafka-messages-with-hibernate-reactive>>."
msgstr "如果你使用Hibernate Reactive，请看 link:#persisting-kafka-messages-with-hibernate-reactive[[persisting-kafka-messages-with-hibernate-reactive]] 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2077 upstream/_guides/kafka.adoc:2157
#, fuzzy
msgid "Let's imagine you receive `Fruit` objects.  For simplicity purposes, our `Fruit` class is pretty simple:"
msgstr "让我们想象一下，你收到 `Fruit` 对象。为了简单起见，我们的 `Fruit` 类是非常简单的。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2083 upstream/_guides/kafka.adoc:2163
#, no-wrap
msgid "import javax.persistence.Entity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2085
#, no-wrap
msgid "import io.quarkus.hibernate.orm.panache.PanacheEntity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2088 upstream/_guides/kafka.adoc:2168
#, no-wrap
msgid ""
"@Entity\n"
"public class Fruit extends PanacheEntity {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2090 upstream/_guides/kafka.adoc:2170
#, no-wrap
msgid "    public String name;\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2095 upstream/_guides/kafka.adoc:2176
#, fuzzy
msgid "To consume `Fruit` instances stored on a Kafka topic, and persist them into a database, you can use the following approach:"
msgstr "要消费存储在Kafka主题上的 `Fruit` 实例，并将其持久化到数据库中，你可以使用以下方法。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2106
#, no-wrap
msgid "import io.smallrye.common.annotation.Blocking;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2109
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class FruitConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2116
#, no-wrap
msgid ""
"    @Incoming(\"fruits\")                                     // <1>\n"
"    @Transactional                                          // <2>\n"
"    public void persistFruits(Fruit fruit) {                // <3>\n"
"        fruit.persist();                                    // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2118
#, fuzzy
msgid "Configuring the incoming channel. This channel reads from Kafka."
msgstr "配置传入通道。这个通道从Kafka读取。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2120
#, fuzzy
msgid "As we are writing in a database, we must be in a transaction. This annotation starts a new transaction and commits it when the method returns.  Quarkus automatically considers the method as _blocking_. Indeed, writing to a database using classic Hibernate is blocking. So, Quarkus calls the method on a worker thread you can block (and not an I/O thread)."
msgstr "由于我们是在数据库中写作，我们必须在一个事务中。这个注解启动了一个新的事务，并在方法返回时提交了它。Quarkus会自动认为这个方法是 _阻塞的_ 。事实上，使用经典的Hibernate向数据库写入是阻塞的。所以，Quarkus在一个可以阻塞的工作线程上调用这个方法（而不是I/O线程）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2121
#, fuzzy
msgid "The method receives each Fruit. Note that you would need a deserializer to reconstruct the Fruit instances from the Kafka records."
msgstr "该方法接收每个Fruit。注意，你需要一个反序列化器来从Kafka记录中重构Fruit实例。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2122
#, fuzzy
msgid "Persist the received `fruit` object."
msgstr "保存收到的 `fruit` 对象。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2125
#, fuzzy
msgid "As mentioned in <4>, you need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr "正如<4>中提到的，你需要一个能从记录中创建 `Fruit` 的反序列化器。这可以用Jackson的反序列化器来完成。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2140 upstream/_guides/kafka.adoc:2226
#, fuzzy
msgid "The associated configuration would be:"
msgstr "相关的配置将是。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2145 upstream/_guides/kafka.adoc:2231
#, no-wrap
msgid ""
"mp.messaging.incoming.fruits.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2149 upstream/_guides/kafka.adoc:2235
#, fuzzy
msgid "Check <<jackson-serialization>> for more detail about the usage of Jackson with Kafka.  You can also use Avro."
msgstr "查看 link:#jackson-serialization[[jackson-serialization]] ，了解更多关于Jackson与Kafka的使用细节。你也可以使用Avro。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:2151
#, fuzzy, no-wrap
msgid "Persisting Kafka messages with Hibernate Reactive"
msgstr "用Hibernate Reactive持久化Kafka消息"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2154
#, fuzzy
msgid "To persist objects received from Kafka into a database, you can use Hibernate Reactive with Panache."
msgstr "为了将从Kafka收到的对象持久化到数据库中，你可以使用Hibernate Reactive与Panache。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2165
#, no-wrap
msgid "import io.quarkus.hibernate.reactive.panache.PanacheEntity;  // <1>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2174
#, fuzzy
msgid "Make sure to use the reactive variant"
msgstr "请确保使用反应式变体"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2187
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2190
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class FruitStore {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2198
#, no-wrap
msgid ""
"    @Incoming(\"fruits\")\n"
"    public Uni<Void> persist(Fruit fruit) {\n"
"        return Panache.withTransaction(() ->  // <1>\n"
"            fruit.persist()                   // <2>\n"
"                .map(persisted -> null)       // <3>\n"
"        );\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2202
#, fuzzy
msgid "Instruct Panache to run the given (asynchronous) action in a transaction. The transaction completes when the action completes."
msgstr "指示Panache在一个事务中运行给定的（异步）动作。当该动作完成时，事务就完成了。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2203
#, fuzzy
msgid "Persist the entity. It returns a `Uni<Fruit>`."
msgstr "坚持该实体。它返回一个 `Uni<Fruit>` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2204
#, fuzzy
msgid "Switch back to a `Uni<Void>`."
msgstr "换回一个 `Uni<Void>` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2208
#, fuzzy
msgid "Unlike with _classic_ Hibernate, you can't use `@Transactional`.  Instead, we use `Panache.withTransaction` and persist our entity.  The `map` is used to return a `Uni<Void>` and not a `Uni<Fruit>`."
msgstr "与 _经典的_ Hibernate不同，你不能使用 `@Transactional` 。相反，我们使用 `Panache.withTransaction` ，并持久化我们的实体。 `map` 是用来返回一个 `Uni<Void>` ，而不是一个 `Uni<Fruit>` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2211
#, fuzzy
msgid "You need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr "你需要一个能从记录中创建 `Fruit` 的反序列化器。这可以用Jackson的反序列化器来完成。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:2236
#, fuzzy, no-wrap
msgid "Writing entities managed by Hibernate to Kafka"
msgstr "将Hibernate管理的实体写入Kafka中"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2239
#, fuzzy
msgid "Let's imagine the following process:"
msgstr "让我们想象一下下面的过程。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2241
#, fuzzy
msgid "You receive an HTTP request with a payload,"
msgstr "你收到一个带有有效载荷的HTTP请求。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2242
#, fuzzy
msgid "You create an Hibernate entity instance from this payload,"
msgstr "你从这个有效载荷中创建一个Hibernate实体实例。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2243
#, fuzzy
msgid "You persist that entity into a database,"
msgstr "你将该实体持久化到数据库中。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2244
#, fuzzy
msgid "You send the entity to a Kafka topic"
msgstr "你把实体发送到一个Kafka主题上"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2246
#, fuzzy
msgid "If you use Hibernate Reactive, look at <<writing-entities-managed-by-hibernate-reactive-to-kafka>>."
msgstr "如果你使用Hibernate Reactive，请看 link:#writing-entities-managed-by-hibernate-reactive-to-kafka[[writing-entities-managed-by-hibernate-reactive-to-kafka]] 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2252
#, fuzzy
msgid "Because we write to a database, we must run this method in a transaction.  Yet, sending the entity to Kafka happens asynchronously.  The operation returns a `CompletionStage` (or a `Uni` if you use a `MutinyEmitter`) reporting when the operation completes.  We must be sure that the transaction is still running until the object is written.  Otherwise, you may access the object outside the transaction, which is not allowed."
msgstr "因为我们写到了数据库，所以我们必须在一个事务中运行这个方法。然而，向Kafka发送实体是异步进行的。该操作完成后会返回一个 `CompletionStage` （如果你使用 `MutinyEmitter` ，则返回 `Uni` ）报告。我们必须确定，在对象被写入之前，事务仍然在运行。否则，你可能会在事务之外访问该对象，这是不允许的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2254
#, fuzzy
msgid "To implement this process, you need the following approach:"
msgstr "为了实施这一过程，你需要采取以下方法。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2264
#, no-wrap
msgid ""
"import javax.transaction.Transactional;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2272
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<Fruit> emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2281
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    @Transactional                                                      // <1>\n"
"    public CompletionStage<Void> storeAndSendToKafka(Fruit fruit) {     // <2>\n"
"        fruit.persist();\n"
"        return emitter.send(fruit);                                     // <3>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2283
#, fuzzy
msgid "As we are writing to the database, make sure we run inside a transaction"
msgstr "当我们向数据库写入时，确保我们在一个事务中运行"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2284
#, fuzzy
msgid "The method receives the fruit instance to persist. It returns a `CompletionStage` which is used for the transaction demarcation. The transaction is committed when the return `CompletionStage` completes. In our case, it's when the message is written to Kafka."
msgstr "该方法接收要持久化的水果实例。它返回一个 `CompletionStage` ，用于事务分界。当返回的 `CompletionStage` 完成时，事务就提交了。在我们的例子中，就是消息被写入Kafka的时候。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2285
#, fuzzy
msgid "Send the managed instance to Kafka. Make sure we wait for the message to complete before closing the transaction."
msgstr "将管理的实例发送到Kafka。确保我们在关闭事务之前等待消息的完成。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:2287
#, fuzzy, no-wrap
msgid "Writing entities managed by Hibernate Reactive to Kafka"
msgstr "将Hibernate Reactive管理的实体写入Kafka中"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2290
#, fuzzy
msgid "To send to Kafka entities managed by Hibernate Reactive, we recommend using:"
msgstr "为了向由Hibernate Reactive管理的Kafka实体发送，我们建议使用。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2292
#, fuzzy
msgid "RESTEasy Reactive to serve HTTP requests"
msgstr "RESTEasy Reactive为HTTP请求提供服务"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2293
#, fuzzy
msgid "A `MutinyEmitter` to send message to a channel, so it can be easily integrated with the Mutiny API exposed by Hibernate Reactive or Hibernate Reactive with Panache."
msgstr "一个 `MutinyEmitter` ，向一个通道发送消息，所以它可以很容易地与Hibernate Reactive或Hibernate Reactive with Panache暴露的Mutiny API集成。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2295
#, fuzzy
msgid "The following example demonstrates how to receive a payload, store it in the database using Hibernate Reactive with Panache, and send the persisted entity to Kafka:"
msgstr "下面的例子演示了如何接收一个有效载荷，使用Hibernate Reactive with Panache将其存储在数据库中，并将持久化的实体发送到Kafka。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2302
#, no-wrap
msgid ""
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2308
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2311
#, no-wrap
msgid ""
"@Path(\"/\")\n"
"public class ReactiveGreetingResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2313
#, no-wrap
msgid "    @Channel(\"kafka\") MutinyEmitter<Fruit> emitter;     // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2323
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    public Uni<Void> sendToKafka(Fruit fruit) {         // <2>\n"
"        return Panache.withTransaction(() ->            // <3>\n"
"            fruit.<Fruit>persist()\n"
"        )\n"
"            .chain(f -> emitter.send(f));               // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2325
#, fuzzy
msgid "Inject a `MutinyEmitter` which exposes a Mutiny API. It simplifies the integration with the Mutiny API exposed by Hibernate Reactive with Panache."
msgstr "注入一个 `MutinyEmitter` ，它暴露了Mutiny API。它简化了与Hibernate Reactive与Panache所暴露的Mutiny API的整合。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2326
#, fuzzy
msgid "The HTTP method receiving the payload returns a `Uni<Void>`. The HTTP response is written when the operation completes (the entity is persisted and written to Kafka)."
msgstr "接收有效载荷的HTTP方法返回一个 `Uni<Void>` 。当操作完成后，HTTP响应被写入（实体被持久化并写入Kafka）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2327
#, fuzzy
msgid "We need to write the entity into the database in a transaction."
msgstr "我们需要在一个事务中把实体写进数据库。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2328
#, fuzzy
msgid "Once the persist operation completes, we send the entity to Kafka. The `send` method returns a `Uni<Void>`."
msgstr "一旦持久化操作完成，我们就把实体发送到Kafka。 `send` 方法返回一个 `Uni<Void>` 。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:2330
#, fuzzy, no-wrap
msgid "Streaming Kafka topics as server-sent events"
msgstr "将Kafka主题作为服务器发送的事件流化"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2333
#, fuzzy
msgid "Streaming a Kafka topic as server-sent events (SSE) is straightforward:"
msgstr "将Kafka主题作为服务器发送的事件（SSE）进行流化是很直接的。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2335
#, fuzzy
msgid "You inject the channel representing the Kafka topic in your HTTP endpoint"
msgstr "你在你的HTTP端点中注入代表Kafka主题的通道"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2336
#, fuzzy
msgid "You return that channel as a `Publisher` or a `Multi` from the HTTP method"
msgstr "你将该通道作为一个 `Publisher` ，或从HTTP方法中返回一个 `Multi` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2338
#, fuzzy
msgid "The following code provides an example:"
msgstr "下面的代码提供了一个例子。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2343 upstream/_guides/kafka.adoc:2358
#, no-wrap
msgid ""
"@Channel(\"fruits\")\n"
"Multi<Fruit> fruits;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2349
#, no-wrap
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<Fruit> stream() {\n"
"    return fruits;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2353
#, fuzzy
msgid "Some environment cuts the SSE connection when there is not enough activity.  The workaround consists of sending _ping_ messages (or empty objects) periodically."
msgstr "当没有足够的活动时，有些环境会切断SSE的连接。解决的办法是定期发送 _ping_ 信息（或空对象）。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2361
#, no-wrap
msgid ""
"@Inject\n"
"ObjectMapper mapper;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2371
#, no-wrap
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<String> stream() {\n"
"    return Multi.createBy().merging()\n"
"            .streams(\n"
"                    fruits.map(this::toJson),\n"
"                    emitAPeriodicPing()\n"
"            );\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2376
#, no-wrap
msgid ""
"Multi<String> emitAPeriodicPing() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))\n"
"            .onItem().transform(x -> \"{}\");\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2384
#, no-wrap
msgid ""
"private String toJson(Fruit f) {\n"
"    try {\n"
"        return mapper.writeValueAsString(f);\n"
"    } catch (JsonProcessingException e) {\n"
"        throw new RuntimeException(e);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2388
#, fuzzy
msgid "The workaround is a bit more complex as besides sending the fruits coming from Kafka, we need to send pings periodically.  To achieve this we merge the stream coming from Kafka and a periodic stream emitting `{}` every 10 seconds."
msgstr "这个解决方法有点复杂，因为除了发送来自Kafka的水果，我们还需要定期发送ping。为了实现这一点，我们合并了来自Kafka的数据流和一个周期性的数据流，每10秒发射一次 `{}` 。"

#. type: Title ==
#: upstream/_guides/kafka.adoc:2389
#, fuzzy, no-wrap
msgid "Logging"
msgstr "伐木"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2392
#, fuzzy
msgid "To reduce the amount of log written by the Kafka client, Quarkus sets the level of the following log categories to `WARNING`:"
msgstr "为了减少Kafka客户端写入的日志量，Quarkus将以下日志类别的级别设置为 `WARNING` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2394
#, fuzzy
msgid "`org.apache.kafka.clients`"
msgstr " `org.apache.kafka.clients` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2395
#, fuzzy
msgid "`org.apache.kafka.common.utils`"
msgstr " `org.apache.kafka.common.utils` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2396
#, fuzzy
msgid "`org.apache.kafka.common.metrics`"
msgstr " `org.apache.kafka.common.metrics` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2398
#, fuzzy
msgid "You can override the configuration by adding the following lines to the `application.properties`:"
msgstr "你可以通过在 `application.properties` 中添加以下几行来覆盖配置。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2404
#, no-wrap
msgid ""
"quarkus.log.category.\"org.apache.kafka.clients\".level=INFO\n"
"quarkus.log.category.\"org.apache.kafka.common.utils\".level=INFO\n"
"quarkus.log.category.\"org.apache.kafka.common.metrics\".level=INFO\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka.adoc:2406
#, fuzzy, no-wrap
msgid "Connecting to Managed Kafka clusters"
msgstr "连接到管理的Kafka集群"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2409
#, fuzzy
msgid "This section explains how to connect to notorious Kafka Cloud Services."
msgstr "本节解释了如何连接到臭名昭著的Kafka云服务。"

#. type: Title ===
#: upstream/_guides/kafka.adoc:2410
#, fuzzy, no-wrap
msgid "Azure Event Hub"
msgstr "Azure事件中心"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2413
#, fuzzy
msgid "https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview[Azure Event Hub] provides an endpoint compatible with Apache Kafka."
msgstr "link:https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview[Azure Event Hub] 提供了一个与Apache Kafka兼容的端点。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2417
#, fuzzy
msgid "Azure Event Hubs for Kafka is not available in the _basic_ tier.  You need at least the _standard_ tier to use Kafka.  See https://azure.microsoft.com/en-us/pricing/details/event-hubs/[Azure Event Hubs Pricing] to see the other options."
msgstr "Azure Event Hubs for Kafka在 _基本_ 层中不可用。你至少需要 _标准_ 层才能使用Kafka。请参阅 link:https://azure.microsoft.com/en-us/pricing/details/event-hubs/[Azure Event Hubs定价] ，查看其他选项。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2419
#, fuzzy
msgid "To connect to Azure Event Hub, using the Kafka protocol with TLS, you need the following configuration:"
msgstr "要连接到Azure Event Hub，使用带有TLS的Kafka协议，你需要以下配置。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2428
#, no-wrap
msgid ""
"kafka.bootstrap.servers=my-event-hub.servicebus.windows.net:9093 # <1>\n"
"kafka.security.protocol=SASL_SSL\n"
"kafka.sasl.mechanism=PLAIN\n"
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\ # <2>\n"
"    username=\"$ConnectionString\" \\ # <3>\n"
"    password=\"<YOUR.EVENTHUBS.CONNECTION.STRING>\"; # <4>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2430
#, fuzzy
msgid "The port is `9093`."
msgstr "该端口为 `9093` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2431
#, fuzzy
msgid "You need to use the JAAS `PlainLoginModule`."
msgstr "你需要使用JAAS `PlainLoginModule` 。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2432
#, fuzzy
msgid "The username is the `$ConnectionString` string."
msgstr "用户名是指 `$ConnectionString` 字符串。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2433
#, fuzzy
msgid "The Event Hub connection string given by Azure."
msgstr "由Azure提供的Event Hub连接字符串。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2437
#, fuzzy
msgid "Replace `<YOUR.EVENTHUBS.CONNECTION.STRING>` with the connection string for your Event Hubs namespace.  For instructions on getting the connection string, see https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string[Get an Event Hubs connection string].  The result would be something like:"
msgstr "用您的Event Hubs命名空间的连接字符串替换 `<YOUR.EVENTHUBS.CONNECTION.STRING>` 。有关获取连接字符串的说明，请参阅 link:https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string[获取Event Hubs连接字符串] 。结果会是这样的。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2443
#, no-wrap
msgid ""
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"    username=\"$ConnectionString\" \\\n"
"    password=\"Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX\";\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2446
#, fuzzy
msgid "This configuration can be global (as above), or set in the channel configuration:"
msgstr "这个配置可以是全局的（如上），也可以在通道配置中设置。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2455
#, no-wrap
msgid ""
"mp.messaging.incoming.$channel.bootstrap.servers=my-event-hub.servicebus.windows.net:9093\n"
"mp.messaging.incoming.$channel.security.protocol=SASL_SSL\n"
"mp.messaging.incoming.$channel.sasl.mechanism=PLAIN\n"
"mp.messaging.incoming.$channel.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"    username=\"$ConnectionString\" \\\n"
"    password=\"Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=...\";\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka.adoc:2457
#, fuzzy, no-wrap
msgid "Red Hat OpenShift Streams for Apache Kafka"
msgstr "红帽OpenShift Streams for Apache Kafka"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2462
#, fuzzy
msgid "https://cloud.redhat.com/[Red Hat OpenShift Streams for Apache Kafka] provides managed Kafka brokers.  First, follow the instructions from https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the `rhoas` CLI for Red Hat OpenShift Streams for Apache Kafka] to create your Kafka broker instance.  Make sure you copied the client id and client secret associated with the _ServiceAccount_ you created."
msgstr "link:https://cloud.redhat.com/[Red Hat OpenShift Streams for Apache Kafka] 提供了可管理的Kafka经纪人。首先，按照 link:https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Red Hat OpenShift Streams for Apache Kafka的 `rhoas` CLI入门] 的说明，创建你的Kafka经纪人实例。确保你复制了与你创建的 _ServiceAccount_ 相关的客户ID和客户秘密。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2464
#, fuzzy
msgid "Then, you can configure the Quarkus application to connect to the broker as follows:"
msgstr "然后，你可以配置Quarkus应用程序以连接到经纪人，如下所示。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2473
#, no-wrap
msgid ""
"kafka.bootstrap.servers=<connection url> # <1>\n"
"kafka.security.protocol=SASL_SSL\n"
"kafka.sasl.mechanism=PLAIN\n"
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"  username=\"${KAFKA_USERNAME}\" \\ # <2>\n"
"  password=\"${KAFKA_PASSWORD}\"; # <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2475
#, fuzzy
msgid "The connection string, given on the admin console, such as `demo-c--bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443`"
msgstr "连接字符串，在管理控制台给出，例如 `demo-c—​bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443` "

#. type: Plain text
#: upstream/_guides/kafka.adoc:2476
#, fuzzy
msgid "The kafka username (the client id from the service account)"
msgstr "kafka的用户名（来自服务账户的客户端ID）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2477
#, fuzzy
msgid "the kafka password (the client secret from the service account)"
msgstr "kafka密码（来自服务账户的客户秘密）。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2479
#, fuzzy
msgid "In general, these properties are prefixed using `%prod` to enable them only when running in production mode."
msgstr "一般来说，这些属性的前缀是使用 `%prod` ，以便只在生产模式下运行时启用。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2482
#, fuzzy
msgid "As explained in https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka], to use Red Hat OpenShift Streams for Apache Kafka, you must create the topic beforehand, create a _Service Account_, and provide permissions to read and write to your topic from that service account.  The authentication data (client id and secret) relates to the service account, which means you can implement fine-grain permissions and restrict access to the topic."
msgstr "正如在《 link:https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kaf] ka》中所解释的那样，要使用Red Hat OpenShift Streams for Apache Kafka，你必须事先创建主题，创建一个 _服务账户_ ，并提供从该服务账户读取和写入主题的权限。认证数据（客户端ID和秘密）与服务账户有关，这意味着你可以实现细粒度的权限，并限制对主题的访问。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2484
#, fuzzy
msgid "When using Kubernetes, it is recommended to set the client id and secret in a Kubernetes secret:"
msgstr "当使用Kubernetes时，建议在Kubernetes秘密中设置客户端ID和秘密。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2494
#, no-wrap
msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: kafka-credentials\n"
"stringData:\n"
"  KAFKA_USERNAME: \"...\"\n"
"  KAFKA_PASSWORD: \"...\"\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka.adoc:2497
#, fuzzy
msgid "To allow your Quarkus application to use that secret, add the following line to the `application.properties` file:"
msgstr "为了允许你的Quarkus应用程序使用该秘密，请在 `application.properties` 文件中添加以下一行。"

#. type: delimited block -
#: upstream/_guides/kafka.adoc:2501
#, no-wrap
msgid "%prod.quarkus.openshift.env.secrets=kafka-credentials\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka.adoc:2503
#, fuzzy, no-wrap
msgid "Going further"
msgstr "更进一步"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2507
#, fuzzy
msgid "This guide has shown how you can interact with Kafka using Quarkus.  It utilizes SmallRye Reactive Messaging to build data streaming applications."
msgstr "本指南已经展示了如何使用Quarkus与Kafka进行交互。它利用SmallRye Reactive Messaging来构建数据流应用。"

#. type: Plain text
#: upstream/_guides/kafka.adoc:2508
msgid "If you want to go further, check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus."
msgstr ""
