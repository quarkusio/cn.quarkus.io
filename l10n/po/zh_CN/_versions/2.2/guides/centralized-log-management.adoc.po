# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-05-12 15:59+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:6
#, no-wrap
msgid "Centralized log management (Graylog, Logstash, Fluentd)"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:13
msgid "This guide explains how you can send your logs to a centralized log management system like Graylog, Logstash (inside the Elastic Stack or ELK - Elasticsearch, Logstash, Kibana) or Fluentd (inside EFK - Elasticsearch, Fluentd, Kibana)."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:16
msgid "There are a lot of different ways to centralize your logs (if you are using Kubernetes, the simplest way is to log to the console and ask you cluster administrator to integrate a central log manager inside your cluster).  In this guide, we will expose how to send them to an external tool using the `quarkus-logging-gelf` extension that can use TCP or UDP to send logs in the Graylog Extended Log Format (GELF)."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:19
msgid "The `quarkus-logging-gelf` extension will add a GELF log handler to the underlying logging backend that Quarkus uses (jboss-logmanager).  By default, it is disabled, if you enable it but still use another handler (by default the console handler is enabled), your logs will be sent to both handlers."
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:20
#, no-wrap
msgid "Example application"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:23
msgid "The following examples will all be based on the same example application that you can create with the following steps."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:25
msgid "Create an application with the `quarkus-logging-gelf` extension. You can use the following Maven command to create it:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:34
#, no-wrap
msgid ""
"mvn io.quarkus.platform:quarkus-maven-plugin:{quarkus-version}:create \\\n"
"    -DprojectGroupId=org.acme \\\n"
"    -DprojectArtifactId=gelf-logging \\\n"
"    -DclassName=\"org.acme.quickstart.GelfLoggingResource\" \\\n"
"    -Dpath=\"/gelf-logging\" \\\n"
"    -Dextensions=\"resteasy,logging-gelf\"\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:38
msgid "If you already have your Quarkus project configured, you can add the `logging-gelf` extension to your project by running the following command in your project base directory:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:42
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"logging-gelf\"\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:45
msgid "This will add the following to your `pom.xml`:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:52
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-logging-gelf</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:55
msgid "For demonstration purposes, we create an endpoint that does nothing but log a sentence. You don't need to do this inside your application."
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:61
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:63
#, no-wrap
msgid "import org.jboss.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:68
#, no-wrap
msgid ""
"@Path(\"/gelf-logging\")\n"
"@ApplicationScoped\n"
"public class GelfLoggingResource {\n"
"    private static final Logger LOG = Logger.getLogger(GelfLoggingResource.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:73
#, no-wrap
msgid ""
"    @GET\n"
"    public void log() {\n"
"        LOG.info(\"Some useful log message\");\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:75
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:78
msgid "Configure the GELF log handler to send logs to an external UDP endpoint on the port 12201:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:84
#, no-wrap
msgid ""
"quarkus.log.handler.gelf.enabled=true\n"
"quarkus.log.handler.gelf.host=localhost\n"
"quarkus.log.handler.gelf.port=12201\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:86
#, no-wrap
msgid "Send logs to Graylog"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:89
msgid "To send logs to Graylog, you first need to launch the components that compose the Graylog stack:"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:91
msgid "MongoDB"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:92
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:172
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:261
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:347
msgid "Elasticsearch"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:93
msgid "Graylog"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:95
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:176
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:265
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:351
msgid "You can do this via the following docker-compose file that you can launch via `docker-compose run -d`:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:99
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:269
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:355
#, no-wrap
msgid "version: '3.2'\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:109
#, no-wrap
msgid ""
"services:\n"
"  elasticsearch:\n"
"    image: docker.elastic.co/elasticsearch/elasticsearch-oss:{es-version}\n"
"    ports:\n"
"      - \"9200:9200\"\n"
"    environment:\n"
"      ES_JAVA_OPTS: \"-Xms512m -Xmx512m\"\n"
"    networks:\n"
"      - graylog\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:114
#, no-wrap
msgid ""
"  mongo:\n"
"    image: mongo:4.0\n"
"    networks:\n"
"      - graylog\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:128
#, no-wrap
msgid ""
"  graylog:\n"
"    image: graylog/graylog:3.1\n"
"    ports:\n"
"      - \"9000:9000\"\n"
"      - \"12201:12201/udp\"\n"
"      - \"1514:1514\"\n"
"    environment:\n"
"      GRAYLOG_HTTP_EXTERNAL_URI: \"http://127.0.0.1:9000/\"\n"
"    networks:\n"
"      - graylog\n"
"    depends_on:\n"
"      - elasticsearch\n"
"      - mongo\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:132
#, no-wrap
msgid ""
"networks:\n"
"  graylog:\n"
"    driver: bridge\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:136
msgid "Then, you need to create a UDP input in Graylog.  You can do it from the Graylog web console (System -> Input -> Select GELF UDP) available at http://localhost:9000 or via the API."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:138
msgid "This curl example will create a new Input of type GELF UDP, it uses the default login from Graylog (admin/admin)."
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:144
#, no-wrap
msgid ""
"curl -H \"Content-Type: application/json\" -H \"Authorization: Basic YWRtaW46YWRtaW4=\" -H \"X-Requested-By: curl\" -X POST -v -d \\\n"
"'{\"title\":\"udp input\",\"configuration\":{\"recv_buffer_size\":262144,\"bind_address\":\"0.0.0.0\",\"port\":12201,\"decompress_size_limit\":8388608},\"type\":\"org.graylog2.inputs.gelf.udp.GELFUDPInput\",\"global\":true}' \\\n"
"http://localhost:9000/api/system/inputs\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:147
msgid "Launch your application, you should see your logs arriving inside Graylog."
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:148
#, no-wrap
msgid "Send logs to Logstash / the Elastic Stack (ELK)"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:151
msgid "Logstash comes by default with an Input plugin that can understand the GELF format, we will first create a pipeline that enables this plugin."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:153
msgid "Create the following file in `$HOME/pipelines/gelf.conf`:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:167
#, no-wrap
msgid ""
"input {\n"
"  gelf {\n"
"    port => 12201\n"
"  }\n"
"}\n"
"output {\n"
"  stdout {}\n"
"  elasticsearch {\n"
"    hosts => [\"http://elasticsearch:9200\"]\n"
"  }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:170
msgid "Finally, launch the components that compose the Elastic Stack:"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:173
msgid "Logstash"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:174
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:263
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:349
msgid "Kibana"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:181
#, no-wrap
msgid ""
"# Launch Elasticsearch\n"
"version: '3.2'\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:192
#, no-wrap
msgid ""
"services:\n"
"  elasticsearch:\n"
"    image: docker.elastic.co/elasticsearch/elasticsearch-oss:{es-version}\n"
"    ports:\n"
"      - \"9200:9200\"\n"
"      - \"9300:9300\"\n"
"    environment:\n"
"      ES_JAVA_OPTS: \"-Xms512m -Xmx512m\"\n"
"    networks:\n"
"      - elk\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:207
#, no-wrap
msgid ""
"  logstash:\n"
"    image: docker.elastic.co/logstash/logstash-oss:{es-version}\n"
"    volumes:\n"
"      - source: $HOME/pipelines\n"
"        target: /usr/share/logstash/pipeline\n"
"        type: bind\n"
"    ports:\n"
"      - \"12201:12201/udp\"\n"
"      - \"5000:5000\"\n"
"      - \"9600:9600\"\n"
"    networks:\n"
"      - elk\n"
"    depends_on:\n"
"      - elasticsearch\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:216
#, no-wrap
msgid ""
"  kibana:\n"
"    image: docker.elastic.co/kibana/kibana-oss:{es-version}\n"
"    ports:\n"
"      - \"5601:5601\"\n"
"    networks:\n"
"      - elk\n"
"    depends_on:\n"
"      - elasticsearch\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:220
#, no-wrap
msgid ""
"networks:\n"
"  elk:\n"
"    driver: bridge\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:224
msgid "Launch your application, you should see your logs arriving inside the Elastic Stack; you can use Kibana available at http://localhost:5601/ to access them."
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:225
#, no-wrap
msgid "Send logs to Fluentd (EFK)"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:229
msgid "First, you need to create a Fluentd image with the needed plugins: elasticsearch and input-gelf.  You can use the following Dockerfile that should be created inside a `fluentd` directory."
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:235
#, no-wrap
msgid ""
"FROM fluent/fluentd:v1.3-debian\n"
"RUN [\"gem\", \"install\", \"fluent-plugin-elasticsearch\", \"--version\", \"3.7.0\"]\n"
"RUN [\"gem\", \"install\", \"fluent-plugin-input-gelf\", \"--version\", \"0.3.1\"]\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:238
msgid "You can build the image or let docker-compose build it for you."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:240
msgid "Then you need to create a fluentd configuration file inside `$HOME/fluentd/fluent.conf`"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:249
#, no-wrap
msgid ""
"<source>\n"
"  type gelf\n"
"  tag example.gelf\n"
"  bind 0.0.0.0\n"
"  port 12201\n"
"</source>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:256
#, no-wrap
msgid ""
"<match example.gelf>\n"
"  @type elasticsearch\n"
"  host elasticsearch\n"
"  port 9200\n"
"  logstash_format true\n"
"</match>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:259
msgid "Finally, launch the components that compose the EFK Stack:"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:262
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:348
msgid "Fluentd"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:280
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:366
#, no-wrap
msgid ""
"services:\n"
"  elasticsearch:\n"
"    image: docker.elastic.co/elasticsearch/elasticsearch-oss:{es-version}\n"
"    ports:\n"
"      - \"9200:9200\"\n"
"      - \"9300:9300\"\n"
"    environment:\n"
"      ES_JAVA_OPTS: \"-Xms512m -Xmx512m\"\n"
"    networks:\n"
"      - efk\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:293
#, no-wrap
msgid ""
"  fluentd:\n"
"    build: fluentd\n"
"    ports:\n"
"      - \"12201:12201/udp\"\n"
"    volumes:\n"
"      - source: $HOME/fluentd\n"
"        target: /fluentd/etc\n"
"        type: bind\n"
"    networks:\n"
"      - efk\n"
"    depends_on:\n"
"      - elasticsearch\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:302
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:388
#, no-wrap
msgid ""
"  kibana:\n"
"    image: docker.elastic.co/kibana/kibana-oss:{es-version}\n"
"    ports:\n"
"      - \"5601:5601\"\n"
"    networks:\n"
"      - efk\n"
"    depends_on:\n"
"      - elasticsearch\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:306
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:392
#, no-wrap
msgid ""
"networks:\n"
"  efk:\n"
"    driver: bridge\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:309
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:406
msgid "Launch your application, you should see your logs arriving inside EFK: you can use Kibana available at http://localhost:5601/ to access them."
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:310
#, no-wrap
msgid "GELF alternative: use Syslog"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:314
msgid "You can also send your logs to Fluentd using a Syslog input.  As opposed to the GELF input, the Syslog input will not render multiline logs in one event, that's why we advise to use the GELF input that we implement in Quarkus."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:317
msgid "First, you need to create a Fluentd image with the elasticsearch plugin.  You can use the following Dockerfile that should be created inside a `fluentd` directory."
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:322
#, no-wrap
msgid ""
"FROM fluent/fluentd:v1.3-debian\n"
"RUN [\"gem\", \"install\", \"fluent-plugin-elasticsearch\", \"--version\", \"3.7.0\"]\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:325
msgid "Then, you need to create a fluentd configuration file inside `$HOME/fluentd/fluent.conf`"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:335
#, no-wrap
msgid ""
"<source>\n"
"  @type syslog\n"
"  port 5140\n"
"  bind 0.0.0.0\n"
"  message_format rfc5424\n"
"  tag system\n"
"</source>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:342
#, no-wrap
msgid ""
"<match **>\n"
"  @type elasticsearch\n"
"  host elasticsearch\n"
"  port 9200\n"
"  logstash_format true\n"
"</match>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:345
msgid "Then, launch the components that compose the EFK Stack:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:379
#, no-wrap
msgid ""
"  fluentd:\n"
"    build: fluentd\n"
"    ports:\n"
"      - \"5140:5140/udp\"\n"
"    volumes:\n"
"      - source: $HOME/fluentd\n"
"        target: /fluentd/etc\n"
"        type: bind\n"
"    networks:\n"
"      - efk\n"
"    depends_on:\n"
"      - elasticsearch\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:395
msgid "Finally, configure your application to send logs to EFK using Syslog:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:403
#, no-wrap
msgid ""
"quarkus.log.syslog.enable=true\n"
"quarkus.log.syslog.endpoint=localhost:5140\n"
"quarkus.log.syslog.protocol=udp\n"
"quarkus.log.syslog.app-name=quarkus\n"
"quarkus.log.syslog.hostname=quarkus-test\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:407
#, no-wrap
msgid "Elasticsearch indexing consideration"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:412
msgid "Be careful that, by default, Elasticsearch will automatically map unknown fields (if not disabled in the index settings) by detecting their type.  This can become tricky if you use log parameters (which are included by default), or if you enable MDC inclusion (disabled by default), as the first log will define the type of the message parameter (or MDC parameter) field inside the index."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:414
msgid "Imagine the following case:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:419
#, no-wrap
msgid ""
"LOG.info(\"some {} message {} with {} param\", 1, 2, 3);\n"
"LOG.info(\"other {} message {} with {} param\", true, true, true);\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:424
msgid "With log message parameters enabled, the first log message sent to Elasticsearch will have a `MessageParam0` parameter with an `int` type; this will configure the index with a field of type `integer`.  When the second message will arrive to Elasticsearch, it will have a `MessageParam0` parameter with the boolean value `true`, and this will generate an indexing error."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:427
msgid "To work around this limitation, you can disable sending log message parameters via `logging-gelf` by configuring `quarkus.log.handler.gelf.include-log-message-parameters=false`, or you can configure your Elasticsearch index to store those fields as text or keyword, Elasticsearch will then automatically make the translation from int/boolean to a String."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:429
msgid "See the following documentation for Graylog (but the same issue exists for the other central logging stacks): link:https://docs.graylog.org/en/3.2/pages/configuration/elasticsearch.html#custom-index-mappings[Custom Index Mappings]."
msgstr ""

#. type: Title ==
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:431
#, no-wrap
msgid "Configuration Reference"
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:434
msgid "Configuration is done through the usual `application.properties` file."
msgstr ""

#. type: Plain text
#: upstream/_versions/2.2/guides/centralized-log-management.adoc:438
msgid "This extension uses the `logstash-gelf` library that allow more configuration options via system properties, you can access its documentation here: https://logging.paluch.biz/ ."
msgstr ""
