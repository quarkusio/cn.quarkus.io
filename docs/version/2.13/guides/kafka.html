<!DOCTYPE html>
<html lang="cn">







<head>
  <title>Apache Kafka参考指南 - 2.13 - Quarkus</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Security-Policy" content="
  connect-src 'self' https://dpm.demdex.net https://adobedc.demdex.net https://analytics.ossupstream.org/ https://search.quarkus.io https://smetrics.redhat.com; 
  script-src 'self' 'unsafe-inline' 'unsafe-eval'
      
      https://assets.adobedtm.com
      js.bizographics.com
      https://www.redhat.com
      https://static.redhat.com
      https://app.requestly.io/
      jsonip.com
      https://ajax.googleapis.com
      https://use.fontawesome.com
      http://www.youtube.com
      http://www.googleadservices.com
      https://googleads.g.doubleclick.net
      https://giscus.app
      https://analytics.ossupstream.org/
      https://app.mailjet.com;

  style-src 'self' https://fonts.googleapis.com https://use.fontawesome.com; 
  img-src 'self' * data:; 
  media-src 'self'; 
  frame-src https://redhat.demdex.net https://www.youtube.com https://player.restream.io https://app.mailjet.com http://xy0p2.mjt.lu https://mj.quarkus.io https://giscus.app; 
  base-uri 'none'; 
  object-src 'none'; 
  form-action 'none'; 
  font-src 'self' https://use.fontawesome.com https://fonts.gstatic.com;" />
  <script id="adobe_dtm" src="https://www.redhat.com/dtm.js" type="text/javascript"></script>
  <script src="/assets/javascript/highlight.pack.js" type="text/javascript"></script>
  <META HTTP-EQUIV='X-XSS-Protection' CONTENT="1; mode=block">
  <META HTTP-EQUIV='X-Content-Type-Options' CONTENT="nosniff">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Quarkus: Supersonic Subatomic Java">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@QuarkusIO"> 
  <meta name="twitter:creator" content="@QuarkusIO">
  <meta property="og:url" content="https://quarkus.io/version/2.13/guides/kafka" />
  <meta property="og:title" content="Apache Kafka参考指南 - 2.13" />
  <meta property="og:description" content="Quarkus: Supersonic Subatomic Java" />
  <meta property="og:image" content="https://quarkus.io/assets/images/quarkus_card.png" />
  
  <link rel="canonical" href="https://quarkus.io/guides/kafka">
  <link rel="shortcut icon" type="image/png" href="/favicon.ico" >
  <link rel="stylesheet" href="/guides/stylesheet/config.css" />
  <link rel="stylesheet" href="/assets/css/main.css?2021-07-29" />
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.5.2/css/all.css" crossorigin="anonymous">
  <link rel="alternate" type="application/rss+xml"  href="/feed.xml" title="Quarkus">
  <script src="/assets/javascript/hl.js" type="text/javascript"></script>
  
  
  
  
  <link rel="alternate" hreflang="en" href="https://quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="pt-br" href="https://pt.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="es" href="https://es.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="zh" href="https://cn.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="ja" href="https://ja.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="x-default" href="https://quarkus.io/" />  
  <script src="/assets/javascript/tracking.js"></script>
  
  <script src="/assets/javascript/colormode.js" type="text/javascript"></script>

</head>

<body class="guides">

  


<div class="grid-wrapper communitysite">
  <div class="grid__item width-12-12">The <a href="https://quarkus.io/version/2.13/guides/kafka">English version of quarkus.io</a> is the official project site. Translated sites are community supported on a best-effort basis.</div>
</div>


  <div class="nav-wrapper">
  <div class="grid-wrapper">
    <div class="width-12-12">
      <input type="checkbox" id="checkbox" />
      <nav id="main-nav" class="main-nav">
        <div class="logo-wrapper">
           <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_600px_reverse.png" class="project-logo" title="Quarkus"></a>
        </div>
    <label class="nav-toggle" for="checkbox"> <i class="fa fa-bars"></i>
</label>
    <ul id="menu" class="menu">
      <li class="dropdown">
        <span href="#">Why<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/about" class="">QUARKUS是什么？</a></li>
          <li><a href="/developer-joy" class="">开发者的乐趣 </a></li>
          <li><a href="/performance" class="">PERFORMANCE</a></li>
          <li><a href="/kubernetes-native" class="">KUBERNETES 原生</a></li>
          <li><a href="/standards" class="">标准</a></li>
          <li><a href="/versatility" class="">VERSATILITY</a></li>
          <li><a href="/container-first" class="">容器优先 </a></li>
          <li><a href="/spring" class="">USING SPRING?</a></li>
          <li class="tertiarydropdown">
            <span href="#">AI<i class="fas fa-chevron-down"></i></span>
            <ul class="tertiarymenu">
              <li><a href="/ai" class="">AI OVERVIEW</a></li>
              <li><a href="/java-for-ai" class="">JAVA FOR AI</a></li>
              <li><a href="/quarkus-for-ai" class="">WHY QUARKUS FOR AI</a></li>
              <li><a href="/ai-blueprints" class="">AI BLUEPRINTS</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="#">Learn<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/get-started" class="">入门</a></li>
          <li><a href="/guides" class="active" >指南</a></li>
          <li><a href="/userstories/" class="">USER STORIES</a></li>  
          <li><a href="/qtips" class="">"Q" TIP视频</a></li>          
          <li><a href="/books" class="">书籍</a></li>
          </ul>
      </li>
      <li class="dropdown">
        <span href="#">Extensions<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          
          <!-- Note that quarkus.io is hardcoded here, because it is the only url which supports extensions -->
<li><a href="https://quarkus.io/extensions/" class="">浏览扩展</a></li>
          <li><a href="/faq/#what-is-a-quarkus-extension" class="">使用扩展</a></li>
          <li><a href="/guides/writing-extensions" class="" >创建扩展</a></li>
          <li><a href="https://hub.quarkiverse.io" class="">SHARE EXTENSIONS</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="#">Community<i class="fas fa-chevron-down firsti"></i></span>
        <ul class="submenu">
          <li><a href="/support/" class="">支持</a></li>
          <li><a href="/blog" class="" >博客</a></li>
          <li><a href="/discussion" class="">讨论</a></li>
          <li><a href="/working-groups" class="">WORKING GROUPS</a></li>
          <li><a href="/insights" class="" >播客</a></li>
          <li><a href="/events" class="">活动</a></li>
          <li><a href="/newsletter" class="">新闻</a></li>
          <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" class="">路线图</a></li>
          <li><a href="/benefactors" class="">BENEFACTORS</a></li>
          </ul>
      </li>
      <li>
        <a href="https://code.quarkus.io" class="button-cta secondary
white">开始编码</a>
      </li>
      <li class="dropdown">
        <span href="/language/"><div class="fas fa-globe langicon"></div><i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="https://quarkus.io/version/2.13/guides/kafka" >OFFICIAL (ENGLISH)</a></li>
          <li><a href="https://pt.quarkus.io/version/2.13/guides/kafka">PORTUGUÊS (BR)</a></li>
          <li><a href="https://es.quarkus.io/version/2.13/guides/kafka">ESPAÑOL</a></li>
          <li><a href="https://cn.quarkus.io/version/2.13/guides/kafka">简体中文</a></li>
          <li><a href="https://ja.quarkus.io/version/2.13/guides/kafka">日本語</a></li>
          </ul>
      </li>
      <li>
        <span href="#" class="modeswitcher" id='theme-toggle'><i class="fas
fa-sun"></i><i class="fas fa-moon"></i><i class="fas fa-cog"></i></span>
      </li>
    </ul>
      </nav>
    </div>
  </div>
</div>

  <div class="content">
    





<section class="full-width-version-bg flexfilterbar guides">
  <div class="guideflexcontainer">
    <div class="docslink">
      <a class="returnlink" href="/version/2.13/guides/">返回指南目录</a>
    </div>
    <div class="flexlabel">
      <label>选择指南版本</label>
    </div>
    <div class="guidepulldown version">
    <select id="guide-version-dropdown">
      
        
        
        <option value="main" >Main - SNAPSHOT</option>
        
        
        
        <option value="latest" >3.28.5 - Latest</option>
        
        
        
        <option value="3.27" >3.27</option>
        
        
        
        <option value="3.20" >3.20</option>
        
        
        
        <option value="3.15" >3.15</option>
        
        
        
        <option value="3.8" >3.8</option>
        </select>
    </div>
  </div>
</section>

<div class="guide">
  <div class="grid-wrapper">
    <div class="grid__item width-8-12 width-12-12-m">
      <h1 class="text-caps">Apache Kafka参考指南 </h1>
      <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>本参考指南展示了如何在您的Quarkus应用程序中利用SmallRye Reactive Messaging与Apache Kafka进行交互。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>1. 简介</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://kafka.apache.org">Apache Kafka</a> 是一个流行的开源分布式事件流平台。它通常用于高性能数据管道、流式分析、数据集成以及任务关键型应用。类似于消息队列或企业消息平台，它可以允许您：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>发布</strong> (写)以及 <strong>订阅</strong> (读)事件流，称为 <em>记录</em> 。
</p>
</li>
<li>
<p>在 <em>topic</em> 内持久而可靠地 <strong>存储</strong> 流式记录。
</p>
</li>
<li>
<p>对流式记录进行起始或回溯*处理*。
</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>而所有这些功能都是以分布式、高可扩展性、弹性、容错以及安全的方式提供的。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="quarkus-extension-for-apache-kafka"><a class="anchor" href="#quarkus-extension-for-apache-kafka"></a>2. Apache Kafka Quarkus扩展</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus通过 <a href="https://smallrye.io/smallrye-reactive-messaging/">SmallRye Reactive Messaging</a> 框架为Apache Kafka提供支持。基于Eclipse MicroProfile Reactive Messaging 2.0 规范，框架提供了一种灵活的基于CDI和事件驱动的编程模型。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>本指南深入介绍了Apache Kafka和SmallRye Reactive Messaging框架。要想快速入门，请参考 <a href="kafka-reactive-getting-started">Getting Started to SmallRye Reactive Messaging with Apache Kafka</a> 。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>您可以通过在您的项目根目录下运行以下命令来将 <code>smallrye-reactive-messaging-kafka</code> 扩展添加到您的项目中：</p>
</div>
<div class="listingblock primary asciidoc-tabs-sync-cli">
<div class="title">CLI</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">quarkus extension add 'smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-maven">
<div class="title">Maven</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./mvnw quarkus:add-extension -Dextensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-gradle">
<div class="title">Gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./gradlew addExtension --extensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="paragraph">
<p>这会将以下内容添加到你的构建文件中:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-smallrye-reactive-messaging-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-smallrye-reactive-messaging-kafka")</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The extension includes <code>kafka-clients</code> version 3.2.1 as a transitive dependency and is compatible with Kafka brokers version 2.x.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="configuring-smallrye-kafka-connector"><a class="anchor" href="#configuring-smallrye-kafka-connector"></a>3. 配置Smallrye Kafka Connector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为Smallrye Reactive Messaging框架支持不同的消息后端，如Apache Kafka，AMQP，Apache Camel，JMS以及MQTT等，所以它使用了一个通用的术语表：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>应用程序发送和接收 <strong>messages</strong> 。一条消息包含一个 <em>payload</em> ，并可以用一些 <em>metadata</em> 进行扩展。通过Kafka connector，一条 <em>message</em> 对应于一条Kafka <em>record</em>。</p>
</li>
<li>
<p>信息在 <strong>channels</strong> 上传输。应用程序组件通过连接 channels 来发布和消费消息。Kafka connector将 <em>channels</em> 映射到Kafka的 _topics_上 。</p>
</li>
<li>
<p>Channels 通过 <strong>connectors</strong> 连接到消息后端。Connectors通过配置将传入的消息映射到一个指定channel上(该channel由应用程序来消费)，并对发送到指定channel的消息进行收集。每个connector都专用于某种特定的消息传递技术。例如，与Kafka交互的的connector被命名为 <code>smallrye-kafka</code> 。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>一个配有消息接收channel的Kafka connector的最小配置如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.incoming.prices.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>请务必为生产环境配置broker地址。您可以在全局环境配置或使用 <code>mp.messaging.incoming.$channel.bootstrap.servers</code> 属性来针对特定channel配置。在开发模式和运行测试时， <a href="#kafka-dev-services">Kafka开发服务（Dev Services）</a>会自动启动一个Kafka broker。如果没有提供这个属性，则默认为 <code>localhost:9092</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Configure the connector to manage the prices channel. By default, the topic name is same as the channel name. You can configure the topic attribute to override it.</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>%prod</code> 前缀表示该属性只在应用程序运行在生产模式下时生效(而不是在开发或测试模式)。更多细节请参考 <a href="config-reference#profiles">Profile documentation</a>。
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">连接器自动连接</div>
<div class="paragraph">
<p>如果在你的classpath上有一个连接器，你可以省略 <code>connector</code> 属性配置。Quarkus会自动将 <em>orphan</em> 通道与classpath上找到的（唯一的）连接器联系起来。 <em>Orphans</em> 通道是没有下游消费者的传出通道或没有上游生产者的传入通道。</p>
</div>
<div class="paragraph">
<p>可以用以下方法禁用这种自动连接功能：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.auto-connector-attachment=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="receiving-messages-from-kafka"><a class="anchor" href="#receiving-messages-from-kafka"></a>4. 接收来自Kafka的消息</h2>
<div class="sectionbody">
<div class="paragraph">
<p>让我们继续刚才的最小配置。您的Quarkus应用程序可以直接接收消息payload：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceConsumer {

    @Incoming("prices")
    public void consume(double price) {
        // process your price.
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>您的应用程序还可以通过另外集中方式来消费接收到的消息：</p>
</div>
<div class="listingblock">
<div class="title">Message</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consume(Message&lt;Double&gt; msg) {
    // access record metadata
    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();
    // process the message payload.
    double price = msg.getPayload();
    // Acknowledge the incoming message (commit the offset)
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Message</code> 类型允许consuming methond访问接收到消息的metadata并手动进行确认。我们将在 <a href="#commit-strategies">提交策略(Commit Strategies)</a>中探讨不同的确认策略。</p>
</div>
<div class="paragraph">
<p>如果您想直接访问Kafka record对象，请使用：</p>
</div>
<div class="listingblock">
<div class="title">ConsumerRecord</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(ConsumerRecord&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
    String topic = record.topic();
    int partition = record.partition();
    // ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ConsumerRecord</code> 由底层Kafka client提供，并且可以直接注入到consumer method中。另一种更简单的方法是使用  <code>Record</code>：</p>
</div>
<div class="listingblock">
<div class="title">Record</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(Record&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Record</code> 提供了对接收到的Kafka record中key和payload的简单的包装。</p>
</div>
<div class="paragraph">
<div class="title">@Channel</div>
<p>另外，您的应用程序可以在您的Bean中注入一个 <code>Multi</code> ，然后像下面的例子那样订阅它的事件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import io.smallrye.reactive.messaging.annotations.Channel;

import javax.inject.Inject;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import org.jboss.resteasy.reactive.RestStreamElementType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("prices")
    Multi&lt;Double&gt; prices;

    @GET
    @Path("/prices")
    @RestStreamElementType(MediaType.TEXT_PLAIN)
    public Multi&lt;Double&gt; stream() {
        return prices;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个例子很好的展示了如何将Kafka consumer与另一个downstream进行集成。在这个例子中，我们将这个downstream暴露为一个服务端事件节点(Server-Sent Events endpoint)。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>当使用 <code>@Channel</code> 消费消息时，代码需要负责消息订阅。在上面的例子中，RESTEasy Reactive endpoint 已负责为您处理了这个问题。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>以下类型可以作为 channels 被注入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject @Channel("prices") Multi&lt;Double&gt; streamOfPayloads;

@Inject @Channel("prices") Multi&lt;Message&lt;Double&gt;&gt; streamOfMessages;

@Inject @Channel("prices") Publisher&lt;Double&gt; publisherOfPayloads;

@Inject @Channel("prices") Publisher&lt;Message&lt;Double&gt;&gt; publisherOfMessages;</code></pre>
</div>
</div>
<div class="paragraph">
<p>如前面 <code>Message</code> 例子所示，如果您的注入channel接收到了playloads( <code>Multi&lt;T&gt;</code> )，它可以支持多订阅者自动确认消息。如果您的注入channel收到Message( <code>Multi&lt;Message&lt;T&gt;&gt;</code> )，那么您需要自行负责消息确认和广播。我们将在<a href="#broadcasting-messages-on-multiple-consumers">对多个消费者广播信息</a> 中探讨消息的发送和广播。</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>注入 <code>@Channel("prices")</code> 或使用 <code>@Incoming("prices")</code> 无法通过配置使应用程序自动从Kafka消费消息。您需要用 <code>mp.messaging.incoming.prices&#8230;&#8203;</code> 配置一个接收connector，或者在您的应用程序中使用 <code>@Outgoing("prices")</code> 方法(在这种情况下， <code>prices</code> 将是一个内存型channel)。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="blocking-processing"><a class="anchor" href="#blocking-processing"></a>4.1. 阻塞处理</h3>
<div class="paragraph">
<p>Reactive Messaging会在一个I/O线程中调用您的方法。关于这个话题的更多细节，请看  <a href="quarkus-reactive-architecture">Quarkus Reactive Architecture documentation</a>  。但是您可能需要经常将Reactive Messaging 与阻塞式处理相结合使用，比如与数据库通信。为此，您需要使用 <code>@Blocking</code> 注解来表该明处理是 <em>阻塞的</em> ，并且不在调用者线程中运行。</p>
</div>
<div class="paragraph">
<p>例如，下面的代码说明了如何使用带有Panache的Hibernate来将传入的有效载荷存储到数据库：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Blocking;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

@ApplicationScoped
public class PriceStorage {

    @Incoming("prices")
    @Transactional
    public void store(int priceInUsd) {
        Price price = new Price();
        price.value = priceInUsd;
        price.persist();
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>完整的例子可以参考 <code>kafka-panache-quickstart</code> <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-panache-quickstart">directory</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>有2个 <code>@Blocking</code> 注释：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>io.smallrye.reactive.messaging.annotations.Blocking</code> </p>
</li>
<li>
<p><code>io.smallrye.common.annotation.Blocking</code> </p>
</li>
</ol>
</div>
<div class="paragraph">
<p>它们效果相同。因此，您可以随意使用。第一个提供了更精细的配置，比如worker pool以及是否保留顺序。第二种，同其他的Quarkus Reactive功能类似，使用默认的worker pool并且保留了顺序。</p>
</div>
<div class="paragraph">
<p>Detailed information on the usage of <code>@Blocking</code> annotation can be found in <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/blocking/">SmallRye Reactive Messaging – Handling blocking execution</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">@Transactional</div>
<div class="paragraph">
<p>如果你的方法被注释为 <code>@Transactional</code> ，它将被自动视为 <em>blocking</em> ，即使该方法没有被注释为 <code>@Blocking</code> 。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="acknowledgment-strategies"><a class="anchor" href="#acknowledgment-strategies"></a>4.2. 确认策略(Acknowledgment Strategies)</h3>
<div class="paragraph">
<p>消费者收到的所有消息都必须被确认(acknowleged)。在没有确认的情况下，消息处理会出错。如果消费者方法收到一个 <code>Record</code> 或一个payload，该消息将通过方法返回被确认，也被称为 <code>Strategy.POST_PROCESSING</code> 。如果消费者方法返回另一个reactive stream或 <code>CompletionStage</code> ，那么当下游消息(downstream message)被确认时，该消息也将被确认。您可以覆盖默认行为从而在消息到达时进行确认( <code>Strategy.PRE_PROCESSING</code> )，或者在消费者方法中不进行任何确认( <code>Strategy.NONE</code> )，如下例所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)
public void process(double price) {
    // process price
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果消费者方法接收到一个 <code>Message</code> ，那么确认策略是 <code>Strategy.MANUAL</code> 并且消费者方法将负责对消息进行ack/nack。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; process(Message&lt;Double&gt; msg) {
    // process price
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如上所述，该方法还可以将确认策略设置为 <code>PRE_PROCESSING</code> 或 <code>NONE</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="commit-strategies"><a class="anchor" href="#commit-strategies"></a>4.3. 提交策略(Commit Strategies)</h3>
<div class="paragraph">
<p>当一条由Kafka记录产生的消息被确认时，connector将会调用一个提交策略。这些策略决定了特定topic/分区(topic/partition)的消费者偏移将在何时被提交。提交一个偏移量(offset)表明所有之前的记录已经被处理了。它也是应用程序从崩溃中恢复后或重启后重新开始处理的位置。</p>
</div>
<div class="paragraph">
<p>由于Kafka的偏移量管理可能很慢，所以每次提交偏移量都会有性能上的损失。然而，如果程序在两次提交之间崩溃，不够频繁的偏移量提交可能会导致消息出现重复提交。</p>
</div>
<div class="paragraph">
<p>Kafka connector支持三种策略：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>throttled</code> keeps track of received messages and commits an offset of the latest acked message in sequence (meaning, all previous messages were also acked).
This strategy guarantees at-least-once delivery even if the channel performs asynchronous processing.
The connector tracks the received records and periodically (period specified by <code>auto.commit.interval.ms</code>, default: 5000 ms) commits the highest consecutive offset.
The connector will be marked as unhealthy if a message associated with a record is not acknowledged in <code>throttled.unprocessed-record-max-age.ms</code> (default: 60000 ms).
Indeed, this strategy cannot commit the offset as soon as a single record processing fails (see <a href="#error-handling">错误处理策略(Error Handling Strategies)</a> to configure what happens on failing processing).
If <code>throttled.unprocessed-record-max-age.ms</code> is set to less than or equal to <code>0</code>, it does not perform any health check verification.
Such a setting might lead to running out of memory if there are "poison pill" messages (that are never acked).
This strategy is the default if <code>enable.auto.commit</code> is not explicitly set to true.</p>
</li>
<li>
<p><code>latest</code> 一旦关联消息被确认，Kafka消费者就会提交所接收到的record偏移量(前提是当前偏移量高于之前提交的偏移量)。如果channel在不执行任何异步处理的情况下处理消息的话，这种策略能保证至少一次提交。这种策略不推荐在高负载环境中使用，因为偏移量的提交很昂贵。但是它减少了消息重复提交的风险。</p>
</li>
<li>
<p><code>ignore</code> 不执行任何提交。当消费者的 <code>enable.auto.commit</code> 属性被明确配置为true时，该策略将是默认策略。它将偏移量的提交委托给底层Kafka client负责。当 <code>enable.auto.commit</code> 为true的时候 ，该策略 <strong>不</strong> 保证至少会有一次提交。SmallRye Reactive Messaging是异步处理记录的，所以那些已经被轮询但尚未处理的record的偏移量有可能会被提交。如果提交失败，只有那些尚未被提交的record才会被重新处理。</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>当Kafka connector没有明确启用时，它将禁用Kafka自动提交。这与传统的Kafka消费者不同。如果高吞吐量对您来说很重要而且您不受下游的限制，我们建议要么：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>使用 <code>throttled</code> 策略,</p>
</li>
<li>
<p>要么将 <code>enable.auto.commit</code> 设置为true，并在consuming方法中使用 <code>@Acknowledgment(Acknowledgment.Strategy.NONE)</code> 注解。</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Smallrye Reactive Messaging enables implementing custom commit strategies.
See <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">SmallRye Reactive Messaging documentation</a> for more information.</p>
</div>
</div>
<div class="sect2">
<h3 id="error-handling"><a class="anchor" href="#error-handling"></a>4.4. 错误处理策略(Error Handling Strategies)</h3>
<div class="paragraph">
<p>如果从Kafka record中产生的消息未被确认，那么一个失败策略就会被启用。Kafka connector支持三种策略：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>fail</code> ：直接使程序失败，不再处理更多的记录(默认策略)。未被正确处理的记录的偏移量不会被提交。</p>
</li>
<li>
<p><code>ignore</code> ：记录失败的日志，但消息处理将继续进行。没有被正确处理的记录的偏移量会被提交。</p>
</li>
<li>
<p><code>dead-letter-queue</code> ：未被正确处理的记录的偏移量会被提交，但该记录会被写入Kafka的dead letter topic。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>失败策略通过 <code>failure-strategy</code> 属性来设置。</p>
</div>
<div class="paragraph">
<p>在 <code>dead-letter-queue</code> 情况下 ，您可以配置以下属性：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>dead-letter-queue.topic</code> : 该topic用来保存未被正确处理的记录，默认为 <code>dead-letter-topic-$channel</code> ， <code>$channel</code> 是channel的名称。</p>
</li>
<li>
<p><code>dead-letter-queue.key.serializer</code> 该序列化器用来对记录到dead letter queue中的record key进行序列化。默认情况下，该序列化器会从key的反序列化器反推出。</p>
</li>
<li>
<p><code>dead-letter-queue.value.serializer</code> :该序列化器用来对记录到dead letter queue中的record value进行序列化。默认情况下，该序列化器会从value的反序列化器反推出。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>所有写入dead letter queue中的记录将包含一组关于原始记录的附加headers：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>dead-letter-reason</strong> ：失败原因
</p>
</li>
<li>
<p><strong>dead-letter-cause</strong> ：失败的起因(如果有)。
</p>
</li>
<li>
<p><strong>dead-letter-topic</strong> ：失败记录的原始topic
</p>
</li>
<li>
<p><strong>dead-letter-partition</strong> ：失败记录的原始分区(integer映射为String)
</p>
</li>
<li>
<p><strong>dead-letter-offset</strong> ：失败记录的原始偏移量(long映射为String)
</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Smallrye Reactive Messaging enables implementing custom failure strategies.
See <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">SmallRye Reactive Messaging documentation</a> for more information.</p>
</div>
<div class="sect3">
<h4 id="retrying-processing"><a class="anchor" href="#retrying-processing"></a>4.4.1. 重试处理(Retrying processing)</h4>
<div class="paragraph">
<p>您可以将Reactive Messaging与 <a href="https://github.com/smallrye/smallrye-fault-tolerance">SmallRye 容错</a>结合起来，如果失败的话可以进行重试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
public void consume(String v) {
   // ... retry if this method throws an exception
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>您可以对延迟，重试次数以及抖动(jitter)等处理方式进行设置。</p>
</div>
<div class="paragraph">
<p>如果您的方法返回一个 <code>Uni</code> 或 <code>CompletionStage</code> ，您需要添加 <code>@NonBlocking</code> 注解：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
@NonBlocking
public Uni&lt;String&gt; consume(String v) {
   // ... retry if this method throws an exception or the returned Uni produce a failure
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>@NonBlocking</code> 注解仅在SmallRye Fault Tolerance 5.1.0及之前版本中需要。从SmallRye Fault Tolerance 5.2.0开始(Quarkus 2.1.0.Final开始)，它就不再必须了。更多信息请参见<a href="https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode">SmallRye 容错文档</a> 。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>传入的消息只有在处理成功完成后才会被确认。所以，它在处理成功后会提交偏移量。如果在所有的重试后处理仍然失败， 消息就会被标记为 <em>未确认(nacked)</em> ，然后触发失败策略。</p>
</div>
</div>
<div class="sect3">
<h4 id="handling-deserialization-failures"><a class="anchor" href="#handling-deserialization-failures"></a>4.4.2. 反序列化失败的处理</h4>
<div class="paragraph">
<p>当反序列化失败发生时，您可以对其进行拦截并提供一个失败处理策略。为了实现这一点，您需要创建一个实现 <code>DeserializationFailureHandler&lt;T&gt;</code> 接口的bean：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-retry") // Set the name of the failure handler
public class MyDeserializationFailureHandler
    implements DeserializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public JsonObject decorateDeserialization(Uni&lt;JsonObject&gt; deserialization, String topic, boolean isKey,
            String deserializer, byte[] data, Headers headers) {
        return deserialization
                    .onFailure().retry().atMost(3)
                    .await().atMost(Duration.ofMillis(200));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>要使用这个故障处理的handler，Bean必须使用 <code>@Identifier</code> 限定符来暴露，并且connector配置必须指定属性 <code>mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler</code> (对于键或值的反序列化器)。</p>
</div>
<div class="paragraph">
<p>这个handler在被调用提供反序列化的细节，包括以 <code>Uni&lt;T&gt;</code> 所表示的操作(action)。在 <code>Uni</code> 提供的反序列化错误处理策略中，可以实现例如重试，提供回调(fallback)值或超时处理等等方式。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="consumer-groups"><a class="anchor" href="#consumer-groups"></a>4.5. 消费者组(Consumer Groups)</h3>
<div class="paragraph">
<p>在Kafka中，消费者组表示可以通过合作来消费来自于同一个topic的数据的一组消费者。 一个topic可以包含一组分区(partitions)。一个topic的分区会在组内的消费者之间分配，从而有效地提高消费的吞吐量。请注意，每个分区只会被分配给组内的一个消费者。但如果分区的数量大于组中消费者的数量， 那么一个消费者可以被分配多个分区。</p>
</div>
<div class="paragraph">
<p>让我们简单展示一下不同的生产者/消费者模式以及如何使用Quarkus来实现它们：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>消费者组内使用单一消费者线程</strong>
</p>
<div class="paragraph">
<p>这是一个应用程序订阅Kafka topic的默认方式：每个Kafka Connector将创建一个独立的消费者线程，并将其置于一个单独的消费者组内。消费者组id默认为 <code>quarkus.application.name</code> 所设定的应用程序名称。它也可以使用 <code>kafka.group.id</code> 来设置。</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-one-consumer.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>一个消费者组内使用多个消费者线程</strong> 
</p>
<div class="paragraph">
<p>对于一个给定的应用程序实例，消费者组内的消费者数量可以使用 <code>mp.messaging.incoming.$channel.partitions</code> 进行配置。被订阅的topic中的分区将会在所有的消费者线程间进行分配。请注意，如果 <code>partitions</code> 值超过topic本身的分区数量，那么某些消费者线程将得不到分区分配。</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-two-consumers.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>一个消费者组内有多个消费者应用程序</strong> 
</p>
<div class="paragraph">
<p>与前面的例子类似，一个应用程序的多个实例可以订阅同一个消费者组。这种方式可以通过 <code>mp.messaging.incoming.$channel.group.id</code> 进行配置，或默认为应用程序的名称。这种方式会在应用程序实例之间分配topic的分区。</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-one-consumer-group.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>发布/订阅：多个消费者群体订阅同一个topic</strong> 
</p>
<div class="paragraph">
<p>最后，不同的应用程序可以使用不同的 <strong>consumer group ids</strong> 来的独立订阅同一topic。例如，发布在一个名为 <em>orders</em> 的topic上的消息可以被两个消费者应用相互独立的消费，其中一个的group id是 <code>mp.messaging.incoming.orders.group.id=invoicing</code> ，另一个是 <code>mp.messaging.incoming.orders.group.id=shipping</code> 。因此，不同的消费者组可以根据消息消费的需求独立的进行扩容。</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-two-consumer-groups.png" alt="Architecture" width="60%">
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A common business requirement is to consume and process Kafka records in order.
The Kafka broker preserves order of records inside a partition and not inside a topic.
Therefore, it is important to think about how records are partitioned inside a topic.
The default partitioner uses record key hash to compute the partition for a record, or when the key is not defined, chooses a partition randomly per batch or records.</p>
</div>
<div class="paragraph">
<p>正常操作中，Kafka消费者会保留分配给它的每个分区里面的records的顺序。Smallrye Reactive Messaging会使用这个顺序进行处理，除非设置了 <code>@Blocking(ordered = false)</code> (参见<a href="#blocking-processing">阻塞处理</a> )。</p>
</div>
<div class="paragraph">
<p>请注意，由于消费者之间的再平衡(rebalances)，Kafka消费者只保证对单一records的至少一次(at-least-once)处理，这意味着未提交的records <em>可以</em> 被消费者再次处理。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="consumer-rebalance-listener"><a class="anchor" href="#consumer-rebalance-listener"></a>4.5.1. 消费者再平衡监听器(Consumer Rebalance Listener)</h4>
<div class="paragraph">
<p>在一个消费者组内，随着新老组员的交替，分区将会被重新分配，从而使每个组员都能分配到分区。这就是组的再平衡。为了处理偏移提交以及分区的分配，您可以提供一个消费者再平衡监听器。为了实现这一点，请实现 <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> 接口，并将其暴露为CDI bean并使用 <code>@Idenfier</code> 修饰符修饰。一个常见的用例是将偏移量存储在一个单独的数据存储中以使其保证语义上的精准一次(exactly-once semantic)，或者在某一个特定的偏移量开始时处理。</p>
</div>
<div class="paragraph">
<p>监听器会在消费者的topic/分区分配发生变化时启动。例如，当应用程序启动时，它会调用 <code>partitionsAssigned</code>  回调并传入与消费者相关的初始topic/分区集合 。如果后来这个集合发生变化，它会再次调用 <code>partitionsRevoked</code> 和 <code>partitionsAssigned</code> 回调，所以您可以自行实现对应的逻辑。</p>
</div>
<div class="paragraph">
<p>请注意，再平衡(rebalance)监听器方法是在Kafka轮询线程中被调用的，并且 <strong>会</strong> 阻塞调用者线程直到完成。这是因为再平衡协议(rebalance protocol)有同步屏障，而在再平衡监听器中的异步代码可能会在同步屏障之后执行。</p>
</div>
<div class="paragraph">
<p>当topic/分区被从消费者那里分配或撤销时，它会暂停消息传递， 然后在重平衡完成后立即恢复。</p>
</div>
<div class="paragraph">
<p>如果使用再平衡监听器代替用户来处理偏移量提交(使用 <code>NONE</code> 提交策略)，再平衡监听器就必须在partitionRevoked回调中同步提交偏移量。我们也建议在应用程序停止时使用同样的逻辑。</p>
</div>
<div class="paragraph">
<p>与Apache Kafka的 <code>ConsumerRebalanceListener</code> 不同， <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> 的方法会传递Kafka消费者和topic/分区集合。</p>
</div>
<div class="paragraph">
<p>In the following example we set up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).
First we need to provide a bean that implements <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> and is annotated with <code>io.smallrye.common.annotation.Identifier</code>.
We then must configure our inbound connector to use this bean.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.common.annotation.Identifier;
import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.OffsetAndTimestamp;
import org.apache.kafka.clients.consumer.TopicPartition;

import javax.enterprise.context.ApplicationScoped;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.logging.Logger;

@ApplicationScoped
@Identifier("rebalanced-example.rebalancer")
public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {

    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());

    /**
     * When receiving a list of partitions, will search for the earliest offset within 10 minutes
     * and seek the consumer to it.
     *
     * @param consumer   underlying consumer
     * @param partitions set of assigned topic partitions
     */
    @Override
    public void onPartitionsAssigned(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions) {
        long now = System.currentTimeMillis();
        long shouldStartAt = now - 600_000L; //10 minute ago

        Map&lt;TopicPartition, Long&gt; request = new HashMap&lt;&gt;();
        for (TopicPartition partition : partitions) {
            LOGGER.info("Assigned " + partition);
            request.put(partition, shouldStartAt);
        }
        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = consumer.offsetsForTimes(request);
        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; position : offsets.entrySet()) {
            long target = position.getValue() == null ? 0L : position.getValue().offset();
            LOGGER.info("Seeking position " + target + " for " + position.getKey());
            consumer.seek(position.getKey(), target);
        }
    }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;
import org.eclipse.microprofile.reactive.messaging.Acknowledgment;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.CompletionStage;

@ApplicationScoped
public class KafkaRebalancedConsumer {

    @Incoming("rebalanced-example")
    @Acknowledgment(Acknowledgment.Strategy.NONE)
    public CompletionStage&lt;Void&gt; consume(IncomingKafkaRecord&lt;Integer, String&gt; message) {
        // We don't need to ACK messages because in this example,
        // we set offset during consumer rebalance
        return CompletableFuture.completedFuture(null);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如要配置inbound connector使用所提供的监听器，我们可以通过消费者再平衡监听器的标识符 <code>mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer</code> 来设置</p>
</div>
<div class="paragraph">
<p>或者令监听器的名字与消费者组的ID相同：</p>
</div>
<div class="paragraph">
<p><code>mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer</code></p>
</div>
<div class="paragraph">
<p>注意，设置消费者再平衡监听器的名称的方式要比使用组ID的方式优先被使用。</p>
</div>
</div>
<div class="sect3">
<h4 id="using-unique-consumer-groups"><a class="anchor" href="#using-unique-consumer-groups"></a>4.5.2. 使用单一的消费者组</h4>
<div class="paragraph">
<p>如果您想处理一个topic中的所有记录(从其最开始时)，您需要：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>设置 <code>auto.offset.reset = earliest</code></p>
</li>
<li>
<p>将您的消费者分配到一个不被任何其他程序使用的消费者组。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Quarkus生成的UUID在两次执行之间会发生变化(包括在dev模式下)。因此，您可以确定没有其他消费者使用它，而且每次您的应用程序启动时都会收到一个新的唯一的组ID。</p>
</div>
<div class="paragraph">
<p>您可以使用生成的UUID作为消费者组id，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel.auto.offset.reset=earliest
mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
如果没有设置 <code>group.id</code> ，则其默认与 <code>quarkus.application.name</code> 相同。
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="receiving-kafka-records-in-batches"><a class="anchor" href="#receiving-kafka-records-in-batches"></a>4.6. 批量接收Kafka记录</h3>
<div class="paragraph">
<p>默认情况下，接收方法会单独接收每条Kafka记录。在后台，Kafka消费者client会不断地轮询broker，并批量接收记录然后放入 <code>ConsumerRecords</code> 容器中。</p>
</div>
<div class="paragraph">
<p>在 <strong>批量</strong> 模式下，您的程序可以一次性接收消费者 <strong>轮询</strong> 返回的所有记录。</p>
</div>
<div class="paragraph">
<p>为了达到这一点，您需要指定一个兼容的容器类型来接收所有数据：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(List&lt;Double&gt; prices) {
    for (double price : prices) {
        // process price
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>接收方法也可以接收 <code>Message&lt;List&lt;Payload&gt;&gt;</code> , <code>KafkaRecordBatch&lt;Key, Payload&gt;</code> <code>ConsumerRecords&lt;Key, Payload&gt;</code> 等类型。这些类型可以访问记录的细节，如偏移量或时间戳：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consumeMessage(KafkaRecordBatch&lt;String, Double&gt; records) {
    for (KafkaRecord&lt;String, Double&gt; record : records) {
        String payload = record.getPayload();
        String topic = record.getTopic();
        // process messages
    }
    // ack will commit the latest offsets (per partition) of the batch.
    return records.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>注意，对于接收到的记录批次的成功处理会提交所收到批次内每个分区的最新偏移量。所配置的提交策略将只应用于这些记录。</p>
</div>
<div class="paragraph">
<p>反之，如果处理过程抛出一个异常，所有的消息都_不会被确认(nacked)_ ，并且对批次中的所有记录应用失败策略。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Quarkus自动检测incoming channels 的批处理类型并自动设置批处理配置。您可以用 <code>mp.messaging.incoming.$channel.batch</code> 配置批处理模式。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sending-messages-to-kafka"><a class="anchor" href="#sending-messages-to-kafka"></a>5. 向Kafka发送消息</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Kafka Connector中用于发送的 channels 的配置与用于接收的 channel 的配置类似：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.outgoing.prices-out.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.outgoing.prices-out.topic=prices <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>请配置生产环境的broker位置。您可以在全局配置，或使用 <code>mp.messaging.outgoing.$channel.bootstrap.servers</code> 来针对特定channel配置它。在开发模式和运行测试时， <a href="#kafka-dev-services">Kafka开发服务（Dev Services）</a>会自动启动一个Kafka broker。如果该属性未提供，它将默认为 <code>localhost:9092</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>配置connector来管理 <code>prices-out</code> channel。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>默认情况下，topic名称与channel名称相同。您可以配置topic属性来覆盖它。</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>在应用配置里面，channel名称是唯一的。因此，如果您打算在相同topic上同时配置一个接收和一个发送的channel，您需要对这两个 channels 使用不同的名称(比如本指南的例子，<code>mp.messaging.incoming.prices</code> 和 <code>mp.messaging.outgoing.prices-out</code> )。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>然后，您的程序可以生成消息并将其发布到 <code>prices-out</code> channel。它可以使用 <code>double</code> payloads，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;
import java.time.Duration;
import java.util.Random;

@ApplicationScoped
public class KafkaPriceProducer {

    private final Random random = new Random();

    @Outgoing("prices-out")
    public Multi&lt;Double&gt; generate() {
        // Build an infinite stream of random prices
        // It emits a price every second
        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; random.nextDouble());
    }

}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>您不应该在您的代码中直接调用被标记了 <code>@Incoming</code> 和/或 <code>@Outgoing</code> 注解的方法。它们会被框架调用。如果在用户代码中调用将不会得到预期的结果。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>请注意， <code>generate</code> 方法返回了一个 <code>Multi&lt;Double&gt;</code> ，它实现了Reactive Streams <code>Publisher</code> 接口。Quarkus框架会使用这个发布者生成消息，并将其发送到您配置的Kafka topic中。</p>
</div>
<div class="paragraph">
<p>为了发送键/值对， 您可以直接返回一个 <code>io.smallrye.reactive.messaging.kafka.Record</code> 来代理一个payload：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("out")
public Multi&lt;Record&lt;String, Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
        .map(x -&gt; Record.of("my-key", random.nextDouble()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Payload可以被封装在 <code>org.eclipse.microprofile.reactive.messaging.Message</code>，以便对写入的记录有更多的控制：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Message&lt;Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; Message.of(random.nextDouble())
                    .addMetadata(OutgoingKafkaRecordMetadata.&lt;String&gt;builder()
                            .withKey("my-key")
                            .withTopic("my-key-prices")
                            .withHeaders(new RecordHeaders().add("my-header", "value".getBytes()))
                            .build()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>OutgoingKafkaRecordMetadata</code> 允许您设置Kafka记录的元数据属性，如 <code>key</code> ， <code>topic</code> ， <code>partition</code> 或 <code>timestamp</code> 。一种场景是动态地选择消息的目标topic。在这种情况下，您需要使用出站元数据(outgoing metadata)来设置topic名称，而不是在配置文件中配置topic。</p>
</div>
<div class="paragraph">
<p>除了返回Reactive Stream <code>Publisher</code> ( <code>Multi</code> 实现了 <code>Publisher</code> )的方法签名外，发送方法也可以返回单个消息。在这种情况下，生产者将使用该方法作为生成器来创建一个无限的流(infinite stream)。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("prices-out") T generate(); // T excluding void

@Outgoing("prices-out") Message&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;Message&lt;T&gt;&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;T&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;Message&lt;T&gt;&gt; generate();</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="sending-messages-with-emitter"><a class="anchor" href="#sending-messages-with-emitter"></a>5.1. 使用@Emitter发送消息</h3>
<div class="paragraph">
<p>有时，您需要使用命令式的方式来发送消息。</p>
</div>
<div class="paragraph">
<p>例如，如果您需要在REST节点内收到一个POST请求时向一个流发送消息。在这种情况下，您无法使用 <code>@Outgoing</code> ，因为您的方法有参数。</p>
</div>
<div class="paragraph">
<p>这种情况下您可以使用 <code>Emitter</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        CompletionStage&lt;Void&gt; ack = priceEmitter.send(price);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>发送一个payload会返回一个 <code>CompletionStage</code> ，并且它会在消息被确认时完成。如果消息传输失败， <code>CompletionStage</code> 会以异常结束，并且包含未被确认的原因。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>Emitter</code> 的配置方式与 其他被 <code>@Incoming</code> 和 <code>@Outgoing</code> 使用的流配置相同。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>使用 <code>Emitter</code> 的话您会以命令式代码的方式发送消息到响应式消息中(reactive messaging)。这些消息被存储在一个队列中，直到它们被发送。如果Kafka生产者client无法跟上发送到Kafka的消息节奏，这个队列就会成为一个内存占用者，甚至会耗尽内存。您可以使用 <code>@OnOverflow</code> 来配置背压策略。它可以让您配置队列的大小(默认是256)和达到缓冲区上限时要应用的策略。可用的策略有 <code>DROP</code> , <code>LATEST</code> , <code>FAIL</code> , <code>BUFFER</code> , <code>UNBOUNDED_BUFFER</code> 和 <code>NONE</code> 。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>通过 <code>Emitter</code> API，您也可以将要发送的payload封装在 <code>Message&lt;T&gt;</code> 中 。与前面的例子一样， <code>Message</code> 让您以不同的方式处理确认/拒绝(ack/nack)的情况。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.concurrent.CompletableFuture;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject @Channel("price-create") Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        priceEmitter.send(Message.of(price)
            .withAck(() -&gt; {
                // Called when the message is acked
                return CompletableFuture.completedFuture(null);
            })
            .withNack(throwable -&gt; {
                // Called when the message is nacked
                return CompletableFuture.completedFuture(null);
            }));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果您偏好于使用Reactive Stream APIs，您可以使用 <code>MutinyEmitter</code> ，它将在 <code>send</code> 方法中返回 <code>Uni&lt;Void&gt;</code> 。因此，您可以使用Mutiny APIs来处理下游的信息和错误。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    MutinyEmitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public Uni&lt;String&gt; addPrice(Double price) {
        return quoteRequestEmitter.send(price)
                .map(x -&gt; "ok")
                .onFailure().recoverWithItem("ko");
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>也可以通过 <code>sendAndAwait</code> 方法在发送事件到emitter的时候进行阻塞。只有当事件被接收者确认或拒绝时，它才会从该方法中返回。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">废弃的API</div>
<div class="paragraph">
<p><code>io.smallrye.reactive.messaging.annotations.Emitter</code> , <code>io.smallrye.reactive.messaging.annotations.Channel</code> 和 <code>io.smallrye.reactive.messaging.annotations.OnOverflow</code> 类现在已被废弃，并被替换为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Emitter</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Channel</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.OnOverflow</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>新的 <code>Emitter.send</code> 方法会返回一个 <code>CompletionStage</code> ，并且它会在产生的消息被确认时完成。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Depreciation</div>
<div class="paragraph">
<p><code>MutinyEmitter#send(Message msg)</code> method is deprecated in favor of following methods receiving <code>Message</code> for emitting:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Uni&lt;Void&gt; sendMessage(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; void sendMessageAndAwait(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Cancellable sendMessageAndForget(M msg)</code></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>More information on how to use <code>Emitter</code> can be found in <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/emitter/">SmallRye Reactive Messaging – Emitters and Channels</a></p>
</div>
</div>
<div class="sect2">
<h3 id="write-acknowledgement"><a class="anchor" href="#write-acknowledgement"></a>5.2. 写确认</h3>
<div class="paragraph">
<p>当Kafka broker收到一条记录时，它的确认可能需要时间，这取决于配置。此外，它还会在内存中存储不能写入的记录。</p>
</div>
<div class="paragraph">
<p>默认情况下，connector会等待Kafka确认记录以继续处理(确认收到的消息)。您可以通过将 <code>waitForWriteCompletion</code> 设置为 <code>false</code> 来禁用这个功能。</p>
</div>
<div class="paragraph">
<p>请注意， <code>acks</code> 属性对记录的确认有巨大影响。</p>
</div>
<div class="paragraph">
<p>如果一条记录无法写入，消息就会被拒绝。</p>
</div>
</div>
<div class="sect2">
<h3 id="backpressure"><a class="anchor" href="#backpressure"></a>5.3. 背压</h3>
<div class="paragraph">
<p>Kafka的出站connector负责处理背压，并且会监测等待写入Kafka broker中的in-flight的消息数量。in-flight的消息的数量是通过 <code>max-inflight-messages</code> 配置的，默认为1024。</p>
</div>
<div class="paragraph">
<p>Connector只会并行发送指定数量的消息。在至少一个in-flight的消息被broker确认之前，其他消息都不会被发送。然后，当broker中有in-flight的消息得到确认时，connector才会向Kafka写入一个新的消息。请确保相应地配置Kafka的 <code>batch.size</code> 和 <code>linger.ms</code> 属性。</p>
</div>
<div class="paragraph">
<p>您也可以通过将 <code>max-inflight-messages</code> 设置为 <code>0</code> 来取消in-flight消息的限制。但请注意，如果请求数量达到 <code>max.in.flight.requests.per.connection</code> 指定的值，Kafka生产者可能会阻塞。</p>
</div>
</div>
<div class="sect2">
<h3 id="retrying-message-dispatch"><a class="anchor" href="#retrying-message-dispatch"></a>5.4. 重试消息的发送</h3>
<div class="paragraph">
<p>当Kafka生产者收到来自服务器的错误时，如果它是一个暂时的、可恢复的错误，那么客户端将重试发送这批消息。这种行为是由 <code>retries</code> 和 <code>retry.backoff.ms</code> 参数控制的。除此之外，SmallRye Reactive Messaging还会在可恢复的错误中重试单个消息，这取决于 <code>retries</code> 和 <code>delivery.timeout.ms</code> 参数。</p>
</div>
<div class="paragraph">
<p>请注意，虽然在对一个可靠的系统来说拥有重试机制是一种最佳实践，但 <code>max.in.flight.requests.per.connection</code> 参数默认为 <code>5</code> 将会意味着消息的顺序不会被保证。如果消息的顺序对您来说是必须保证的，将 <code>max.in.flight.requests.per.connection</code> 设置为 <code>1</code> 将确保一次只发送一批消息，但代价是限制生产者的吞吐量。</p>
</div>
<div class="paragraph">
<p>关于如何对错误处理应用重试机制，请参见 <a href="#retrying-processing">[重试-处理</a>] 一节。</p>
</div>
</div>
<div class="sect2">
<h3 id="handling-serialization-failures"><a class="anchor" href="#handling-serialization-failures"></a>5.5. 处理序列化失败</h3>
<div class="paragraph">
<p>对于Kafka生产者客户端来说序列化失败是不可恢复的，因此消息发送不会被重试。在这些情况下，您可能需要为序列化器设置一个失败策略。为了实现这一点，您需要一个实现了 <code>SerializationFailureHandler&lt;T&gt;</code> 接口的bean：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-fallback") // Set the name of the failure handler
public class MySerializationFailureHandler
    implements SerializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public byte[] decorateSerialization(Uni&lt;byte[]&gt; serialization, String topic, boolean isKey,
        String serializer, Object data, Headers headers) {
        return serialization
                    .onFailure().retry().atMost(3)
                    .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>要使用该故障处理，Bean必须用 <code>@Identifier</code> 限定符修饰，并且connector的配置必须指定属性 <code>mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler</code> (对于键或值序列化器)。</p>
</div>
<div class="paragraph">
<p>处理器被调用，并被提供序列化的细节，包括以 <code>Uni&lt;byte[]&gt;</code> 表示的操作。注意，该方法必须对在结果处进行等待，并返回序列化后的字节数组。</p>
</div>
</div>
<div class="sect2">
<h3 id="in-memory-channels"><a class="anchor" href="#in-memory-channels"></a>5.6. 内存 channels</h3>
<div class="paragraph">
<p>在某些情况下，使用消息模式在同一个应用程序内传输消息是很方便的。当您没有将channel连接到像Kafka这样的消息后端时，一切都会发生在内存中，并且流会通过链式方法创建。每个链式调用仍是一个响应式流，并执行背压策略。</p>
</div>
<div class="paragraph">
<p>Quarkus框架会验证生产者/消费者链是否完整，这意味着如果应用程序将消息写入内存channel(仅使用 <code>@Outgoing</code> 修饰符方法，或 <code>Emitter</code> )，它也必须从应用程序内部消费消息(仅 <code>@Incoming</code> 修饰符方法 ，或使用不受管理的流)。</p>
</div>
</div>
<div class="sect2">
<h3 id="broadcasting-messages-on-multiple-consumers"><a class="anchor" href="#broadcasting-messages-on-multiple-consumers"></a>5.7. 对多个消费者广播信息</h3>
<div class="paragraph">
<p>默认情况下，一个channel可以关联到一个单一的消费者上，通过使用 <code>@Incoming</code> 方法或 <code>@Channel</code> 响应式应式流。在程序启动时，channels 会被验证，以形成一个由单个消费者和生产者组成的消费者和生产者链。您可以通过在channel上设置 <code>mp.messaging.$channel.broadcast=true</code> 来覆盖这种行为。</p>
</div>
<div class="paragraph">
<p>在内存 channels 的情况下， <code>@Broadcast</code> 注释可以用在 <code>@Outgoing</code> 方法上。比如说,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Random;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.reactive.messaging.annotations.Broadcast;

@ApplicationScoped
public class MultipleConsumer {

    private final Random random = new Random();

    @Outgoing("in-memory-channel")
    @Broadcast
    double generate() {
        return random.nextDouble();
    }

    @Incoming("in-memory-channel")
    void consumeAndLog(double price) {
        System.out.println(price);
    }

    @Incoming("in-memory-channel")
    @Outgoing("prices2")
    double consumeAndSend(double price) {
        return price;
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>相应地，同一 channel 上的多个生产者可以通过设置 <code>mp.messaging.incoming.$channel.merge=true</code> 来进行合并。在 <code>@Incoming</code> 方法上，您可以使用 <code>@Merge</code> 来控制多个 channels 的合并方式。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="kafka-transactions"><a class="anchor" href="#kafka-transactions"></a>5.8. Kafka事务处理</h3>
<div class="paragraph">
<p>Kafka 事务支持对多个 Kafka 主题和分区进行原子写入。 Kafka 连接器提供了 <code>KafkaTransactions</code> 自定义emitter，用于在事务中写入 Kafka 记录。 它可以作为常规emitter <code>@Channel</code> 注入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaTransactionalProducer {

    @Channel("tx-out-example")
    KafkaTransactions&lt;String&gt; txProducer;

    public Uni&lt;Void&gt; emitInTransaction() {
        return txProducer.withTransaction(emitter -&gt; {
            emitter.send(KafkaRecord.of(1, "a"));
            emitter.send(KafkaRecord.of(2, "b"));
            emitter.send(KafkaRecord.of(3, "c"));
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>传入 <code>withTransaction</code> 方法的函数参数会使用 <code>TransactionalEmitter</code> 来产生记录，并返回 <code>Uni</code> 做为事务结果。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果处理成功完成，则刷新生产者并提交事务。</p>
</li>
<li>
<p>如果处理过程抛出异常，会返回失败的 <code>Uni</code>，或将 <code>TransactionalEmitter</code> 标记为中止，然后事务会被中止。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Kafka 事务生产者需要配置 <code>acks=all</code> 客户端属性，以及 <code>transactional.id</code> 的唯一 id，这意味着 <code>enable.idempotence=true</code> 。 当 Quarkus 检测到传出通道使用 <code>KafkaTransactions</code> 时，它会在通道上配置这些属性，为 <code>transactional.id</code> 属性提供默认值 <code>"${quarkus.application.name}-${channelName}"</code> 。</p>
</div>
<div class="paragraph">
<p>请注意，要在生产环境使用，必须确保 <code>transactional.id</code> 在所有应用实例中是唯一的。</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>虽然普通的消息emitter支持并发调用 <code>send</code> 方法并将要写入 Kafka 的传出消息顺序排队，但 <code>KafkaTransactions</code> emitter每次只支持一个事务。 从调用 <code>withTransaction</code> 直到返回的 <code>Uni</code> 导致成功或失败，事务被视为正在进行中。 当事务正在进行时，对 <code>withTransaction</code> 的后续调用，包括给定函数内的嵌套调用，都将抛出 <code>IllegalStateException</code> 。</p>
</div>
<div class="paragraph">
<p>请注意，在 Reactive Messaging 中，处理方法的执行已经被序列化，除非使用了 <code>@Blocking(ordered = false)</code> 。 如果可以同时调用 <code>withTransaction</code> ，例如从 REST 节点，建议限制执行的并发性。 这可以使用后面链接中的 <code>@Bulkhead</code> 注释来完成：<a href="https://quarkus.io/guides/smallrye-fault-tolerance"><em>Microprofile Fault Tolerance</em></a>。</p>
</div>
<div class="paragraph">
<p>示例用法可以在 <a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">Chaining Kafka Transactions with Hibernate Reactive transactions</a> 中找到。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="transaction-aware-consumers"><a class="anchor" href="#transaction-aware-consumers"></a>5.8.1. 事务感知型消费者</h4>
<div class="paragraph">
<p>如果您想使用仅在 Kafka 事务中写入和提交的记录，您需要在传入通道上配置 <code>isolation.level</code> 属性，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.isolation.level=read_committed</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="processing-messages"><a class="anchor" href="#processing-messages"></a>6. 处理消息</h2>
<div class="sectionbody">
<div class="paragraph">
<p>应用的流式数据常常需要从一个topic中消费一些事件，对其进行处理并将结果发布到不同的topic中。一个处理器方法可以简单地通过使用 <code>@Incoming</code> 和 <code>@Outgoing</code> 注解来实现：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public double process(double price) {
        return price * CONVERSION_RATE;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>process</code> 方法的参数是传入的消息的payload，而返回值将被用作传出的消息的payload。之前提到的参数和返回类型的签名也被支持，如 <code>Message&lt;T&gt;</code> ， <code>Record&lt;K, V&gt;</code> 等等。</p>
</div>
<div class="paragraph">
<p>您可以通过消费和返回响应式流 <code>Multi&lt;T&gt;</code> 类型来应用异步流处理：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.mutiny.Multi;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public Multi&lt;Double&gt; process(Multi&lt;Integer&gt; prices) {
        return prices.filter(p -&gt; p &gt; 100).map(p -&gt; p * CONVERSION_RATE);
    }

}</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="propagating-record-key"><a class="anchor" href="#propagating-record-key"></a>6.1. 传播记录键</h3>
<div class="paragraph">
<p>在处理信息时，您可以将传入的记录键发送给传出的记录。</p>
</div>
<div class="paragraph">
<p>通过启用 <code>mp.messaging.outgoing.$channel.propagate-record-key=true</code> ，记录键传播可以产生与传入记录的 <em>键</em> 相同的传出记录。</p>
</div>
<div class="paragraph">
<p>如果传出的记录已经包含一个 <em>键</em>，那么它 <strong>不会</strong> 被传入的记录键的键所覆盖。如果传入的记录键为_空_，那么 <code>mp.messaging.outgoing.$channel.key</code> 设置的值会被使用。</p>
</div>
</div>
<div class="sect2">
<h3 id="exactly-once-processing"><a class="anchor" href="#exactly-once-processing"></a>6.2. （Exactly-Once Processing）精确一次处理</h3>
<div class="paragraph">
<p>Kafka 事务可以同时管理其中的消费端和生产端的消息偏移量。 这使得消费端能够以 <em>consume-transform-produce</em> 模式与生产端耦合，也称为 <strong>exactly-once 精确一次性处理</strong>。</p>
</div>
<div class="paragraph">
<p><code>KafkaTransactions</code> 定制emitter可以提供一种对事务中传入的 Kafka 消息进行一次性处理的方法。</p>
</div>
<div class="paragraph">
<p>以下示例包括在事务中进行 Kafka 记录的批处理。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.OnOverflow;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.KafkaRecordBatch;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaExactlyOnceProcessor {

    @Channel("prices-out")
    @OnOverflow(value = OnOverflow.Strategy.BUFFER, bufferSize = 500) <i class="conum" data-value="3"></i><b>(3)</b>
    KafkaTransactions&lt;Integer&gt; txProducer;

    @Incoming("prices-in")
    public Uni&lt;Void&gt; emitInTransaction(KafkaRecordBatch&lt;String, Integer&gt; batch) { <i class="conum" data-value="1"></i><b>(1)</b>
        return txProducer.withTransactionAndAck(batch, emitter -&gt; { <i class="conum" data-value="2"></i><b>(2)</b>
            for (KafkaRecord&lt;String, Integer&gt; record : batch) {
                emitter.send(KafkaRecord.of(record.getKey(), record.getPayload() + 1)); <i class="conum" data-value="3"></i><b>(3)</b>
            }
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>建议在消费端批处理模式中采用exactly-once。 虽然可以将它与单个 Kafka 消息一起使用，但这样会对性能产生重大影响。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>消费的 <code>KafkaRecordBatch</code> 消息被传递给 <code>KafkaTransactions#withTransactionAndAck</code> ，以处理偏移提交和消息确认。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><code>send</code> 方法将记录通过事务写入 Kafka，而无需等待来自代理的发送回执。 等待写入 Kafka 的消息将被缓冲，并在提交事务之前刷新。 因此，建议配置 <code>@OnOverflow</code> <code>bufferSize</code> 以适应足够的消息，例如 <code>max.poll.records</code>，即批处理中返回的最大记录数。
<div class="ulist">
<ul>
<li>
<p>如果处理成功完成，<em>在提交事务之前</em> ，给定批处理消息的主题分区偏移量将提交给事务。</p>
</li>
<li>
<p>如果处理需要中止，<em>在中止事务后</em> ，消费者的位置将重置为最后提交的偏移量，能有效地从该偏移量恢复消费。 如果没有消费者偏移量被提交到主题分区，消费者的位置将被重置到主题分区的开头，<em>即使把 <code>latest</code> 做为偏移量重置策略</em> 。</p>
</li>
</ul>
</div></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>当使用（exactly-once）精确一次处理时，消耗的消息偏移量提交由事务处理，因此应用程序不应通过其他方式提交偏移量。 消费者应该有 <code>enable.auto.commit=false</code> （默认）并明确设置 <code>commit-strategy=ignore</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.commit-strategy=ignore
mp.messaging.incoming.prices-in.failure-strategy=ignore</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="error-handling-for-the-exactly-once-processing"><a class="anchor" href="#error-handling-for-the-exactly-once-processing"></a>6.2.1. （exactly-once）精确一次处理的错误处理</h4>
<div class="paragraph">
<p>如果事务失败并被中止，则从 KafkaTransactions#withTransaction 返回的 <code>Uni</code> 将产生失败。 应用程序可以选择处理错误情况，但如果从 <code>@Incoming</code> 方法返回失败的 <code>Uni</code> ，则传入通道将有效地失败并停止响应流。</p>
</div>
<div class="paragraph">
<p><code>KafkaTransactions#withTransactionAndAck</code> 方法确认和确认消息，但 <strong>不会</strong> 返回失败的 <code>Uni</code> 。 Nacked 消息将由传入通道的故障策略处理，（参见<a href="#error-handling">错误处理策略(Error Handling Strategies)</a>）。 配置 <code>failure-strategy=ignore</code> 只是将 Kafka 消费者重置为最后提交的偏移量并从那里恢复消费。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-bare-clients"><a class="anchor" href="#kafka-bare-clients"></a>7. 直接访问Kafka客户端</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在少数情况下，您可能需要访问底层的Kafka客户端。<code>KafkaClientService</code> 提供线程安全的方式来访问 <code>Producer</code> 和 <code>Consumer</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.event.Observes;
import javax.inject.Inject;

import org.apache.kafka.clients.producer.ProducerRecord;

import io.quarkus.runtime.StartupEvent;
import io.smallrye.reactive.messaging.kafka.KafkaClientService;
import io.smallrye.reactive.messaging.kafka.KafkaConsumer;
import io.smallrye.reactive.messaging.kafka.KafkaProducer;

@ApplicationScoped
public class PriceSender {

    @Inject
    KafkaClientService clientService;

    void onStartup(@Observes StartupEvent startupEvent) {
        KafkaProducer&lt;String, Double&gt; producer = clientService.getProducer("generated-price");
        producer.runOnSendingThread(client -&gt; client.send(new ProducerRecord&lt;&gt;("prices", 2.4)))
            .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>KafkaClientService</code> 是一个实验性的API，在未来可能会发生变化。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>您也可以把Kafka配置注入到您的应用程序中来直接创建Kafka生产者，消费者以及管理客户端：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.common.annotation.Identifier;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.KafkaAdminClient;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import java.util.HashMap;
import java.util.Map;

@ApplicationScoped
public class KafkaClients {

    @Inject
    @Identifier("default-kafka-broker")
    Map&lt;String, Object&gt; config;

    @Produces
    AdminClient getAdmin() {
        Map&lt;String, Object&gt; copy = new HashMap&lt;&gt;();
        for (Map.Entry&lt;String, Object&gt; entry : config.entrySet()) {
            if (AdminClientConfig.configNames().contains(entry.getKey())) {
                copy.put(entry.getKey(), entry.getValue());
            }
        }
        return KafkaAdminClient.create(copy);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>default-kafka-broker</code> 配置map包含所有以 <code>kafka.</code> 或 <code>KAFKA_</code> 为前缀的应用属性。更多的配置选项，请查看 <a href="#kafka-configuration-resolution">[kafka配置方案</a>] 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-serialization"><a class="anchor" href="#kafka-serialization"></a>8. JSON序列化</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus有内置的能力来处理JSON格式的Kafka消息。</p>
</div>
<div class="paragraph">
<p>假设我们有一个 <code>Fruit</code> 数据类，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class Fruit {

    public String name;
    public int price;

    public Fruit() {
    }

    public Fruit(String name, int price) {
        this.name = name;
        this.price = price;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>而我们想用它来接收来自Kafka的消息，从而进行一些价格转换，并将消息传回Kafka。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Broadcast;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

/**
* A bean consuming data from the "fruit-in" channel and applying some price conversion.
* The result is pushed to the "fruit-out" channel.
*/
@ApplicationScoped
public class FruitProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("fruit-in")
    @Outgoing("fruit-out")
    @Broadcast
    public Fruit process(Fruit fruit) {
        fruit.price = fruit.price * CONVERSION_RATE;
        return fruit;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To do this, we will need to set up JSON serialization with Jackson or JSON-B.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
在正确配置了JSON序列化后，您也可以使用 <code>Publisher&lt;Fruit&gt;</code> 和 <code>Emitter&lt;Fruit&gt;</code> 。
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="jackson-serialization"><a class="anchor" href="#jackson-serialization"></a>8.1. 通过Jackson进行序列化</h3>
<div class="paragraph">
<p>Quarkus内置了对基于Jackson的JSON序列化和反序列化的支持。它也会为您 <a href="#serialization-generation">生成</a> 序列化器和反序列化器，所以您不需要配置任何东西。当生成器被禁用时，您可以提供 <code>ObjectMapperSerializer</code> 和 <code>ObjectMapperDeserializer</code> ，如下所述。</p>
</div>
<div class="paragraph">
<p>有一个现有的 <code>ObjectMapperSerializer</code> ，可以用来通过Jackson来序列化所有的数据对象。如果您想使用 <a href="#serialization-autodetection">[自动侦测序列化</a>] ，您可以创建一个空的子类来继承该类。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
默认情况下， <code>ObjectMapperSerializer</code> 将null序列化为 <code>"null"</code> 字符串，这可以通过设置Kafka配置属性 <code>json.serialize.null-as-null=true</code> ，将null序列化为 <code>null</code> 。这在使用压缩的topic时很方便，因为 <code>null</code> 被用作标记来表示在压缩阶段哪些消息被删除了。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>对应的反序列化器类也需要被子类化。因此，让我们创建一个 <code>FruitDeserializer</code> 来继承 <code>ObjectMapperDeserializer</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>最后，配置您的 channelss 以使用Jackson序列化器和反序列化器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在，您的Kafka消息将包含 <code>Fruit</code> 数据对象的Jackson序列化格式。在这种情况下，<code>deserializer</code> 的配置不是必须的，因为 <a href="#serialization-autodetection">[序列化自动侦测</a>] 是默认启用的。</p>
</div>
<div class="paragraph">
<p>如果您想反序列化一个fruit对象列表，您需要创建一个反序列化器，它会用Jackson <code>TypeReference</code> 表示所用到的通用集合。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import java.util.List;
import com.fasterxml.jackson.core.type.TypeReference;
import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class ListOfFruitDeserializer extends ObjectMapperDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new TypeReference&lt;List&lt;Fruit&gt;&gt;() {});
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="jsonb-serialization"><a class="anchor" href="#jsonb-serialization"></a>8.2. 通过JSON-B进行序列化</h3>
<div class="paragraph">
<p>首先，您需要引入 <code>quarkus-jsonb</code> 扩展。</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-jsonb&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-jsonb")</code></pre>
</div>
</div>
<div class="paragraph">
<p>有一个现有的 <code>JsonbSerializer</code> ，可以通过JSON-B来序列化所有的数据对象。如果您想使用 <a href="#serialization-autodetection">[序列化自动侦测</a>] ，您可以创建一个空的子类类继承它。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
默认情况下， <code>JsonbSerializer</code> 将null序列化为 <code>"null"</code> 字符串，这可以通过设置Kafka配置属性 <code>json.serialize.null-as-null=true</code> 来将null序列化为 <code>null</code> 。这在使用压缩的topic时很方便，因为 <code>null</code> 被用作标记来表示在压缩阶段哪些消息被删除了。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>相应的反序列化器类需要被子类化。因此，让我们创建一个 <code>FruitDeserializer</code> 来继承 <code>JsonbDeserializer</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;

import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class FruitDeserializer extends JsonbDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>最后，通过配置来使您的 channels 使用JSON-B串行器和反串行器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.connector=smallrye-kafka
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.connector=smallrye-kafka
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在，您的Kafka消息将包含 <code>Fruit</code> 数据对象的JSON-B序列化格式。</p>
</div>
<div class="paragraph">
<p>如果您想反序列化一个fruit对象列表，您需要创建一个反序列化器，它会用一个 <code>Type</code> 表示所用到的通用集合。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;
import java.lang.reflect.Type;
import java.util.ArrayList;
import java.util.List;
import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class ListOfFruitDeserializer extends JsonbDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new ArrayList&lt;MyEntity&gt;() {}.getClass().getGenericSuperclass());
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
如果您不想为每个数据对象创建一个反序列化器，您可以使用通用的 <code>io.vertx.kafka.client.serialization.JsonObjectDeserializer</code> ，它将把消息反序列化为一个 <code>io.vertx.core.json.JsonObject</code> 。也可以使用与之相对应的序列化器： <code>io.vertx.kafka.client.serialization.JsonObjectSerializer</code> 。
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="avro-serialization"><a class="anchor" href="#avro-serialization"></a>9. Avro序列化</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这部分在一个专门的指南中有所描述。 <a href="kafka-schema-registry-avro.html">使用Apache Kafka与Schema Registry和Avro协同工作</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-autodetection"><a class="anchor" href="#serialization-autodetection"></a>10. 序列化/反串行器自动侦测</h2>
<div class="sectionbody">
<div class="paragraph">
<p>当使用SmallRye Reactive Messaging with Kafka ( <code>io.quarkus:quarkus-smallrye-reactive-messaging-kafka</code> )时，Quarkus通常可以自动检测可用的序列化器和反序列化器类。这种自动检测是基于 <code>@Incoming</code> 和 <code>@Outgoing</code> 方法的声明，以及注入的 <code>@Channel</code> 。</p>
</div>
<div class="paragraph">
<p>例如，如果您声明</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Integer&gt; generate() {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>而您的配置表明 <code>generated-price</code>  channel 使用了 <code>smallrye-kafka</code> 连接器，那么Quarkus会自动将 <code>value.serializer</code> 设置为Kafka内置的 <code>IntegerSerializer</code> 。</p>
</div>
<div class="paragraph">
<p>同样地，如果您声明</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("my-kafka-records")
public void consume(KafkaRecord&lt;Long, byte[]&gt; record) {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>并且您的配置表明 <code>my-kafka-records</code>  channel 使用了 <code>smallrye-kafka</code> 连接器，那么Quarkus会自动将 <code>key.deserializer</code> 设置为Kafka内置的 <code>LongDeserializer</code> ，以及 <code>value.deserializer</code> 设置为 <code>ByteArrayDeserializer</code> 。</p>
</div>
<div class="paragraph">
<p>最后，如果您声明</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject
@Channel("price-create")
Emitter&lt;Double&gt; priceEmitter;</code></pre>
</div>
</div>
<div class="paragraph">
<p>而您的配置表明 <code>price-create</code>  channel 使用 <code>smallrye-kafka</code> 连接器，那么Quarkus将自动将 <code>value.serializer</code> 设置为Kafka内置的 <code>DoubleSerializer</code> 。</p>
</div>
<div class="paragraph">
<p>序列化器/反序列化器自动侦测所支持的全部类型有：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>short</code> 和 <code>java.lang.Short</code></p>
</li>
<li>
<p><code>int</code> 和 <code>java.lang.Integer</code></p>
</li>
<li>
<p><code>long</code> 和 <code>java.lang.Long</code></p>
</li>
<li>
<p><code>float</code> 和 <code>java.lang.Float</code></p>
</li>
<li>
<p><code>double</code> 和 <code>java.lang.Double</code></p>
</li>
<li>
<p><code>byte[]</code> </p>
</li>
<li>
<p><code>java.lang.String</code></p>
</li>
<li>
<p><code>java.util.UUID</code></p>
</li>
<li>
<p><code>java.nio.ByteBuffer</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils.Bytes</code></p>
</li>
<li>
<p><code>io.vertx.core.buffer.Buffer</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonObject</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonArray</code></p>
</li>
<li>
<p>直接实现了 <code>org.apache.kafka.common.serialization.Serializer&lt;T&gt;</code> / <code>org.apache.kafka.common.serialization.Deserializer&lt;T&gt;</code> 的类。</p>
<div class="ulist">
<ul>
<li>
<p>这些实现类需要指定类型参数 <code>T</code> 作为(反)序列化的类型。</p>
</li>
</ul>
</div>
</li>
<li>
<p>从Avro Schema生成的类，类似于Avro <code>GenericRecord</code>。如果Confluent或Apicurio Registry <em>serde</em> 存在的话</p>
<div class="ulist">
<ul>
<li>
<p>如果存在多个Avro serdes，必须为Avro生成的类手动配置序列化器/反序列化器，因为这种情况下无法进行自动侦测</p>
</li>
<li>
<p>关于使用Confluent或Apicurio Registry的更多信息，请参见 <a href="kafka-schema-registry-avro.html">协同使用Apache Kafka，Schema Registry以及Avro</a></p>
</li>
</ul>
</div>
</li>
<li>
<p><code>ObjectMapperSerializer</code> / <code>ObjectMapperDeserializer</code> 的子类，如 <a href="#jackson-serialization">[jackson序列化</a>] 中所述</p>
<div class="ulist">
<ul>
<li>
<p>技术上不需要对 <code>ObjectMapperSerializer</code> 子类化，但在这种情况下无法进行自动侦测</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>JsonbSerializer</code> / <code>JsonbDeserializer</code> 的子类，如 <a href="#jsonb-serialization">[jsonb序列化</a>] 中所述</p>
<div class="ulist">
<ul>
<li>
<p>技术上不需要对 <code>JsonbSerializer</code> 子类化，但在这种情况下无法进行自动侦测</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果一个序列化器/反序列化器是通过配置设置的，那么它不会被自动检测所取代。</p>
</div>
<div class="paragraph">
<p>如果您对使用序列化器自动侦测有任何疑问，您可以通过设置 <code>quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false</code> 来彻底关闭它。如果您需要这样做，请在 <a href="https://github.com/quarkusio/quarkus/issues">Quarkus问题跟踪</a> 中提交一个bug，这样我们就能跟踪并解决您的任何问题。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-generation"><a class="anchor" href="#serialization-generation"></a>11. JSON序列化器/反序列化器的生成</h2>
<div class="sectionbody">
<div class="paragraph">
<p>以下情况下，Quarkus会自动为 channels 生成序列化器和反序列化器：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>序列化器/反序列化器未配置</p>
</li>
<li>
<p>自动侦测机制没有找到匹配的序列化器/反序列化器</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>它的底层使用了Jackson。</p>
</div>
<div class="paragraph">
<p>可以用以下方法禁用这种生成机制：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.kafka.serializer-generation.enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
生成机制不支持诸如 <code>List&lt;Fruit&gt;</code> 这样的集合。请参考 <a href="#jackson-serialization">[jackson序列化</a>] 为这种情况编写您自己的序列化器/反序列化器。
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-schema-registry"><a class="anchor" href="#using-schema-registry"></a>12. 使用Schema注册表</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这部分在一个专门的指南中有所描述。 <a href="kafka-schema-registry-avro.html">使用Apache Kafka与Schema Registry和Avro协同工作</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-health-check"><a class="anchor" href="#kafka-health-check"></a>13. 健康检查</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus为Kafka提供了几种健康检查方式。这些方式需要与 <code>quarkus-smallrye-health</code> 扩展结合使用。</p>
</div>
<div class="sect2">
<h3 id="kafka-broker-readiness-check"><a class="anchor" href="#kafka-broker-readiness-check"></a>13.1. Kafka Broker就绪检查(Readiness Check)</h3>
<div class="paragraph">
<p>当使用 <code>quarkus-kafka-client</code> 扩展时，您可以通过在您的 <code>application.properties</code> 配置文件中将 <code>quarkus.kafka.health.enabled</code> 属性设置为 <code>true</code> 来启用 <em>就绪</em> 健康检查。该检查会报告与 <em>默认的</em> Kafka Broker(使用 <code>kafka.bootstrap.servers</code> 配置)的交互状态。它需要一个与Kafka Broker的 <em>管理员连接</em> ，并且默认是禁用的。如果启用，当您访问您应用程序的 <code>/q/health/ready</code> 节点时，您将获得关于连接验证状态的信息。</p>
</div>
</div>
<div class="sect2">
<h3 id="kafka-reactive-messaging-health-checks"><a class="anchor" href="#kafka-reactive-messaging-health-checks"></a>13.2. Kafka响应式消息传递健康检查</h3>
<div class="paragraph">
<p>当使用响应式消息传递和Kafka 连接器时，每个配置的 channel (传入或传出)都会提供 <em>启动</em> 、 <em>活跃度(liveness)</em> 和 <em>就绪</em> 检查。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>启动</em> 检查确保与Kafka集群的通信是否建立。</p>
</li>
<li>
<p><em>活跃性</em> 检查可以捕获与Kafka通信过程中发生的任何不可恢复的故障。</p>
</li>
<li>
<p><em>就绪</em> 检查确保Kafka 连接器是否准备好针对配置的Kafka topic消费或生产消息。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>对于每个 channel ，您都可以禁用检查，通过：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Disable both liveness and readiness checks with `health-enabled=false`:

# Incoming channel (receiving records form Kafka)
mp.messaging.incoming.your-channel.health-enabled=false
# Outgoing channel (writing records to Kafka)
mp.messaging.outgoing.your-channel.health-enabled=false

# Disable only the readiness check with `health-readiness-enabled=false`:

mp.messaging.incoming.your-channel.health-readiness-enabled=false
mp.messaging.outgoing.your-channel.health-readiness-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
您可以使用 <code>mp.messaging.incoming|outgoing.$channel.bootstrap.servers</code> 属性为每个 channel 配置 <code>bootstrap.servers</code> 。默认是 <code>kafka.bootstrap.servers</code> 。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>响应式消息传递的 <em>启动</em> 和 <em>就绪</em> 检查提供了两种策略。默认策略是确认是否与broker建立了活动连接。这种方法不具有侵入性，因为它基于内置的Kafka客户端指标。</p>
</div>
<div class="paragraph">
<p>使用 <code>health-topic-verification-enabled=true</code> 属性， <em>启动</em> 探针使用一个 <em>管理客户端</em> 来检查topic列表。而传入 channel 的 <em>就绪</em> 探针将检查是否至少有一个分区被分配用于消费，而传出 channel 则检查生产者使用的topic是否存在于broker中。</p>
</div>
<div class="paragraph">
<p>注意，要实现这一点， 一个_管理员连接_是必须存在的 。您可以使用 <code>health-topic-verification-timeout</code> 来调整对broker的topic验证调用的超时时间。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-streams"><a class="anchor" href="#kafka-streams"></a>14. Kafka流</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这部分在专门的指南中有所描述：<a href="kafka-streams.html">使用Apache Kafka流</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-snappy-for-message-compression"><a class="anchor" href="#using-snappy-for-message-compression"></a>15. 使用Snappy进行消息压缩</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在 <em>出站</em>  channels 上，您可以通过将 <code>compression.type</code> 设置为 <code>snappy</code> 来启用Snappy压缩：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.fruit-out.compression.type=snappy</code></pre>
</div>
</div>
<div class="paragraph">
<p>在JVM模式下，它开箱即用。然而，如果要把您的应用程序编译成一个原生的可执行文件，您需要：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使用GraalVM 21.+</p>
</li>
<li>
<p>将 <code>quarkus.kafka.snappy.enabled=true</code> 添加到您的 <code>application.properties</code> 中</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在原生模式下，Snappy默认是禁用的，因为使用Snappy需要嵌入一个原生库，并在应用程序启动时对其进行解包。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="authentication-with-oauth"><a class="anchor" href="#authentication-with-oauth"></a>16. 用OAuth进行认证</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果您的Kafka broker使用OAuth作为认证机制，您需要配置Kafka消费者来启用这个认证过程。首先，在您的应用程序中添加以下依赖：</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.strimzi&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-oauth-client&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.strimzi:kafka-oauth-client")</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个依赖提供了处理OAuth工作流所需的回调处理器。然后，在 <code>application.properties</code> ，添加：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT
mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER
mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.client.id="team-a-client" \
  oauth.client.secret="team-a-client-secret" \
  oauth.token.endpoint.uri="http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token" ;
mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler

quarkus.ssl.native=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>更改 <code>oauth.client.id</code> ， <code>oauth.client.secret</code> 和 <code>oauth.token.endpoint.uri</code> 值。</p>
</div>
<div class="paragraph">
<p>OAuth认证在JVM和原生模式下都有效。由于SSL在原生模式下默认不启用，所以必须添加 <code>quarkus.ssl.native=true</code> ，以支持JaasClientOauthLoginCallbackHandler。它使用了SSL。(更多细节请参见《 <a href="native-and-ssl.html">在原生可执行文件中使用SSL</a> 》指南)。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="testing-a-kafka-application"><a class="anchor" href="#testing-a-kafka-application"></a>17. 测试一个Kafka应用程序</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="testing-without-a-broker"><a class="anchor" href="#testing-without-a-broker"></a>17.1. 无broker的测试</h3>
<div class="paragraph">
<p>在不启动Kafka broker的情况下测试应用程序会很有用。为了实现这一点，您可以把Kafka连接器管理的 channels  <em>切换</em> 到_内存 _中 。</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
这种方法只适用于JVM测试。它不能用于原生测试(因为原生模式不支持注入)。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>假设我们想测试以下的处理器应用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
public class BeverageProcessor {

    @Incoming("orders")
    @Outgoing("beverages")
    Beverage process(Order order) {
        System.out.println("Order received " + order.getProduct());
        Beverage beverage = new Beverage();
        beverage.setBeverage(order.getProduct());
        beverage.setCustomer(order.getCustomer());
        beverage.setOrderId(order.getOrderId());
        beverage.setPreparationState("RECEIVED");
        return beverage;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>首先，在您的应用程序中添加以下测试依赖：</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.smallrye.reactive&lt;/groupId&gt;
    &lt;artifactId&gt;smallrye-reactive-messaging-in-memory&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">testImplementation("io.smallrye.reactive:smallrye-reactive-messaging-in-memory")</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后，按以下方法创建Quarkus测试资源：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {

    @Override
    public Map&lt;String, String&gt; start() {
        Map&lt;String, String&gt; env = new HashMap&lt;&gt;();
        Map&lt;String, String&gt; props1 = InMemoryConnector.switchIncomingChannelsToInMemory("orders");     <i class="conum" data-value="1"></i><b>(1)</b>
        Map&lt;String, String&gt; props2 = InMemoryConnector.switchOutgoingChannelsToInMemory("beverages");  <i class="conum" data-value="2"></i><b>(2)</b>
        env.putAll(props1);
        env.putAll(props2);
        return env;  <i class="conum" data-value="3"></i><b>(3)</b>
    }

    @Override
    public void stop() {
        InMemoryConnector.clear();  <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>将传入 channel  <code>orders</code> (等待来自Kafka的消息)切换到内存中。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>将出站 channel <code>beverages</code>(向Kafka写消息)切换到内存中。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>构建并返回一个 <code>Map</code> ，包含配置应用程序使用内存 channels 所需的所有属性。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>当测试停止时，清除 <code>InMemoryConnector</code> (丢弃所有接收和发送的信息)。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>使用上面创建的测试资源创建一个Quarkus测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTest
@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)
class BaristaTest {

    @Inject
    InMemoryConnector connector; <i class="conum" data-value="1"></i><b>(1)</b>

    @Test
    void testProcessOrder() {
        InMemorySource&lt;Order&gt; ordersIn = connector.source("orders");     <i class="conum" data-value="2"></i><b>(2)</b>
        InMemorySink&lt;Beverage&gt; beveragesOut = connector.sink("beverages");  <i class="conum" data-value="3"></i><b>(3)</b>

        Order order = new Order();
        order.setProduct("coffee");
        order.setName("Coffee lover");
        order.setOrderId("1234");

        ordersIn.send(order);  <i class="conum" data-value="4"></i><b>(4)</b>

        await().&lt;List&lt;? extends Message&lt;Beverage&gt;&gt;&gt;until(beveragesOut::received, t -&gt; t.size() == 1); <i class="conum" data-value="5"></i><b>(5)</b>

        Beverage queuedBeverage = beveragesOut.received().get(0).getPayload();
        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());
        Assertions.assertEquals("coffee", queuedBeverage.getBeverage());
        Assertions.assertEquals("Coffee lover", queuedBeverage.getCustomer());
        Assertions.assertEquals("1234", queuedBeverage.getOrderId());
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>在您的测试类中注入内存内连接器。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>检索传入 channel ( <code>orders</code> ) - 该 channel 必须在测试资源中被切换到内存中。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>检索传出 channel  ( <code>beverages</code> ) - 该 channel 必须在测试资源中被切换到内存中。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>使用 <code>send</code> 方法向 <code>orders</code>  channel 发送一个消息。应用程序将处理这个消息并向 <code>beverages</code>  channel 发送消息。</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>在 <code>beverages</code>  channel 上使用 <code>received</code> 方法来检查应用程序产生的消息。</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>有了内存 channels ，我们就可以测试应用程序代码的消息方法，而无需启动Kafka broker。请注意，不同的内存 channel 是独立的，将 channel 连接器切换到内存中并不能模拟配置到同一Kafka topic的 channel 之间的消息传递。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="testing-using-a-kafka-broker"><a class="anchor" href="#testing-using-a-kafka-broker"></a>17.2. 使用Kafka broker的测试</h3>
<div class="paragraph">
<p>如果您使用 <a href="#kafka-dev-services">[kafka-dev-services</a>] ，Kafka broker将被启动并在整个测试中可用，除非它在 <code>%test</code> profile中被禁用。虽然可以使用Kafka客户端API连接到这个broker，但 <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/">Kafka Companion Library</a> 提出了一种更简单的方式来与Kafka broker通信，并在测试中创建消费者、生产者和管理操作。</p>
</div>
<div class="paragraph">
<p>为了在测试中使用 <code>KafkaCompanion</code> API，首先要添加以下依赖：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-test-kafka-companion&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>它提供了 <code>io.quarkus.test.kafka.KafkaCompanionResource</code>&#8201;&#8212;&#8201;<code>io.quarkus.test.common.QuarkusTestResourceLifecycleManager</code> 的一种实现。</p>
</div>
<div class="paragraph">
<p>然后使用 <code>@QuarkusTestResource</code> 在测试中配置Kafka Companion，比如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import static org.junit.jupiter.api.Assertions.assertEquals;

import java.util.UUID;

import org.apache.kafka.clients.producer.ProducerRecord;
import org.junit.jupiter.api.Test;

import io.quarkus.test.common.QuarkusTestResource;
import io.quarkus.test.junit.QuarkusTest;
import io.quarkus.test.kafka.InjectKafkaCompanion;
import io.quarkus.test.kafka.KafkaCompanionResource;
import io.smallrye.reactive.messaging.kafka.companion.ConsumerTask;
import io.smallrye.reactive.messaging.kafka.companion.KafkaCompanion;

@QuarkusTest
@QuarkusTestResource(KafkaCompanionResource.class)
public class OrderProcessorTest {

    @InjectKafkaCompanion <i class="conum" data-value="1"></i><b>(1)</b>
    KafkaCompanion companion;

    @Test
    void testProcessor() {
        companion.produceStrings().usingGenerator(i -&gt; new ProducerRecord&lt;&gt;("orders", UUID.randomUUID().toString())); <i class="conum" data-value="2"></i><b>(2)</b>

        // Expect that the tested application processes orders from 'orders' topic and write to 'orders-processed' topic

        ConsumerTask&lt;String, String&gt; orders = companion.consumeStrings().fromTopics("orders-processed", 10); <i class="conum" data-value="3"></i><b>(3)</b>
        orders.awaitCompletion(); <i class="conum" data-value="4"></i><b>(4)</b>
        assertEquals(10, orders.count());
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>@InjectKafkaCompanion</code> 注入了 <code>KafkaCompanion</code> 实例，并被配置为可访问为测试目的而创建的Kafka broker。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>使用 <code>KafkaCompanion</code> 来创建生产者任务，用于向 'orders' topic写入10条记录。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>创建消费者任务，用来订阅&#8217;orders-processed&#8217;topic并消费10条记录。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>等待消费者任务的完成。</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>如果Kafka Dev Service在测试期间是可用的， <code>KafkaCompanionResource</code> 则会使用创建的Kafka broker，否则就使用 <a href="https://github.com/strimzi/test-container">Strimzi测试容器</a>创建一个Kafka broker。</p>
</div>
<div class="paragraph">
<p>创建Kafka broker的配置可以通过使用 <code>@ResourceArg</code> 来自定义，例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTestResource(value = KafkaCompanionResource.class, initArgs = {
        @ResourceArg(name = "strimzi.kafka.image", value = "quay.io/strimzi/kafka:0.28.0-kafka-3.0.0"), // Image name
        @ResourceArg(name = "kafka.port", value = "9092"), // Fixed port for kafka, by default it will be exposed on a random port
        @ResourceArg(name = "kraft", value = "true"), // Enable Kraft mode
        @ResourceArg(name = "num.partitions", value = "3"), // Other custom broker configurations
})
public class OrderProcessorTest {
    // ...
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="custom-test-resource"><a class="anchor" href="#custom-test-resource"></a>17.2.1. 自定义测试资源</h4>
<div class="paragraph">
<p>另外，您也可以在测试资源中启动一个Kafka broker。下面的片段展示了如何在一个测试资源使用 <a href="https://www.testcontainers.org/modules/kafka/">Testcontainers</a> 启动一个Kafka broker：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaResource implements QuarkusTestResourceLifecycleManager {

    private final KafkaContainer kafka = new KafkaContainer();

    @Override
    public Map&lt;String, String&gt; start() {
        kafka.start();
        return Collections.singletonMap("kafka.bootstrap.servers", kafka.getBootstrapServers());  <i class="conum" data-value="1"></i><b>(1)</b>
    }

    @Override
    public void stop() {
        kafka.close();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>配置Kafka bootstrap位置，这样应用程序就会连接到这个broker。</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-dev-services"><a class="anchor" href="#kafka-dev-services"></a>18. Kafka开发服务（Dev Services）</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果有任何Kafka相关的扩展（如 <code>quarkus-smallrye-reactive-messaging-kafka</code> ），Kafka开发服务会在开发模式和运行测试时自动启动一个Kafka broker。所以您不需要手动启动broker。这是由应用程序是自动配置的。</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
因为启动Kafka broker的时间可能很长，所以Kafka开发服务使用了 <a href="https://vectorized.io/redpanda">Redpanda</a> ，这是一个与Kafka兼容的broker，而且启动时间仅为1秒左右。
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="enabling-disabling-dev-services-for-kafka"><a class="anchor" href="#enabling-disabling-dev-services-for-kafka"></a>18.1. 启用/禁用Kafka开发服务</h3>
<div class="paragraph">
<p>Kafka的开发服务是自动启用的，除非：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus.kafka.devservices.enabled</code> 被设置为 <code>false</code></p>
</li>
<li>
<p>配置了 <code>kafka.bootstrap.servers</code> </p>
</li>
<li>
<p>所有的Reactive Messaging Kafka通道都设置了 <code>bootstrap.servers</code> 属性</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Kafka的开发服务依赖于Docker来启动broker。如果您的环境不支持Docker，您需要手动启动broker，或者连接到一个已经运行的broker。您可以使用 <code>kafka.bootstrap.servers</code> 来配置broker地址。</p>
</div>
</div>
<div class="sect2">
<h3 id="shared-broker"><a class="anchor" href="#shared-broker"></a>18.2. 共享的代理</h3>
<div class="paragraph">
<p>大多数情况下，您需要在应用程序之间共享broker。Kafka的开发服务实现了一个 <em>服务发现(service discovery)</em> 机制，可以让您的多个在 <em>开发</em> 模式下运行的Quarkus应用程序共享一个broker。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Kafka开发服务用 <code>quarkus-dev-service-kafka</code> 标签来启动容器，该标签用于识别容器。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>如果您需要多个（共享的）broker，您可以配置 <code>quarkus.kafka.devservices.service-name</code> 属性并指明broker的名称。它会查询一个具有相同名称的容器，如果找不到的话就启动一个新的容器。默认的服务名称是 <code>kafka</code> 。</p>
</div>
<div class="paragraph">
<p>在开发模式下，共享是默认启用的，但在测试模式下是禁用的。您可以用 <code>quarkus.kafka.devservices.shared=false</code> 停用共享。</p>
</div>
</div>
<div class="sect2">
<h3 id="setting-the-port"><a class="anchor" href="#setting-the-port"></a>18.3. 设置端口</h3>
<div class="paragraph">
<p>默认情况下，Kafka开发服务会随机挑选一个端口并配置应用程序。您可以通过配置 <code>quarkus.kafka.devservices.port</code> 属性来设置端口。</p>
</div>
<div class="paragraph">
<p>注意，Kafka的广告地址(advertised address)会自动配置为所选择的端口。</p>
</div>
</div>
<div class="sect2">
<h3 id="configuring-the-image"><a class="anchor" href="#configuring-the-image"></a>18.4. 配置镜像</h3>
<div class="paragraph">
<p>Kafka开发服务支持 <a href="https://redpanda.com">Redpanda</a> 和 <a href="https://strimzi.io">Strimzi</a> （在 <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md">Kraft</a> 模式下）。</p>
</div>
<div class="paragraph">
<p>Redpanda是一个兼容Kafka的事件流平台。因为它在dev服务默的 <code>vectorized/redpanda</code> 镜像中提供了更快的启动时间。您可以从 <a href="https://hub.docker.com/r/vectorized/redpanda" class="bare">https://hub.docker.com/r/vectorized/redpanda</a>  中选择任何版本。</p>
</div>
<div class="paragraph">
<p>Strimzi为在Kubernetes上运行Apache Kafka提供了容器镜像和Operator。虽然Strimzi针对Kubernetes进行了优化，但这些镜像在经典的容器环境中也能完美运行。Strimzi容器镜像在JVM上运行 "真实的 "Kafka broker，其启动速度较慢。</p>
</div>
<div class="paragraph">
<p>对于Strimzi，您可以从 <a href="https://quay.io/repository/strimzi-test-container/test-container?tab=tags" class="bare">https://quay.io/repository/strimzi-test-container/test-container?tab=tags</a> ，选择任何可以获得Kraft支持的Kafka版本（2.8.1及以上）的镜像</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.image-name=quay.io/strimzi-test-container/test-container:0.100.0-kafka-3.1.0</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="configuring-kafka-topics"><a class="anchor" href="#configuring-kafka-topics"></a>18.5. 配置Kafka主题</h3>
<div class="paragraph">
<p>您可以配置Kafka开发服务来在broker启动后创建主题。主题以给定的分区数量以及1个副本创建。</p>
</div>
<div class="paragraph">
<p>下面的例子创建了一个名为 <code>test</code> ，有3个分区的主题，以及另一个名为 <code>messages</code> ，有2个分区的主题。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.topic-partitions.test=3
quarkus.kafka.devservices.topic-partitions.messages=2</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果具有某个指定名称的主题已经存在，那么创建会被跳过，并且不会尝试对已经存在的主题重新分区到不同的数量。</p>
</div>
<div class="paragraph">
<p>您可以通过 <code>quarkus.kafka.devservices.topic-partitions-timeout</code> 来配置在主题创建中所使用的Kafka管理员客户端调用的超时时间，默认为2秒。</p>
</div>
</div>
<div class="sect2">
<h3 id="redpanda-transactions"><a class="anchor" href="#redpanda-transactions"></a>18.6. Transactional and Idempotent producers support</h3>
<div class="paragraph">
<p>By default, the Red Panda broker is configured to enable transactions and idempotence features.
You can disable those using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.redpanda.transaction-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Redpanda transactions does not support exactly-once processing.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kubernetes-service-bindings"><a class="anchor" href="#kubernetes-service-bindings"></a>19. Kubernetes服务绑定</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus Kafka扩展支持 <a href="deploying-to-kubernetes.html">Kubernetes服务绑定规范</a> 。您可以通过添加 <code>quarkus-kubernetes-service-binding</code> 扩展来启用它。</p>
</div>
<div class="paragraph">
<p>当在正确配置的Kubernetes集群中运行时，Kafka扩展将从集群内部可用的服务绑定中获取Kafka broker连接配置，而不需要用户来配置。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="execution-model"><a class="anchor" href="#execution-model"></a>20. 执行模型</h2>
<div class="sectionbody">
<div class="paragraph">
<p>响应式流会在I/O线程上调用用户的方法。因此在默认情况下，这些方法不能阻塞。正如 <a href="#blocking-processing">[阻塞处理</a>] 中所述，如果这个方法会阻塞调用者线程，那么您需要在方法上添加 <code>@Blocking</code> 注解。</p>
</div>
<div class="paragraph">
<p>关于这个话题的更多细节，请看 <a href="quarkus-reactive-architecture.html">Quarkus响应式架构文档</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="channel-decorators"><a class="anchor" href="#channel-decorators"></a>21. Channel Decorators</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SmallRye Reactive Messaging supports decorating incoming and outgoing channels for implementing cross-cutting concerns such as monitoring, tracing or message interception. For more information on implementing decorators and message interceptors see the <a href="http://smallrye.io/smallrye-reactive-messaging/3.19.1/concepts/decorators/">SmallRye Reactive Messaging documentation</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-configuration"><a class="anchor" href="#kafka-configuration"></a>22. 配置参考</h2>
<div class="sectionbody">
<div class="paragraph">
<p>More details about the SmallRye Reactive Messaging configuration can be found in the <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/kafka/#using-the-kafka-connector">SmallRye Reactive Messaging - Kafka Connector Documentation</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>每个 channel 都可以通过配置来禁用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.[incoming|outgoing].[channel].enabled=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>以下表格中列出了最重要的属性：</p>
</div>
<div class="sect2">
<h3 id="incoming-channel-configuration-polling-from-kafka"><a class="anchor" href="#incoming-channel-configuration-polling-from-kafka"></a>22.1. 入站 channel 配置(从Kafka轮询)</h3>
<div class="paragraph">
<p>以下属性通过该方式进行配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>有些属性拥有可以进行全局配置的别名：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>您也可以传递底层 <a href="https://kafka.apache.org/documentation/#consumerconfigs">Kafka消费者</a> 支持的任何属性。</p>
</div>
<div class="paragraph">
<p>例如，要配置 <code>max.poll.records</code> 属性，可以使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.poll.records=1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>一些消费者客户端属性被配置为相对合理的默认值：</p>
</div>
<div class="paragraph">
<p>如果没有设置， <code>reconnect.backoff.max.ms</code> 则会被配置为 <code>10000</code> ，以避免断开时导致的高负载。</p>
</div>
<div class="paragraph">
<p>如果没有设置， <code>key.deserializer</code> 则会被设置为 <code>org.apache.kafka.common.serialization.StringDeserializer</code> 。</p>
</div>
<div class="paragraph">
<p>消费者 <code>client.id</code> 会根据使用 <code>mp.messaging.incoming.[channel].partitions</code> 属性创建的客户端数量进行配置。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果提供了一个 <code>client.id</code> ，它将直接被使用， 或者如果 <code>partitions</code> 属性被设置的话，则会被加上客户端索引的后缀。</p>
</li>
<li>
<p>如果没有提供 <code>client.id</code> ，则使用 <code>kafka-consumer-[channel][-index]</code> 来生成 。</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. 'smallrye-kafka' 连接器的传入属性</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">属性 <em>（别名）</em></th>
<th class="tableblock halign-left valign-top">描述</th>
<th class="tableblock halign-left valign-top">是否强制</th>
<th class="tableblock halign-left valign-top">默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用逗号分隔的主机：端口列表，用于建立与Kafka集群的初始连接。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">被消费/生产消息的Kafka主题。如果这个属性和 <code>topics</code> 属性都没有设置，则使用通道名称。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">健康报告是否被启用（默认启用）或禁用</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否启用（默认启用）或禁用就绪情况报告</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>已废弃</em> - 就绪检查是否应该验证broker上是否存在主题。默认为false。启用它需要一个管理员连接。已废弃：请使用 'health-topic-verification-enabled' 代替。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>已废弃</em> - 在就绪状态健康检查期间，连接器会连接到broker并获取主题列表。这个属性指定了获取操作的最大耗时（ms）。如果超时，通道会被认为是没有就绪的。已废弃：使用&#8217;health-topic-verification-timeout&#8217;代替。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">启动和就绪检查是否要验证broker上存在主题。默认为false。启用它需要一个管理员客户端连接。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在启动和就绪的健康检查期间，连接器会连接到broker并获取主题列表。这个属性指定了获取的最大耗时（ms）。如果超时，通道就被认为是没有就绪的。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否启用（默认启用）或禁用tracing</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">启用（默认启用）或停用云事件支持。如果在 <em>传入</em> 通道上启用，连接器会分析传入记录并尝试创建云事件元数据。如果在 <em>传出</em> 通道上启用，并且如果消息包括云事件元数据，连接器会将传出的消息作为云事件发送。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">为通道提供默认Kafka消费者/生产者配置的CDI bean的标识符。通道自身的配置仍可以覆盖任何属性。该bean必须有一个Map&lt;String, Object&gt;的类型，并且必须使用@io.smallrye.common.annotation.Identifier限定符来设置标识符。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topics</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separating list of topics to be consumed. Cannot be used with the <code>topic</code> or <code>pattern</code> properties</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pattern</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">表示 <code>topic</code> 属性是一个正则表达式。必须与 <code>topic</code> 属性一起使用。不能与 <code>topics</code> 属性一起使用</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于反序列化记录的键值的反序列化器的类名</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringDeserializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于反序列化记录的值的反序列化器的类名</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fetch.min.bytes</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">针对一个获取请求，服务器所应该返回的最小数据量。默认设置为1个字节，意味着在等待数据到达的同时，一旦有一个字节的数据可用，那么获取请求就会被响应，或者直至获取请求超时。</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>group.id</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">一个唯一的字符串，用于识别应用程序所属的消费者组。</p>
<p class="tableblock">如果未设置, 那么默认为通过 <code>quarkus.application.name</code> 所设定的应用程序名称。</p>
<p class="tableblock">如果这个属性也没有设置，那么会使用一个生成的唯一的id。</p>
<p class="tableblock">建议总是设置一个 <code>group.id</code>，因为自动生成只是一个方便在开发模式中使用的特性。
你可以通过将该属性设置为 <code>${quarkus.uuid}</code> 来显示的获取自动生成的唯一的id。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>enable.auto.commit</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果启用，消费者的偏移量将由底层Kafka客户端在后台定期提交，并忽略记录的实际处理结果。建议不要启用这个设置，而是由Reactive Messaging来处理提交。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the connection to the broker is re-attempted in case of failure</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-attempts</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">失败前的最大重连次数。-1表示无限重试</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-max-wait</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">两次重新连接之间的最大延迟（秒）</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>30</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>broadcast</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka records should be dispatched to multiple consumer</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>auto.offset.reset</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当Kafka没有初始偏移量时的处理策略。可接受的值是earliest, latest 和 none</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>latest</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>failure-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当记录产生的消息未被确认（nack）时要应用的失败策略。值可以是 <code>fail</code> （默认）， <code>ignore</code> ，或 <code>dead-letter-queue</code> </p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>fail</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>commit-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">记录产生的消息被确认时的提交策略。值可以是 <code>latest</code> , <code>ignore</code> 或 <code>throttled</code> 。如果 <code>enable.auto.commit</code> 为真，则默认为 <code>ignore</code> ，否则为 <code>throttled</code> </p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>throttled.unprocessed-record-max-age.ms</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在使用 <code>throttled</code> 提交策略时，指定未处理的消息在连接器被标记为不健康之前的可存续的最大时间（毫秒）。将此属性设置为0可以禁用该监控。</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>60000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当 <code>failure-strategy</code> 被设置为 <code>dead-letter-queue</code> ，用来指明记录会发送到哪个主题的。默认值是 <code>dead-letter-topic-$channel</code> </p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当 <code>failure-strategy</code> 被设置为 <code>dead-letter-queue</code> 时，表示要使用的键值的序列化器。如果没有设置则使用与键值反序列化器相关的序列化器</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当 <code>failure-strategy</code> 被设置为 <code>dead-letter-queue</code> ，表示要使用的值的序列化器。如果没有设置，则使用与值反序列化器相关的序列化器n</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partitions</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">并发消费的分区的数量。连接器会创建指定数量的Kafka消费者。它应该与目标主题的分区数量相匹配</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When <code>partitions</code> is greater than 1, this attribute allows configuring how many records are requested by each consumer every time.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>128</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>consumer-rebalance-listener.name</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在 <code>@Identifier</code> 中设置的实现了 <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> 的bean的名称。如果被设置，那么这个再均衡监听器就会应用到消费者上。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在 <code>@Identifier</code> 中设置的实现了 <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code> 的bean的名称。如果被设置，那么在反序列化键时发生的反序列化失败将被委托给这个处理程序，它可以重试或提供一个回退值。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在 <code>@Identifier</code> 中设置的实现了 <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code> 的bean的名称。如果被设置，那么在反序列化值时发生的反序列化失败将被委托给这个处理程序，它可以重试或提供一个回退值。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fail-on-deserialization-failure</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当没有设置反序列化失败处理程序而反序列化失败发生时，报告该失败并将应用程序标记为不健康。如果设置为 <code>false</code> 并且发生了反序列化失败，会发送一个 <code>null</code> 。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>graceful-shutdown</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether a graceful shutdown should be attempted when the application terminates.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>poll-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">以毫秒为单位的轮询超时时间。当轮询记录时，轮询将在返回记录之前最多等待该时间段。默认是1000ms</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1000</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pause-if-no-requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">当应用程序不请求记录时，轮询是否必须被暂停，或应用程序开始请求记录时轮询是否要恢复。该属性允许实现基于应用容量的背压。需要注意轮询不会停止，但当暂停时不会获取任何记录。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>batch</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否启用Kafka记录的批处理。通道的注入点必须消费一个兼容的类型，例如 <code>List&lt;Payload&gt;</code> 或 <code>KafkaRecordBatch&lt;Payload&gt;</code>.</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-queue-size-factor</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于决定队列中待处理的记录的最大值的乘数因子，使用 <code>max.poll.records</code> * <code>max-queue-size-factor</code> 来决定。默认为2。在 <code>batch</code> 模式下 <code>max.poll.records</code> 为 <code>1</code>。</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="outgoing-channel-configuration-writing-to-kafka"><a class="anchor" href="#outgoing-channel-configuration-writing-to-kafka"></a>22.2. 出站 channel 配置(写入Kafka)。</h3>
<div class="paragraph">
<p>以下属性通过该方式进行配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>有些属性拥有可以进行全局配置的别名：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>您也可以传递底层 <a href="https://kafka.apache.org/documentation/#producerconfigs">Kafka生产者</a> 支持的任何属性。</p>
</div>
<div class="paragraph">
<p>例如，要配置 <code>max.block.ms</code> 属性，可以使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.block.ms=10000</code></pre>
</div>
</div>
<div class="paragraph">
<p>一些生产者客户端属性被配置为合理的默认值：</p>
</div>
<div class="paragraph">
<p>如果没有设置， <code>reconnect.backoff.max.ms</code> 则会被配置为 <code>10000</code> ，以避免断开时导致的高负载。</p>
</div>
<div class="paragraph">
<p>如果没有设置， <code>key.serializer</code> 则会被设置为 <code>org.apache.kafka.common.serialization.StringSerializer</code> 。</p>
</div>
<div class="paragraph">
<p>如果没有设置，生产者 <code>client.id</code> 则会按照 <code>kafka-producer-[channel]</code> 来生成。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. 'smallrye-kafka' 连接器的传出属性</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">属性 <em>（别名）</em></th>
<th class="tableblock halign-left valign-top">描述</th>
<th class="tableblock halign-left valign-top">是否强制</th>
<th class="tableblock halign-left valign-top">默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>acks</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">生产者要求领导者认为一个请求完成之前收到的确认的数量。这控制了发送记录的延续性。可接受的值是：0, 1, all</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用逗号分隔的主机：端口列表，用于建立与Kafka集群的初始连接。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>buffer.memory</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">生产者可用于缓冲等待发送至服务器的记录的总字节数。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>33554432</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>close-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">等待Kafka生产者平滑关闭的毫秒数</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>10000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">启用（默认启用）或停用云事件支持。如果在 <em>传入</em> 通道上启用，连接器会分析传入记录并尝试创建云事件元数据。如果在 <em>传出</em> 通道上启用，并且如果消息包括云事件元数据，连接器会将传出的消息作为云事件发送。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-content-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-content-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">配置传出的云事件的默认 <code>datacontenttype</code> 属性。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>datacontenttype</code> 属性，则使用此值</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-schema</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-schema)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">配置传出的云事件的默认 <code>dataschema</code> 属性。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>dataschema</code> 属性，则使用此值</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-insert-timestamp</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-timestamp)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">连接器是否应将 <code>time</code> 属性自动插入到传出的云事件中。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>time</code> 属性，则使用此值</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-mode</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">云事件模式（ <code>structured</code> 或 <code>binary</code> （默认））。表示如何在传出的记录中写入云事件</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>binary</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-source</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-source)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">配置传出的云事件的默认 <code>source</code> 属性。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>source</code> 属性，则使用此值</p>
<p class="tableblock">类型: _string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-subject</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-subject)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">配置传出的云事件的默认 <code>subject</code> 属性。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>subject</code> 属性，则使用此值</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">配置传出的云事件的默认 <code>type</code> 属性。要求将 <code>cloud-events</code> 设为 <code>true</code> 。如果消息本身没有配置 <code>type</code> 属性，则使用此值</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">健康报告是否被启用（默认启用）或禁用</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否启用（默认启用）或禁用就绪情况报告</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>已废弃</em> - 在就绪状态健康检查期间，连接器会连接到broker并获取主题列表。这个属性指定了获取操作的最大耗时（ms）。如果超时，通道会被认为是没有就绪的。已废弃：使用&#8217;health-topic-verification-timeout&#8217;代替。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>已废弃</em> - 就绪检查是否应该验证broker上是否存在主题。默认为false。启用它需要一个管理员连接。已废弃：请使用 'health-topic-verification-enabled' 代替。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">启动和就绪检查是否要验证broker上存在主题。默认为false。启用它需要一个管理员客户端连接。</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在启动和就绪的健康检查期间，连接器会连接到broker并获取主题列表。这个属性指定了获取的最大耗时（ms）。如果超时，通道就被认为是没有就绪的。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">为通道提供默认Kafka消费者/生产者配置的CDI bean的标识符。通道自身的配置仍可以覆盖任何属性。该bean必须有一个Map&lt;String, Object&gt;的类型，并且必须使用@io.smallrye.common.annotation.Identifier限定符来设置标识符。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">写入记录时使用的键值</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在 <code>@Identifier</code> 中设置的实现了 <code>io.smallrye.reactive.messaging.kafka.SerializationFailureHandler</code> 的bean的名称。如果被设置，那么在序列化键时发生的序列化失败将被委托给这个处理程序，它会重试或提供一个回退值。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用来序列化记录的键的序列化器类名</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringSerializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-inflight-messages</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">并发写入Kafka的消息的最大数量。它限制了等待被写入和被broker确认的消息的数量。你设置为： <code>0</code> 以解除该限制</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1024</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>merge</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">连接器是否应允许多个上游</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partition</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">目标分区的ID。设置为-1可以客户端自行确定分区</p>
<p class="tableblock">类型: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-headers</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separating list of incoming record headers to be propagated to the outgoing record</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-record-key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否将传入的记录键添加到传出的记录中</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retries</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果设置为正数，连接器将尝试重新发送任何没有成功传递的记录（有可能是瞬时错误），直到达到重试的上限。如果设置为0，重试将被禁用。如果不设置，连接器会在 <code>delivery.timeout.ms</code> 配置的时间内，尝试重新发送任何未能交付的记录（由于潜在的瞬时错误）。</p>
<p class="tableblock">类型: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2147483647</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">被消费/生产消息的Kafka主题。如果这个属性和 <code>topics</code> 属性都没有设置，则使用通道名称。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是否启用（默认启用）或禁用tracing</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在 <code>@Identifier</code> 中设置的实现了 <code>io.smallrye.reactive.messaging.kafka.SerializationFailureHandler</code> 的bean的名称。如果被设置，那么在序列化值时发生的序列化失败将被委托给这个处理程序，它会重试或提供一个回退值。</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于序列化payload的序列化器的类名</p>
<p class="tableblock">类型: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>waitForWriteCompletion</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在确认消息之前，客户端是否会等待Kafka确认写入的记录</p>
<p class="tableblock">类型: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> </p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="kafka-configuration-resolution"><a class="anchor" href="#kafka-configuration-resolution"></a>22.3. Kafka配置方案</h3>
<div class="paragraph">
<p>Quarkus公开了所有与Kafka相关的应用属性，这些属性使用 <code>default-kafka-broker</code> 名称加 <code>kafka.</code> 或 <code>KAFKA_</code> 的前缀 。这个配置被用来建立与Kafka broker的连接。</p>
</div>
<div class="paragraph">
<p>除了这个默认配置外，您还可以使用 <code>kafka-configuration</code> 属性配置 <code>Map</code> 生产者的名称：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.my-channel.connector=smallrye-kafka
mp.messaging.incoming.my-channel.kafka-configuration=my-configuration</code></pre>
</div>
</div>
<div class="paragraph">
<p>在这种情况下，连接器会查询与 <code>my-configuration</code> 名称相关的 <code>Map</code> 。如果没有设置 <code>kafka-configuration</code> ，就会进行额外的查询来寻找与 channel 名称相关的 <code>Map</code> (在前面的例子中是 <code>my-channel</code> )。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Produces
@ApplicationScoped
@Identifier("my-configuration")
Map&lt;String, Object&gt; outgoing() {
    return Map.ofEntries(
            Map.entry("value.serializer", ObjectMapperSerializer.class.getName())
    );
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
如果设置了 <code>kafka-configuration</code> ，但没有找到 <code>Map</code> ，则部署会失败。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>属性值的解决方式如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>属性是直接在 channel 配置上设置的( <code>mp.messaging.incoming.my-channel.attribute=value</code> ),</p>
</li>
<li>
<p>如果没有设置，连接器会使用 channel 名称或 <code>kafka-configuration</code> (如果设置了)来查找查找一个 <code>Map</code> ，并从 <code>Map</code> 中取值</p>
</li>
<li>
<p>如果 <code>Map</code> 不包含该值，则使用默认的 <code>Map</code> (通过 <code>default-kafka-broker</code> 名称暴露)</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="integrating-with-kafka-common-patterns"><a class="anchor" href="#integrating-with-kafka-common-patterns"></a>23. 与Kafka的整合&#8212;&#8203;通用模式</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="writing-to-kafka-from-an-http-endpoint"><a class="anchor" href="#writing-to-kafka-from-an-http-endpoint"></a>23.1. 从HTTP节点写消息到Kafka</h3>
<div class="paragraph">
<p>要从HTTP节点向Kafka发送消息，可以在您的节点中注入一个 <code>Emitter</code> (或一个 <code>MutinyEmitter</code> )：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;String&gt; emitter;          <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) { <i class="conum" data-value="2"></i><b>(2)</b>
        return emitter.send(payload);                   <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>注入一个 <code>Emitter&lt;String&gt;</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>HTTP方法接会接收payload，并在消息被写入Kafka时返回一个 <code>CompletionStage</code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>将消息发送到Kafka后， <code>send</code> 方法会返回一个 <code>CompletionStage</code></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>节点将已传递的payload(来自 <code>POST</code> HTTP请求)发送给emitter。emitter的 channel 被映射到 <code>application.properties</code> 文件中指定的一个Kafka topic：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.kafka.connector=smallrye-kafka
mp.messaging.outgoing.kafka.topic=my-topic</code></pre>
</div>
</div>
<div class="paragraph">
<p>节点会返回一个 <code>CompletionStage</code> ，表明该方法是异步的。 <code>emitter.send</code> 方法返回一个 <code>CompletionStage&lt;Void&gt;</code> 。当消息被写入Kafka时，返回的Future就被认为i完成了。如果写入失败，返回的 <code>CompletionStage</code> 会抛出异常。</p>
</div>
<div class="paragraph">
<p>如果节点没有返回 <code>CompletionStage</code> ，HTTP响应可能会返回在消息被发送到Kafka之前，因此失败不会被报告给用户。</p>
</div>
<div class="paragraph">
<p>如果您需要发送一条Kafka记录，请使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import io.smallrye.reactive.messaging.kafka.Record;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Record&lt;String,String&gt;&gt; emitter;  <i class="conum" data-value="1"></i><b>(1)</b>


    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) {
        return emitter.send(Record.of("my-key", payload));    <i class="conum" data-value="2"></i><b>(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>声明 <code>Emitter&lt;Record&lt;K, V&gt;&gt;</code> 的使用</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>通过 <code>Record.of(k, v)</code> 来创建记录</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-with-panache"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-with-panache"></a>23.2. 用Hibernate与Panache来持久化Kafka消息</h3>
<div class="paragraph">
<p>为了将从Kafka接收到的对象持久化到数据库中，您可以结合使用Hibernate与Panache。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
如果您使用Hibernate Reactive，请参看 <a href="#persisting-kafka-messages-with-hibernate-reactive">[使用Hibernate Reactive持久化Kafka消息</a>] 。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>让我们假设您收到了 <code>Fruit</code> 对象。为了简单起见，我们的 <code>Fruit</code> 类非常简单：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.orm.panache.PanacheEntity;

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>为了消费存储在Kafka topic上的 <code>Fruit</code> 实例，并将其持久化到数据库中，您可以使用以下方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.smallrye.common.annotation.Blocking;

@ApplicationScoped
public class FruitConsumer {

    @Incoming("fruits")                                     <i class="conum" data-value="1"></i><b>(1)</b>
    @Transactional                                          <i class="conum" data-value="2"></i><b>(2)</b>
    public void persistFruits(Fruit fruit) {                <i class="conum" data-value="3"></i><b>(3)</b>
        fruit.persist();                                    <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>配置传入 channel 。该 channel 从Kafka读取消息。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>由于我们是往数据库中写入数据，所以必须使用事务。这个注解启动了一个新的事务，并在方法返回时提交它。Quarkus会自动认为这个方法是 <em>阻塞的</em> 。事实上，使用常规的Hibernate方法向数据库写入是阻塞操作。所以，Quarkus会在一个可阻塞的工作线程中调用这个方法(而不是在I/O线程中)。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>该方法接收每个Fruit对象。注意，您需要一个反序列化器来从Kafka记录中重建Fruit实例。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>持久化接收到的 <code>fruit</code> 对象。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>正如&lt;4&gt;中提到的，您需要一个能从记录中重建 <code>Fruit</code> 对象的反序列化器。可以使用Jackson的反序列化器来完成：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>相关的配置如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>请参看 <a href="#jackson-serialization">[jackson序列化</a>]，了解更多关于Jackson与Kafka的使用细节。您也可以使用Avro。</p>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-reactive"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-reactive"></a>23.3. 使用Hibernate Reactive持久化Kafka消息</h3>
<div class="paragraph">
<p>为了将从Kafka收到的对象持久化到数据库中，您可以结合使用Hibernate Reactive与Panache。</p>
</div>
<div class="paragraph">
<p>让我们假设您收到了 <code>Fruit</code> 对象。为了简单起见，我们的 <code>Fruit</code> 类非常简单：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.reactive.panache.PanacheEntity;  <i class="conum" data-value="1"></i><b>(1)</b>

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>请确保使用响应式变量</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>为了消费存储在Kafka topic上的 <code>Fruit</code> 实例，并将其持久化到数据库中，您可以使用以下方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;

@ApplicationScoped
public class FruitStore {

    @Inject
    Mutiny.Session session;                    <i class="conum" data-value="1"></i><b>(1)</b>

    @Incoming("in")
    public Uni&lt;Void&gt; consume(Fruit entity) {
        return session.withTransaction(t -&gt; {  <i class="conum" data-value="2"></i><b>(2)</b>
            return entity.persistAndFlush()    <i class="conum" data-value="3"></i><b>(3)</b>
                    .replaceWithVoid();        <i class="conum" data-value="4"></i><b>(4)</b>
        }).onTermination().call(() -&gt; session.close()); <i class="conum" data-value="5"></i><b>(5)</b>
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject the Hibernate Reactive <code>Session</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Requests a new transaction. The transaction completes when the passed action completes.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>持久化该实体对象。它会返回一个 <code>Uni&lt;Fruit&gt;</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>切换并返回 <code>Uni&lt;Void&gt;</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Close the session - this is close the connection with the database. The connection can then be recycled.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Unlike with <em>classic</em> Hibernate, you can&#8217;t use <code>@Transactional</code>.
Instead, we use <code>session.withTransaction</code> and persist our entity.
The <code>map</code> is used to return a <code>Uni&lt;Void&gt;</code> and not a <code>Uni&lt;Fruit&gt;</code>.</p>
</div>
<div class="paragraph">
<p>您需要一个能从记录中创建 <code>Fruit</code> 实例的反序列化器。可以使用Jackson的反序列化器来完成：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>相关的配置如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>请参看 <a href="#jackson-serialization">[jackson序列化</a>]，了解更多关于Jackson与Kafka的使用细节。您也可以使用Avro。</p>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-to-kafka"></a>23.4. 将Hibernate管理的实体写入Kafka中</h3>
<div class="paragraph">
<p>让我们假设以下过：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>您收到一个带有payload的HTTP请求,</p>
</li>
<li>
<p>您从这个payload中创建一个Hibernate实体对象,</p>
</li>
<li>
<p>您将该实体持久化到数据库中,</p>
</li>
<li>
<p>您把实体发送到一个Kafka topic中</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
如果您使用Hibernate Reactive，请参看<a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">[将hibernate reactive管理的实体写入kafka</a>] 。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>因为我们要往数据库写入数据，所以我们必须在事务中运行该方法。然而，向Kafka发送消息是异步的。该操作完成后会返回一个 <code>CompletionStage</code> (如果您使用 <code>MutinyEmitter</code>，则返回 <code>Uni</code>)。我们必须确认在对象被写入之前事务仍然在运行。否则，您可能会在事务之外访问到该对象，而这是不允许的。</p>
</div>
<div class="paragraph">
<p>为了实现这一过程，您需要采取以下方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.transaction.Transactional;
import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Fruit&gt; emitter;

    @POST
    @Path("/fruits")
    @Transactional                                                      <i class="conum" data-value="1"></i><b>(1)</b>
    public CompletionStage&lt;Void&gt; storeAndSendToKafka(Fruit fruit) {     <i class="conum" data-value="2"></i><b>(2)</b>
        fruit.persist();
        return emitter.send(fruit);                                     <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>当我们向数据库中写入数据时，请确保运行在事务中</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>该方法接收要持久化的fruit实例。它返回了一个 <code>CompletionStage</code> ，用于事务分界。当返回的 <code>CompletionStage</code> 完成时，事务即会提交。在我们的例子中，这种情况就是消息被写入Kafka的时候。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>将管理的实例发送到Kafka。确保我们在事务关闭之前等待消息的完成。</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-reactive-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-reactive-to-kafka"></a>23.5. 将Hibernate Reactive管理的实体写入Kafka中</h3>
<div class="paragraph">
<p>为了将Hibernate Reactive管理的实体发送到Kafka，建议使用：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>RESTEasy Reactive为HTTP请求提供服务</p>
</li>
<li>
<p><code>MutinyEmitter</code> 会向 channel 发送消息，所以它可以很容易地与Hibernate Reactive或Hibernate Reactive with Panache所暴露的Mutiny API进行集成。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>下面的例子演示了如何接收一个payload，使用Hibernate Reactive with Panache将其存储在数据库中，并将持久化的实体发送到Kafka：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/")
public class ReactiveGreetingResource {

    @Channel("kafka") MutinyEmitter&lt;Fruit&gt; emitter;     <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    public Uni&lt;Void&gt; sendToKafka(Fruit fruit) {         <i class="conum" data-value="2"></i><b>(2)</b>
        return Panache.withTransaction(() -&gt;            <i class="conum" data-value="3"></i><b>(3)</b>
            fruit.&lt;Fruit&gt;persist()
        )
            .chain(f -&gt; emitter.send(f));               <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>注入一个暴露了Mutiny API的 <code>MutinyEmitter</code> 。它简化了与Hibernate Reactive with Panache所暴露的Mutiny API的整合。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>接收payload的HTTP方法返回一个 <code>Uni&lt;Void&gt;</code> 。当操作完成后，会返回HTTP响应(实体被持久化并被写入Kafka)。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>我们需要在一个事务中把实体写进数据库。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>一旦持久化操作完成，我们就把实体发送到Kafka。 <code>send</code> 方法会返回一个 <code>Uni&lt;Void&gt;</code> 。</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="streaming-kafka-topics-as-server-sent-events"><a class="anchor" href="#streaming-kafka-topics-as-server-sent-events"></a>23.6. 将Kafka topic作为服务器发送的事件流化</h3>
<div class="paragraph">
<p>将Kafka topic作为服务器发送的事件(Server-sent events, SSE)进行流化非常直白:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>您在您的HTTP节点中注入代表Kafka topic的 channel</p>
</li>
<li>
<p>您将该 channel 作为一个 <code>Publisher</code> 或 <code>Multi</code> 从HTTP方法中返回</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>以下代码提供了一个例子：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;Fruit&gt; stream() {
    return fruits;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>当没有足够的活跃度时，一些环境会切断SSE的连接。替代方法则是定期发送 <em>ping</em> 消息(或空对象)。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@Inject
ObjectMapper mapper;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;String&gt; stream() {
    return Multi.createBy().merging()
            .streams(
                    fruits.map(this::toJson),
                    emitAPeriodicPing()
            );
}

Multi&lt;String&gt; emitAPeriodicPing() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))
            .onItem().transform(x -&gt; "{}");
}

private String toJson(Fruit f) {
    try {
        return mapper.writeValueAsString(f);
    } catch (JsonProcessingException e) {
        throw new RuntimeException(e);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>该替代方法有点复杂，因为除了发送来自Kafka的fruit实例，我们还需要定期发送ping。为了实现这一点，我们合并了来自Kafka的数据流和一个每10秒发送一个 <code>{}</code> 的数据流。</p>
</div>
</div>
<div class="sect2">
<h3 id="chaining-kafka-transactions-with-hibernate-reactive-transactions"><a class="anchor" href="#chaining-kafka-transactions-with-hibernate-reactive-transactions"></a>23.7. Chaining Kafka Transactions with Hibernate Reactive transactions</h3>
<div class="paragraph">
<p>By chaining a Kafka transaction with a Hibernate Reactive transaction you can send records to a Kafka transaction,
perform database updates and commit the Kafka transaction only if the database transaction is successful.</p>
</div>
<div class="paragraph">
<p>The following example demonstrates:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Receive a payload by serving HTTP requests using RESTEasy Reactive,</p>
</li>
<li>
<p>Limit concurrency of that HTTP endpoint using Smallrye Fault Tolerance,</p>
</li>
<li>
<p>Start a Kafka transaction and send the payload to Kafka record,</p>
</li>
<li>
<p>Store the payload in the database using Hibernate Reactive with Panache,</p>
</li>
<li>
<p>Commit the Kafka transaction only if the entity is persisted successfully.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1) <i class="conum" data-value="2"></i><b>(2)</b>
    public Uni&lt;Void&gt; post(Fruit fruit) { <i class="conum" data-value="3"></i><b>(3)</b>
        return kafkaTx.withTransaction(emitter -&gt; { <i class="conum" data-value="4"></i><b>(4)</b>
            emitter.send(fruit); <i class="conum" data-value="5"></i><b>(5)</b>
            return Panache.withTransaction(() -&gt; { <i class="conum" data-value="6"></i><b>(6)</b>
                return fruit.&lt;Fruit&gt;persist(); <i class="conum" data-value="7"></i><b>(7)</b>
            });
        }).replaceWithVoid();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject a <code>KafkaTransactions</code> which exposes a Mutiny API. It allows the integration with the Mutiny API exposed by Hibernate Reactive with Panache.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Limit the concurrency of the HTTP endpoint to "1", preventing starting multiple transactions at a given time.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The HTTP method receiving the payload returns a <code>Uni&lt;Void&gt;</code>. The HTTP response is written when the operation completes (the entity is persisted and Kafka transaction is committed).</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Begin a Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Send the payload to Kafka inside the Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Persist the entity into the database in a Hibernate Reactive transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Once the persist operation completes, and there is no errors, the Kafka transaction is committed.
The result is omitted and returned as the HTTP response.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the previous example the database transaction (inner) will commit followed by the Kafka transaction (outer).
If you wish to commit the Kafka transaction first and the database transaction second, you need to nest them in the reverse order.</p>
</div>
<div class="paragraph">
<p>The next example demonstrates that using the Hibernate Reactive API (without Panache):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;
import io.vertx.mutiny.core.Context;
import io.vertx.mutiny.core.Vertx;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx;

    @Inject Mutiny.SessionFactory sf; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1)
    public Uni&lt;Void&gt; post(Fruit fruit) {
        Context context = Vertx.currentContext(); <i class="conum" data-value="2"></i><b>(2)</b>
        return sf.withTransaction(session -&gt; <i class="conum" data-value="3"></i><b>(3)</b>
                kafkaTx.withTransaction(emitter -&gt; <i class="conum" data-value="4"></i><b>(4)</b>
                        session.persist(fruit).invoke(() -&gt; emitter.send(fruit)) <i class="conum" data-value="5"></i><b>(5)</b>
                ).emitOn(context::runOnContext) <i class="conum" data-value="6"></i><b>(6)</b>
        );
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject the Hibernate Reactive <code>SessionFactory</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Capture the caller Vert.x context.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Begin a Hibernate Reactive transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Begin a Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Persist the payload and send the entity to Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The Kafka transaction terminates on the Kafka producer sender thread.
We need to switch to the Vert.x context previously captured in order to terminate the Hibernate Reactive transaction on the same context we started it.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="logging"><a class="anchor" href="#logging"></a>24. 日志</h2>
<div class="sectionbody">
<div class="paragraph">
<p>为了减少Kafka客户端的日志量，Quarkus将以下日志类别的级别设置为 <code>WARNING</code>：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.apache.kafka.clients</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.metrics</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>您可以通过在 <code>application.properties</code> 中添加以下属性来覆盖配配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.log.category."org.apache.kafka.clients".level=INFO
quarkus.log.category."org.apache.kafka.common.utils".level=INFO
quarkus.log.category."org.apache.kafka.common.metrics".level=INFO</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="connecting-to-managed-kafka-clusters"><a class="anchor" href="#connecting-to-managed-kafka-clusters"></a>25. 连接到受管理的Kafka集群</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本节解释了如何连接到臭名昭著的Kafka云服务。</p>
</div>
<div class="sect2">
<h3 id="azure-event-hub"><a class="anchor" href="#azure-event-hub"></a>25.1. Azure Event Hub</h3>
<div class="paragraph">
<p><a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview">Azure Event Hub</a> 提供了一个与Apache Kafka兼容的节点。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Azure Event Hubs for Kafka在 <em>基础(basic)</em> 层中不可用。您至少需要 <em>标准(standard)</em> 层才能使用Kafka。请参阅 <a href="https://azure.microsoft.com/en-us/pricing/details/event-hubs/">Azure Event Hubs定价</a> 查看其他选项。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>使用带有TLS的Kafka协议连接到Azure Event Hub的话，您需要以下配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=my-event-hub.servicebus.windows.net:9093 <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \ <i class="conum" data-value="2"></i><b>(2)</b>
    username="$ConnectionString" \ <i class="conum" data-value="3"></i><b>(3)</b>
    password="&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;"; <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>该端口为 <code>9093</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>您需要使用JAAS <code>PlainLoginModule</code> 。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>用户名是 <code>$ConnectionString</code> 字符串。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>由Azure提供的Event Hub连接字符串。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>用您的Event Hubs命名空间的连接字符串替换 <code>&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;</code> 。有关获取连接字符串的说明，请参阅 <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string">获取Event Hubs连接字符串</a> 。结果会类似这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX";</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个配置可以是全局的(如上)，也可以在 channel 配置中设置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.$channel.bootstrap.servers=my-event-hub.servicebus.windows.net:9093
mp.messaging.incoming.$channel.security.protocol=SASL_SSL
mp.messaging.incoming.$channel.sasl.mechanism=PLAIN
mp.messaging.incoming.$channel.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=...";</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="red-hat-openshift-streams-for-apache-kafka"><a class="anchor" href="#red-hat-openshift-streams-for-apache-kafka"></a>25.2. 红帽OpenShift Streams for Apache Kafka</h3>
<div class="paragraph">
<p><a href="https://cloud.redhat.com/">红帽OpenShift Streams for Apache Kafka</a> 提供了受管理的Kafka brokers。首先，按照 <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">红帽OpenShift Streams for Apache Kafka的 <code>rhoas</code> 命令行入门</a> 的说明，创建您的Kafka broker实例。请确保您复制了与您创建的 <em>ServiceAccount</em> 相关的客户ID和客户密码。</p>
</div>
<div class="paragraph">
<p>然后，您可以配置Quarkus应用程序以连接到broker，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=&lt;connection url&gt; <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="${KAFKA_USERNAME}" \ <i class="conum" data-value="2"></i><b>(2)</b>
  password="${KAFKA_PASSWORD}"; <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>在管理控制台所给出的连接字符串，例如 <code>demo-c—​bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Kafka的用户名(来自service account的客户端ID)</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>kafka密码(来自service account的客户密码)</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
一般来说，这些属性的前缀使用 <code>%prod</code> ，以便只在生产模式下运行时启用。
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
正如在《 <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">红帽OpenShift Streams for Apache Kafka的 <code>rhoas</code> 命令行入门</a> 》中所解释的那样，要使用红帽OpenShift Streams for Apache Kafka，您必须事先创建topic，创建一个 <em>Service Account</em> ，并提供从该服务账户读取和写入topic的权限。认证数据(客户端ID和密码)与服务账户有关，这意味着您可以实现细粒度的权限，并限制对topic的访问。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>当使用Kubernetes时，建议在Kubernetes secret中设置客户端ID和secret：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: kafka-credentials
stringData:
  KAFKA_USERNAME: "..."
  KAFKA_PASSWORD: "..."</code></pre>
</div>
</div>
<div class="paragraph">
<p>为了允许您的Quarkus应用程序使用该secret，请在 <code>application.properties</code> 文件中添加下面一行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.quarkus.openshift.env.secrets=kafka-credentials</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="red-hat-openshift-service-registry"><a class="anchor" href="#red-hat-openshift-service-registry"></a>25.2.1. Red Hat OpenShift Service Registry</h4>
<div class="paragraph">
<p><a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry">Red Hat OpenShift Service Registry</a>
provides fully managed service registry for handling Kafka schemas.</p>
</div>
<div class="paragraph">
<p>You can follow the instructions from
<a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/ab1894d1-cae0-4d11-b185-81d62b4aabc7#_60472331-fa00-48ec-a621-bbd039500c7d">Getting started with Red Hat OpenShift Service Registry</a>,
or use the <code>rhoas</code> CLI to create a new service registry instance:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry create --name my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>Make sure to note the <em>Registry URL</em> of the instance created.
For authentication, you can use the same <em>ServiceAccount</em> you created previously.
You need to make sure that it has the necessary permissions to access the service registry.</p>
</div>
<div class="paragraph">
<p>For example, using the <code>rhoas</code> CLI, you can grant the <code>MANAGER</code> role to the service account:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry role add --role manager --service-account [SERVICE_ACCOUNT_CLIENT_ID]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, you can configure the Quarkus application to connect to the schema registry as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.apicurio.registry.url=${RHOAS_SERVICE_REGISTRY_URL} <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.service.token.endpoint=${RHOAS_OAUTH_TOKEN_ENDPOINT} <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.id=${RHOAS_CLIENT_ID} <i class="conum" data-value="3"></i><b>(3)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.secret=${RHOAS_CLIENT_ID} <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The service registry URL, given on the admin console, such as <code><a href="https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2" class="bare">https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The OAuth token endpoint URL, such as <code><a href="https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token" class="bare">https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The client id (from the service account)</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The client secret (from the service account)</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"><a class="anchor" href="#binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"></a>25.2.2. Binding Red Hat OpenShift managed services to Quarkus application using the Service Binding Operator</h4>
<div class="paragraph">
<p>If your Quarkus application is deployed on a Kubernetes or OpenShift cluster with <a href="https://github.com/redhat-developer/service-binding-operator">Service Binding Operator</a> and <a href="https://github.com/redhat-developer/app-services-operator/tree/main/docs">OpenShift Application Services</a> operators installed,
configurations necessary to access Red Hat OpenShift Streams for Apache Kafka and Service Registry can be injected to the application using <a href="deploying-to-kubernetes#service_binding">Kubernetes Service Binding</a>.</p>
</div>
<div class="paragraph">
<p>In order to set up the Service Binding, you need first to connect OpenShift managed services to your cluster.
For an OpenShift cluster you can follow the instructions from <a href="https://github.com/redhat-developer/app-services-guides/tree/main/docs/registry/service-binding-registry#connecting-a-kafka-and-service-registry-instance-to-your-openshift-cluster">Connecting a Kafka and Service Registry instance to your OpenShift cluster</a>.</p>
</div>
<div class="paragraph">
<p>Once you&#8217;ve connected your cluster with the RHOAS Kafka and Service Registry instances, make sure you&#8217;ve granted necessary permissions to the newly created service account.</p>
</div>
<div class="paragraph">
<p>Then, using the <a href="deploying-to-kubernetes#service_binding">Kubernetes Service Binding</a> extension,
you can configure the Quarkus application to generate <code>ServiceBinding</code> resources for those services:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kubernetes-service-binding.detect-binding-resources=true

quarkus.kubernetes-service-binding.services.kafka.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.kafka.kind=KafkaConnection
quarkus.kubernetes-service-binding.services.kafka.name=my-kafka

quarkus.kubernetes-service-binding.services.serviceregistry.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.serviceregistry.kind=ServiceRegistryConnection
quarkus.kubernetes-service-binding.services.serviceregistry.name=my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>For this example Quarkus build will generate the following <code>ServiceBinding</code> resources:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-kafka
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: KafkaConnection
      name: my-kafka
  detectBindingResources: true
  bindAsFiles: true
---
apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-serviceregistry
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: ServiceRegistryConnection
      name: my-schema-registry
  detectBindingResources: true
  bindAsFiles: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can follow <a href="deploying-to-kubernetes#openshift">Deploying to OpenShift</a> to deploy your application, including generated <code>ServiceBinding</code> resources.
The configuration properties necessary to access the Kafka and Schema Registry instances will be injected to the application automatically at deployment.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="going-further"><a class="anchor" href="#going-further"></a>26. 进一步探索</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本指南已经展示了如何使用Quarkus与Kafka进行交互。它利用SmallRye Reactive Messaging来构建数据流应用。</p>
</div>
<div class="paragraph">
<p>如果您想更进一步，请参看<a href="https://smallrye.io/smallrye-reactive-messaging">SmallRye Reactive Messaging</a>，在Quarkus中使用的实现。</p>
</div>
</div>
</div>
    </div>
    <div class="grid__item width-4-12 width-12-12-m tocwrapper">
      <div class="hide-mobile toc"><ul class="sectlevel1">
<li><a href="#introduction">1. 简介</a></li>
<li><a href="#quarkus-extension-for-apache-kafka">2. Apache Kafka Quarkus扩展</a></li>
<li><a href="#configuring-smallrye-kafka-connector">3. 配置Smallrye Kafka Connector</a></li>
<li><a href="#receiving-messages-from-kafka">4. 接收来自Kafka的消息</a>
<ul class="sectlevel2">
<li><a href="#blocking-processing">4.1. 阻塞处理</a></li>
<li><a href="#acknowledgment-strategies">4.2. 确认策略(Acknowledgment Strategies)</a></li>
<li><a href="#commit-strategies">4.3. 提交策略(Commit Strategies)</a></li>
<li><a href="#error-handling">4.4. 错误处理策略(Error Handling Strategies)</a></li>
<li><a href="#consumer-groups">4.5. 消费者组(Consumer Groups)</a></li>
<li><a href="#receiving-kafka-records-in-batches">4.6. 批量接收Kafka记录</a></li>
</ul>
</li>
<li><a href="#sending-messages-to-kafka">5. 向Kafka发送消息</a>
<ul class="sectlevel2">
<li><a href="#sending-messages-with-emitter">5.1. 使用@Emitter发送消息</a></li>
<li><a href="#write-acknowledgement">5.2. 写确认</a></li>
<li><a href="#backpressure">5.3. 背压</a></li>
<li><a href="#retrying-message-dispatch">5.4. 重试消息的发送</a></li>
<li><a href="#handling-serialization-failures">5.5. 处理序列化失败</a></li>
<li><a href="#in-memory-channels">5.6. 内存 channels</a></li>
<li><a href="#broadcasting-messages-on-multiple-consumers">5.7. 对多个消费者广播信息</a></li>
<li><a href="#kafka-transactions">5.8. Kafka事务处理</a></li>
</ul>
</li>
<li><a href="#processing-messages">6. 处理消息</a>
<ul class="sectlevel2">
<li><a href="#propagating-record-key">6.1. 传播记录键</a></li>
<li><a href="#exactly-once-processing">6.2. （Exactly-Once Processing）精确一次处理</a></li>
</ul>
</li>
<li><a href="#kafka-bare-clients">7. 直接访问Kafka客户端</a></li>
<li><a href="#kafka-serialization">8. JSON序列化</a>
<ul class="sectlevel2">
<li><a href="#jackson-serialization">8.1. 通过Jackson进行序列化</a></li>
<li><a href="#jsonb-serialization">8.2. 通过JSON-B进行序列化</a></li>
</ul>
</li>
<li><a href="#avro-serialization">9. Avro序列化</a></li>
<li><a href="#serialization-autodetection">10. 序列化/反串行器自动侦测</a></li>
<li><a href="#serialization-generation">11. JSON序列化器/反序列化器的生成</a></li>
<li><a href="#using-schema-registry">12. 使用Schema注册表</a></li>
<li><a href="#kafka-health-check">13. 健康检查</a>
<ul class="sectlevel2">
<li><a href="#kafka-broker-readiness-check">13.1. Kafka Broker就绪检查(Readiness Check)</a></li>
<li><a href="#kafka-reactive-messaging-health-checks">13.2. Kafka响应式消息传递健康检查</a></li>
</ul>
</li>
<li><a href="#kafka-streams">14. Kafka流</a></li>
<li><a href="#using-snappy-for-message-compression">15. 使用Snappy进行消息压缩</a></li>
<li><a href="#authentication-with-oauth">16. 用OAuth进行认证</a></li>
<li><a href="#testing-a-kafka-application">17. 测试一个Kafka应用程序</a>
<ul class="sectlevel2">
<li><a href="#testing-without-a-broker">17.1. 无broker的测试</a></li>
<li><a href="#testing-using-a-kafka-broker">17.2. 使用Kafka broker的测试</a></li>
</ul>
</li>
<li><a href="#kafka-dev-services">18. Kafka开发服务（Dev Services）</a>
<ul class="sectlevel2">
<li><a href="#enabling-disabling-dev-services-for-kafka">18.1. 启用/禁用Kafka开发服务</a></li>
<li><a href="#shared-broker">18.2. 共享的代理</a></li>
<li><a href="#setting-the-port">18.3. 设置端口</a></li>
<li><a href="#configuring-the-image">18.4. 配置镜像</a></li>
<li><a href="#configuring-kafka-topics">18.5. 配置Kafka主题</a></li>
<li><a href="#redpanda-transactions">18.6. Transactional and Idempotent producers support</a></li>
</ul>
</li>
<li><a href="#kubernetes-service-bindings">19. Kubernetes服务绑定</a></li>
<li><a href="#execution-model">20. 执行模型</a></li>
<li><a href="#channel-decorators">21. Channel Decorators</a></li>
<li><a href="#kafka-configuration">22. 配置参考</a>
<ul class="sectlevel2">
<li><a href="#incoming-channel-configuration-polling-from-kafka">22.1. 入站 channel 配置(从Kafka轮询)</a></li>
<li><a href="#outgoing-channel-configuration-writing-to-kafka">22.2. 出站 channel 配置(写入Kafka)。</a></li>
<li><a href="#kafka-configuration-resolution">22.3. Kafka配置方案</a></li>
</ul>
</li>
<li><a href="#integrating-with-kafka-common-patterns">23. 与Kafka的整合&#8212;&#8203;通用模式</a>
<ul class="sectlevel2">
<li><a href="#writing-to-kafka-from-an-http-endpoint">23.1. 从HTTP节点写消息到Kafka</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-with-panache">23.2. 用Hibernate与Panache来持久化Kafka消息</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-reactive">23.3. 使用Hibernate Reactive持久化Kafka消息</a></li>
<li><a href="#writing-entities-managed-by-hibernate-to-kafka">23.4. 将Hibernate管理的实体写入Kafka中</a></li>
<li><a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">23.5. 将Hibernate Reactive管理的实体写入Kafka中</a></li>
<li><a href="#streaming-kafka-topics-as-server-sent-events">23.6. 将Kafka topic作为服务器发送的事件流化</a></li>
<li><a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">23.7. Chaining Kafka Transactions with Hibernate Reactive transactions</a></li>
</ul>
</li>
<li><a href="#logging">24. 日志</a></li>
<li><a href="#connecting-to-managed-kafka-clusters">25. 连接到受管理的Kafka集群</a>
<ul class="sectlevel2">
<li><a href="#azure-event-hub">25.1. Azure Event Hub</a></li>
<li><a href="#red-hat-openshift-streams-for-apache-kafka">25.2. 红帽OpenShift Streams for Apache Kafka</a></li>
</ul>
</li>
<li><a href="#going-further">26. 进一步探索</a></li>
</ul></div>
    </div>
  </div>
  </div>

  </div>

  <div class="content project-footer">
  <div class="footer-section">
    <div class="logo-wrapper">
      <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
    </div>
  </div>
  <div class="grid-wrapper">
    <p class="grid__item width-3-12">Quarkus is open. All dependencies of this project are available under the <a href='https://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache Software License 2.0</a> or compatible license. <i class='fab fa-creative-commons'></i><i class='fab fa-creative-commons-by'></i> <a href='https://creativecommons.org/licenses/by/3.0/' target='_blank'>CC by 3.0</a><br /><br />This website was built with <a href='https://jekyllrb.com/' target='_blank'>Jekyll</a>, is hosted on <a href='https://pages.github.com/' target='_blank'>GitHub Pages</a> and is completely open source. If you want to make it better, <a href='https://github.com/quarkusio/quarkusio.github.io' target='_blank'>fork the website</a> and show us what you’ve got.</p>

    
      <div class="width-1-12 project-links">
        <span>Navigation</span>
        <ul class="footer-links">
          
          
            <li><a href="/" target="_blank">Home</a></li>
          
          
          
            <li><a href="/about" target="_blank">About</a></li>
          
          
          
            <li><a href="/blog" target="_blank">博客</a></li>
          
          
          
            <li><a href="/insights" target="_blank">Podcast</a></li>
          
          
          
            <li><a href="/events" target="_blank">活动</a></li>
          
          
          
            <li><a href="/newsletter" target="_blank">新闻</a></li>
          
          
          
            <li><a href="/userstories" target="_blank">User Stories</a></li>
          
          
          
            <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" target="_blank">路线图</a></li>
          
          
          
            <li><a href="/security" target="_blank">Security&nbsp;policy</a></li>
          
          
          
            <li><a href="/usage" target="_blank">Usage</a></li>
          
          
          
            <li><a href="/brand" target="_blank">Brand</a></li>
          
          
          
            <li><a href="/desktopwallpapers" target="_blank">Wallpapers</a></li>
          
          
          
            <li><a href="https://www.redhat.com/en/about/privacy-policy" target="_blank">Privacy Policy</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Follow Us</span>
        <ul class="footer-links">
          
          
            <li><a href="https://x.com/quarkusio" target="_blank">X</a></li>
          
          
          
            <li><a href="https://bsky.app/profile/quarkus.io" target="_blank">Bluesky</a></li>
          
          
          
            <li><a rel="me" href="https://fosstodon.org/@quarkusio" target="_blank">Mastodon</a></li>
            
          
          
            <li><a href="https://www.threads.com/@quarkusio" target="_blank">Threads</a></li>
          
          
          
            <li><a href="https://www.facebook.com/quarkusio" target="_blank">Facebook</a></li>
          
          
          
            <li><a href="https://www.linkedin.com/company/quarkusio/" target="_blank">Linkedin</a></li>
          
          
          
            <li><a href="https://www.youtube.com/channel/UCaW8QG_QoIk_FnjLgr5eOqg" target="_blank">Youtube</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio" target="_blank">GitHub</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-2-12 project-links">
        <span>Get Help</span>
        <ul class="footer-links">
          
          
            <li><a href="/support" target="_blank">Support</a></li>
          
          
          
            <li><a href="/guides" target="_blank">Guides</a></li>
          
          
          
            <li><a href="/faq" target="_blank">FAQ</a></li>
          
          
          
            <li><a href="/get-started" target="_blank">开始体验</a></li>
          
          
          
            <li><a href="https://stackoverflow.com/questions/tagged/quarkus" target="_blank">Stack Overflow</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio/quarkus/discussions" target="_blank">Discussions</a></li>
          
          
          
            <li><a href="https://groups.google.com/forum/#!forum/quarkus-dev" target="_blank">Development mailing list</a></li>
          
          
          
            <li><a href="https://stats.uptimerobot.com/ze1PfweT2p" target="_blank">Quarkus Service Status</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Languages</span>
        <ul class="footer-links">
          
          
            <li><a href="https://quarkus.io/" target="_blank">English</a></li>
          
          
          
            <li><a href="https://pt.quarkus.io/" target="_blank">Português&nbsp;(Brasileiro)</a></li>
          
          
          
            <li><a href="https://es.quarkus.io/" target="_blank">Español</a></li>
          
          
          
            <li><a href="https://cn.quarkus.io/" target="_blank">简体中文</a></li>
          
          
          
            <li><a href="https://ja.quarkus.io/" target="_blank">日本語</a></li>
          
          
        </ul>
      </div>
    

    
      <div class="width-4-12 more-links">
        <span>Quarkus is made of community projects</span>
        <ul class="footer-links">
          
            <li><a blah href="https://vertx.io/" target="_blank">Eclipse Vert.x</a></li>
          
            <li><a blah href="https://smallrye.io" target="_blank">SmallRye</a></li>
          
            <li><a blah href="https://hibernate.org" target="_blank">Hibernate</a></li>
          
            <li><a blah href="https://netty.io" target="_blank">Netty</a></li>
          
            <li><a blah href="https://resteasy.github.io" target="_blank">RESTEasy</a></li>
          
            <li><a blah href="https://camel.apache.org" target="_blank">Apache Camel</a></li>
          
            <li><a blah href="https://microprofile.io" target="_blank">Eclipse MicroProfile</a></li>
          
            <li><a blah href="https://code.quarkus.io/" target="_blank">And many more...</a></li>
          
        </ul>
      </div>
    
  </div>
</div>

  <div class="content cf-footer">
  <div class="flexcontainer">
    <div class="cf-logo">
      <a class="cf-logo" href="https://www.commonhaus.org/" target="_blank"><img src="https://raw.githubusercontent.com/commonhaus/artwork/main/foundation/brand/svg/CF_logo_horizontal_single_reverse.svg"/></a>
    </div>
    <div class="license">
      Copyright © Quarkus. All rights reserved. For details on our trademarks, please visit our <a href="https://www.commonhaus.org/policies/trademark-policy/">Trademark Policy</a> and <a href="https://www.commonhaus.org/trademarks/">Trademark List</a>. Trademarks of third parties are owned by their respective holders and their mention here does not suggest any endorsement or association.
    </div>
  </div>
</div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
  <script type="text/javascript" src="/assets/javascript/mobile-nav.js"></script>
  <script type="text/javascript" src="/assets/javascript/scroll-down.js"></script>
  <script src="/assets/javascript/satellite.js" type="text/javascript"></script>
  <script src="/guides/javascript/config.js" type="text/javascript"></script>
  <script src="/assets/javascript/guides-version-dropdown.js" type="text/javascript"></script>
  <script src="/assets/javascript/back-to-top.js" type="text/javascript"></script>
  <script src="/assets/javascript/clipboard.min.js" type="text/javascript"></script>
  <script src="/assets/javascript/copy.js" type="text/javascript"></script>
  <script src="/assets/javascript/asciidoc-tabs.js" type="text/javascript"></script>
  <script src="/assets/javascript/future-date.js" type="text/javascript"></script>
  <script src="/assets/javascript/randomize.js" type="text/javascript"></script>
  <script src="/assets/javascript/time.js" type="text/javascript"></script>
</body>

</html>
